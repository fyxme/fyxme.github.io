<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fyx(me) – </title>
    <link>https://fyx.me/bazaar/ai/</link>
    <description>Recent content on fyx(me)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	  <atom:link href="https://fyx.me/bazaar/ai/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title></title>
      <link>https://fyx.me/bazaar/ai/agents/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fyx.me/bazaar/ai/agents/</guid>
      <description>
        
        
        &lt;h2&gt;Agent types&lt;span class=&#34;hx-absolute -hx-mt-20&#34; id=&#34;agent-types&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#agent-types&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Plain LLM Agents&lt;span class=&#34;hx-absolute -hx-mt-20&#34; id=&#34;plain-llm-agents&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#plain-llm-agents&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Plain LLM agents&lt;/strong&gt; are simple agents that use a large language model (LLM) directly to choose next actions or generate task steps without extra layers like complex planners, learned policies, or specialized orchestration frameworks.&lt;/p&gt;
&lt;p&gt;Key characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Single-step decisioning:&lt;/strong&gt; the LLM is prompted to decide the next action each turn (e.g., call a tool, ask a question, produce text).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Minimal state management:&lt;/strong&gt; little or no explicit memory, belief model, or long-term planning beyond what’s kept in the prompt/history.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No learned controller:&lt;/strong&gt; decisions rely on prompt engineering and the LLM’s reasoning, not on a separate trained policy network.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tool-driven behavior:&lt;/strong&gt; often constrained to a fixed set of tools or API calls the LLM can invoke via structured outputs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reactive and iterative:&lt;/strong&gt; acts, observes results, and prompts the LLM again—adapting only through updated context.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When to use:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prototyping agents quickly.&lt;/li&gt;
&lt;li&gt;Tasks where short-horizon, conversational reasoning suffices.&lt;/li&gt;
&lt;li&gt;Systems prioritizing simplicity and interpretability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Limitations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Poor scalability for long, complex plans.&lt;/li&gt;
&lt;li&gt;Fragile to prompt drift and verbose histories.&lt;/li&gt;
&lt;li&gt;Limited ability to optimize across multiple steps or maintain consistent long-term strategies.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title></title>
      <link>https://fyx.me/bazaar/ai/ai-code-review/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fyx.me/bazaar/ai/ai-code-review/</guid>
      <description>
        
        
        &lt;h2&gt;&lt;a href=&#34;https://codebase.md/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;codebase.md&lt;/a&gt;&lt;span class=&#34;hx-absolute -hx-mt-20&#34; id=&#34;codebasemdhttpscodebasemd&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#codebasemdhttpscodebasemd&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;blockquote&gt;
  &lt;p&gt;I built myself an app to turn any GitHub repo into markdown for AI agents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;returns markdown for agents, html for humans&lt;/li&gt;
&lt;li&gt;pagination links agents can follow for large repos&lt;/li&gt;
&lt;li&gt;simple filters for tokens, file extensions etc
&lt;/br&gt;&lt;a href=&#34;https://x.com/iannuttall/status/1975495604823539765&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://x.com/iannuttall/status/1975495604823539765&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/blockquote&gt;
&lt;h2&gt;&lt;a href=&#34;https://deepwiki.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;deekpwiki.com&lt;/a&gt;&lt;span class=&#34;hx-absolute -hx-mt-20&#34; id=&#34;deekpwikicomhttpsdeepwikicom&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#deekpwikicomhttpsdeepwikicom&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;blockquote&gt;
  &lt;p&gt;DeepWiki provides up-to-date documentation you can talk to, for every repo in the world. Think Deep Research for GitHub.&lt;/p&gt;

&lt;/blockquote&gt;
&lt;p&gt;Alternative open-source version: &lt;a href=&#34;https://github.com/AsyncFuncAI/deepwiki-open&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/AsyncFuncAI/deepwiki-open&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title></title>
      <link>https://fyx.me/bazaar/ai/ai-open-source-clients/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fyx.me/bazaar/ai/ai-open-source-clients/</guid>
      <description>
        
        
        &lt;h1&gt;AI open-source Chat Clients&lt;/h1&gt;&lt;h2&gt;&lt;a href=&#34;https://www.jan.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jan.ai&lt;/a&gt;&lt;span class=&#34;hx-absolute -hx-mt-20&#34; id=&#34;janaihttpswwwjanai&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#janaihttpswwwjanai&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Jan is insteresting because it supports&lt;/p&gt;
&lt;p&gt;
    &lt;img src=&#34;../img/Pasted%20image%2020251228090731.webp&#34; alt=&#34;&#34; loading=&#34;lazy&#34; /&gt;&lt;/p&gt;
&lt;h2&gt;Others&lt;span class=&#34;hx-absolute -hx-mt-20&#34; id=&#34;others&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#others&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Mintplex-Labs/anything-llm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;anything-llm&lt;/a&gt;: good to test out models quickly in a single binary (ie. quick install/cleanup)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CherryHQ/cherry-studio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cherry studio&lt;/a&gt;: apparently very &lt;a href=&#34;https://www.reddit.com/r/LocalLLaMA/comments/1lzikqt/annoyed_with_librechat/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;capable and clean&lt;/a&gt; but I&amp;rsquo;ve not tested it&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.librechat.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.librechat.ai/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/open-webui/open-webui&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/open-webui/open-webui&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sillytavern.app/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Silly Tavern&lt;/a&gt;: Extremely customisable but initial setup is longer due to customisation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;AI open-source code clients&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openai/codex&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;codex&lt;/a&gt;: open-ai&amp;rsquo;s own CLI (Chatgpt)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/anthropics/claude-code&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;claude code&lt;/a&gt;: anthropic&amp;rsquo;s own CLI (Claude)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://opencode.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;opencode&lt;/a&gt;: cool sharing feature, I wish they open-sourced the server for it&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/just-every/code&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/just-every/code&lt;/a&gt;: An improved codex version with missing features, agent subtasks, browser support and more. Only got meh results from it so far&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Comparaisons&lt;span class=&#34;hx-absolute -hx-mt-20&#34; id=&#34;comparaisons&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#comparaisons&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=46391391&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;codex vs claude code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title></title>
      <link>https://fyx.me/bazaar/ai/inference-providers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fyx.me/bazaar/ai/inference-providers/</guid>
      <description>
        
        
        &lt;h2&gt;Free API providers&lt;span class=&#34;hx-absolute -hx-mt-20&#34; id=&#34;free-api-providers&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#free-api-providers&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;There&amp;rsquo;s a number of free Inference providers with APIs available:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://build.nvidia.com/explore/discover&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://build.nvidia.com/explore/discover&lt;/a&gt; - Nvidia NIM API - free API for opensource  models like Kimi K2&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openrouter.ai/models?q=free&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://openrouter.ai/models?q=free&lt;/a&gt; - a number of free daily requests (heavily rate limited)&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title></title>
      <link>https://fyx.me/bazaar/ai/inspecting-mcp-servers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fyx.me/bazaar/ai/inspecting-mcp-servers/</guid>
      <description>
        
        
        &lt;p&gt;If you&amp;rsquo;re interacting with MCP servers, you might want to test them without having to use an AI agent/client to connect and interact with it (looking at you HTB mcp_only CTF events&amp;hellip;). Thankfully there&amp;rsquo;s tools available.&lt;/p&gt;
&lt;h2&gt;&lt;a href=&#34;https://github.com/modelcontextprotocol/inspector&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;modelcontextprotocol/inspector&lt;/a&gt;&lt;span class=&#34;hx-absolute -hx-mt-20&#34; id=&#34;modelcontextprotocolinspectorhttpsgithubcommodelcontextprotocolinspector&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#modelcontextprotocolinspectorhttpsgithubcommodelcontextprotocolinspector&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The MCP inspector is a developer tool for testing and debugging MCP servers. Hackthebox has competitions which are only available via MCP which means you need an AI agent/client or a way to inspect the MCP server.&lt;/p&gt;
&lt;p&gt;With inspector, you can query the tools and providing arguments as necessary.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s an example using MCP inspector with &lt;a href=&#34;https://www.hackthebox.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hackthebox MCP&lt;/a&gt; to retrieve events, challenges, etc:&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
    &lt;img src=&#34;../img/MCP%20Inspector%20with%20Hackthebox%20MCP.webp&#34; title=&#34;Using MCP inspector to explore Hackthebox MCP&#34; alt=&#34;&#34; loading=&#34;lazy&#34; /&gt;
    &lt;figcaption&gt;Using MCP inspector to explore Hackthebox MCP&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Alternative, you can use something like &lt;a href=&#34;https://github.com/MCPJam/inspector&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MCPJam/Inspector&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
