<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="index, follow" />
  <link rel="icon shortcut" href="/favicon.ico" sizes="32x32" />
<link rel="icon" href="/favicon.svg" type="image/svg+xml" />
<link rel="icon" href="/favicon-dark.svg" type="image/svg+xml" media="(prefers-color-scheme: dark)" />
<link rel="icon" href="/favicon-16x16.png" type="image/png" sizes="16x16" />
<link rel="icon" href="/favicon-32x32.png" type="image/png" sizes="32x32" />
<link rel="apple-touch-icon" href="/apple-touch-icon.png" sizes="180x180" />
<link fetchpriority="low" href="/site.webmanifest" rel="manifest" />
<title>Exploring Autonomous LLM Agents for Capture The Flag problem solving using Prompt Engineering, RAG and Open Source LLMs – fyx(me)</title>
  <meta name="description" content="Build &amp; benchmark AI agents that solve Capture-The-Flag problems end-to-end with open LLMs, RAG tool retrieval and structured prompting. GitHub code &#43; live CTF results." /><link rel="canonical" href="https://fyx.me/articles/exploring-autonomous-llm-agents-for-capture-the-flag-problem-solving-using-context-engineering-rag-and-open-source-models/" itemprop="url" />

<meta property="og:title" content="fyx(me) - Exploring Autonomous LLM Agents for Capture The Flag problem solving using Prompt Engineering, RAG and Open Source LLMs" />
<meta property="og:description" content="Build &amp; benchmark AI agents that solve Capture-The-Flag problems end-to-end with open LLMs, RAG tool retrieval and structured prompting. GitHub code &#43; live CTF results." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://fyx.me/articles/exploring-autonomous-llm-agents-for-capture-the-flag-problem-solving-using-context-engineering-rag-and-open-source-models/" /><meta property="og:image" content="https://fyx.me/opengraph/content-articles-exploring-autonomous-llm-agents-for-capture-the-flag-problem-solving-using-context-engineering-rag-and-open-source-models.webp" /><meta property="article:section" content="articles" />
<meta property="article:published_time" content="2025-08-28T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-08-28T00:00:00+00:00" /><meta property="og:site_name" content="fyx(me)" />

  <meta itemprop="name" content="Exploring Autonomous LLM Agents for Capture The Flag problem solving using Prompt Engineering, RAG and Open Source LLMs">
  <meta itemprop="description" content="Build &amp; benchmark AI agents that solve Capture-The-Flag problems end-to-end with open LLMs, RAG tool retrieval and structured prompting. GitHub code &#43; live CTF results.">
  <meta itemprop="datePublished" content="2025-08-28T00:00:00+00:00">
  <meta itemprop="dateModified" content="2025-08-28T00:00:00+00:00">
  <meta itemprop="wordCount" content="10634">
  <meta itemprop="image" content="https://fyx.me/opengraph/content-articles-exploring-autonomous-llm-agents-for-capture-the-flag-problem-solving-using-context-engineering-rag-and-open-source-models.webp">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://fyx.me/opengraph/content-articles-exploring-autonomous-llm-agents-for-capture-the-flag-problem-solving-using-context-engineering-rag-and-open-source-models.webp">
  <meta name="twitter:title" content="Exploring Autonomous LLM Agents for Capture The Flag problem solving using Prompt Engineering, RAG and Open Source LLMs">
  <meta name="twitter:description" content="Build &amp; benchmark AI agents that solve Capture-The-Flag problems end-to-end with open LLMs, RAG tool retrieval and structured prompting. GitHub code &#43; live CTF results.">


    <link rel="preload" href="/css/compiled/main.min.33b308ec8b8d5df72a614d7504ed2df3405a9b1d19cf059dc9c4d88f0b8a2551.css" as="style" />
    <link href="/css/compiled/main.min.33b308ec8b8d5df72a614d7504ed2df3405a9b1d19cf059dc9c4d88f0b8a2551.css" rel="stylesheet" />




  <link href="/css/custom.min.6189dd16334b8142c5bd7b6757ba67210d2f98d8cb82f91d80d0d32e844ef2e8.css" rel="stylesheet" />


  <script>
     
    const defaultTheme = 'dark';

    const setDarkTheme = () => {
      document.documentElement.classList.add("dark");
      document.documentElement.style.colorScheme = "dark";
    }
    const setLightTheme = () => {
      document.documentElement.classList.remove("dark");
      document.documentElement.style.colorScheme = "light";
    }

    if ("color-theme" in localStorage) {
      localStorage.getItem("color-theme") === "dark" ? setDarkTheme() : setLightTheme();
    } else {
      defaultTheme === "dark" ? setDarkTheme() : setLightTheme();
      if (defaultTheme === "system") {
        window.matchMedia("(prefers-color-scheme: dark)").matches ? setDarkTheme() : setLightTheme();
      }
    }
  </script>

  <script defer src="https://a.blinking.dog/script.js" data-website-id="ec9f3909-7c35-4c7e-a1cd-5c9248950e26" data-domains="fyx.me,www.fyx.me"></script>

</head>
<body dir="ltr"><div class="nav-container hx-sticky hx-top-0 hx-z-20 hx-w-full hx-bg-transparent print:hx-hidden">
  <div class="nav-container-blur hx-pointer-events-none hx-absolute hx-z-[-1] hx-h-full hx-w-full hx-bg-white dark:hx-bg-dark hx-shadow-[0_2px_4px_rgba(0,0,0,.02),0_1px_0_rgba(0,0,0,.06)] contrast-more:hx-shadow-[0_0_0_1px_#000] dark:hx-shadow-[0_-1px_0_rgba(255,255,255,.1)_inset] contrast-more:dark:hx-shadow-[0_0_0_1px_#fff]"></div>

  <nav class="hx-mx-auto hx-flex hx-items-center hx-justify-end hx-gap-2 hx-h-16 hx-px-6 hx-max-w-[90rem]">
    <a class="hx-flex hx-items-center hover:hx-opacity-75 ltr:hx-mr-auto rtl:hx-ml-auto" href="/">
        <img class="hx-block dark:hx-hidden" src="/images/fyxme.svg" alt="fyx(me)" height="20" width="30" />
        <img class="hx-hidden dark:hx-block" src="/images/fyxme.svg" alt="fyx(me)" height="20" width="30" />
        <span class="hx-mx-2 hx-font-extrabold hx-inline hx-select-none" title="fyx(me)">fyx(me)</span>
    </a><a
            title="about"
            href="/about"
            
            class="hx-text-sm contrast-more:hx-text-gray-700 contrast-more:dark:hx-text-gray-100 hx-relative -hx-ml-2 hx-hidden hx-whitespace-nowrap hx-p-2 md:hx-inline-block hx-text-gray-600 hover:hx-text-gray-800 dark:hx-text-gray-400 dark:hover:hx-text-gray-200"
          >
            <span class="hx-text-center">about</span>
          </a><a
            title="articles"
            href="/articles"
            
            class="hx-text-sm contrast-more:hx-text-gray-700 contrast-more:dark:hx-text-gray-100 hx-relative -hx-ml-2 hx-hidden hx-whitespace-nowrap hx-p-2 md:hx-inline-block hx-font-medium"
          >
            <span class="hx-text-center">articles</span>
          </a><a
            title="minis"
            href="/minis"
            
            class="hx-text-sm contrast-more:hx-text-gray-700 contrast-more:dark:hx-text-gray-100 hx-relative -hx-ml-2 hx-hidden hx-whitespace-nowrap hx-p-2 md:hx-inline-block hx-text-gray-600 hover:hx-text-gray-800 dark:hx-text-gray-400 dark:hover:hx-text-gray-200"
          >
            <span class="hx-text-center">minis</span>
          </a><a
            title="code"
            href="/code"
            
            class="hx-text-sm contrast-more:hx-text-gray-700 contrast-more:dark:hx-text-gray-100 hx-relative -hx-ml-2 hx-hidden hx-whitespace-nowrap hx-p-2 md:hx-inline-block hx-text-gray-600 hover:hx-text-gray-800 dark:hx-text-gray-400 dark:hover:hx-text-gray-200"
          >
            <span class="hx-text-center">code</span>
          </a><a
            title="bazaar"
            href="/bazaar"
            
            class="hx-text-sm contrast-more:hx-text-gray-700 contrast-more:dark:hx-text-gray-100 hx-relative -hx-ml-2 hx-hidden hx-whitespace-nowrap hx-p-2 md:hx-inline-block hx-text-gray-600 hover:hx-text-gray-800 dark:hx-text-gray-400 dark:hover:hx-text-gray-200"
          >
            <span class="hx-text-center">bazaar</span>
          </a><div class="search-wrapper hx-relative md:hx-w-64">
  <div class="hx-relative hx-flex hx-items-center hx-text-gray-900 contrast-more:hx-text-gray-800 dark:hx-text-gray-300 contrast-more:dark:hx-text-gray-300">
    <input
      placeholder="Search..."
      class="search-input hx-block hx-w-full hx-appearance-none hx-rounded-lg hx-px-3 hx-py-2 hx-transition-colors hx-text-base hx-leading-tight md:hx-text-sm hx-bg-black/[.05] dark:hx-bg-gray-50/10 focus:hx-bg-white dark:focus:hx-bg-dark placeholder:hx-text-gray-500 dark:placeholder:hx-text-gray-400 contrast-more:hx-border contrast-more:hx-border-current"
      type="search"
      value=""
      spellcheck="false"
    />
    <kbd
      class="hx-absolute hx-my-1.5 hx-select-none ltr:hx-right-1.5 rtl:hx-left-1.5 hx-h-5 hx-rounded hx-bg-white hx-px-1.5 hx-font-mono hx-text-[10px] hx-font-medium hx-text-gray-500 hx-border dark:hx-border-gray-100/20 dark:hx-bg-dark/50 contrast-more:hx-border-current contrast-more:hx-text-current contrast-more:dark:hx-border-current hx-items-center hx-gap-1 hx-transition-opacity hx-pointer-events-none hx-hidden sm:hx-flex"
    >
      CTRL K
    </kbd>
  </div>

  <div>
    <ul
      class="search-results hextra-scrollbar hx-hidden hx-border hx-border-gray-200 hx-bg-white hx-text-gray-100 dark:hx-border-neutral-800 dark:hx-bg-neutral-900 hx-absolute hx-top-full hx-z-20 hx-mt-2 hx-overflow-auto hx-overscroll-contain hx-rounded-xl hx-py-2.5 hx-shadow-xl hx-max-h-[min(calc(50vh-11rem-env(safe-area-inset-bottom)),400px)] md:hx-max-h-[min(calc(100vh-5rem-env(safe-area-inset-bottom)),400px)] hx-inset-x-0 ltr:md:hx-left-auto rtl:md:hx-right-auto contrast-more:hx-border contrast-more:hx-border-gray-900 contrast-more:dark:hx-border-gray-50 hx-w-screen hx-min-h-[100px] hx-max-w-[min(calc(100vw-2rem),calc(100%+20rem))]"
      style="transition: max-height 0.2s ease 0s;"
    ></ul>
  </div>
</div>

          <a class="hx-p-2 hx-text-current" target="_blank" rel="noreferrer" href="https://github.com/fyxme/" title="github"><svg height=24 fill="currentColor" viewBox="3 3 18 18">
  <path d="M12 3C7.0275 3 3 7.12937 3 12.2276C3 16.3109 5.57625 19.7597 9.15374 20.9824C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441C9.77249 20.3249 9.76125 19.5982 9.76125 18.8254C7.5 19.2522 6.915 18.2602 6.735 17.7412C6.63375 17.4759 6.19499 16.6569 5.8125 16.4378C5.4975 16.2647 5.0475 15.838 5.80124 15.8264C6.51 15.8149 7.01625 16.4954 7.18499 16.7723C7.99499 18.1679 9.28875 17.7758 9.80625 17.5335C9.885 16.9337 10.1212 16.53 10.38 16.2993C8.3775 16.0687 6.285 15.2728 6.285 11.7432C6.285 10.7397 6.63375 9.9092 7.20749 9.26326C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794C7.2975 6.81794 8.05125 6.57571 9.77249 7.76377C10.4925 7.55615 11.2575 7.45234 12.0225 7.45234C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377C15.9937 6.56418 16.7475 6.81794 16.7475 6.81794C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326C17.4113 9.9092 17.76 10.7281 17.76 11.7432C17.76 15.2843 15.6563 16.0687 13.6537 16.2993C13.98 16.5877 14.2613 17.1414 14.2613 18.0065C14.2613 19.2407 14.25 20.2326 14.25 20.5441C14.25 20.7863 14.4188 21.0746 14.8688 20.9824C16.6554 20.364 18.2079 19.1866 19.3078 17.6162C20.4077 16.0457 20.9995 14.1611 21 12.2276C21 7.12937 16.9725 3 12 3Z"></path>
</svg>
<span class="hx-sr-only">github</span>
          </a>
          <a class="hx-p-2 hx-text-current" target="_blank" rel="noreferrer" href="https://x.com/_fyxme" title="twitter"><svg height=24 xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="currentColor" d="M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958 0 002.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 00-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 00-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 01-2.228-.616v.06a4.923 4.923 0 003.946 4.827 4.996 4.996 0 01-2.212.085 4.936 4.936 0 004.604 3.417 9.867 9.867 0 01-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 007.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0024 4.59z"></path></svg><span class="hx-sr-only">twitter</span>
          </a><button type="button" aria-label="Menu" class="hamburger-menu -hx-mr-2 hx-rounded hx-p-2 active:hx-bg-gray-400/20 md:hx-hidden"><svg height=24 fill="none" viewBox="0 0 24 24" stroke="currentColor"><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 8H20"></path></g><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16H20"></path></g></svg></button>
  </nav>
</div>

  <div class="hx-mx-auto hx-flex hx-max-w-screen-xl">
    <div class="mobile-menu-overlay [transition:background-color_1.5s_ease] hx-fixed hx-inset-0 hx-z-10 hx-bg-black/80 dark:hx-bg-black/60 hx-hidden"></div>
<aside class="sidebar-container hx-flex hx-flex-col print:hx-hidden md:hx-top-16 md:hx-shrink-0 md:hx-w-64 md:hx-self-start max-md:[transform:translate3d(0,-100%,0)] md:hx-hidden">
  
  <div class="hx-px-4 hx-pt-4 md:hx-hidden">
    <div class="search-wrapper hx-relative md:hx-w-64">
  <div class="hx-relative hx-flex hx-items-center hx-text-gray-900 contrast-more:hx-text-gray-800 dark:hx-text-gray-300 contrast-more:dark:hx-text-gray-300">
    <input
      placeholder="Search..."
      class="search-input hx-block hx-w-full hx-appearance-none hx-rounded-lg hx-px-3 hx-py-2 hx-transition-colors hx-text-base hx-leading-tight md:hx-text-sm hx-bg-black/[.05] dark:hx-bg-gray-50/10 focus:hx-bg-white dark:focus:hx-bg-dark placeholder:hx-text-gray-500 dark:placeholder:hx-text-gray-400 contrast-more:hx-border contrast-more:hx-border-current"
      type="search"
      value=""
      spellcheck="false"
    />
    <kbd
      class="hx-absolute hx-my-1.5 hx-select-none ltr:hx-right-1.5 rtl:hx-left-1.5 hx-h-5 hx-rounded hx-bg-white hx-px-1.5 hx-font-mono hx-text-[10px] hx-font-medium hx-text-gray-500 hx-border dark:hx-border-gray-100/20 dark:hx-bg-dark/50 contrast-more:hx-border-current contrast-more:hx-text-current contrast-more:dark:hx-border-current hx-items-center hx-gap-1 hx-transition-opacity hx-pointer-events-none hx-hidden sm:hx-flex"
    >
      CTRL K
    </kbd>
  </div>

  <div>
    <ul
      class="search-results hextra-scrollbar hx-hidden hx-border hx-border-gray-200 hx-bg-white hx-text-gray-100 dark:hx-border-neutral-800 dark:hx-bg-neutral-900 hx-absolute hx-top-full hx-z-20 hx-mt-2 hx-overflow-auto hx-overscroll-contain hx-rounded-xl hx-py-2.5 hx-shadow-xl hx-max-h-[min(calc(50vh-11rem-env(safe-area-inset-bottom)),400px)] md:hx-max-h-[min(calc(100vh-5rem-env(safe-area-inset-bottom)),400px)] hx-inset-x-0 ltr:md:hx-left-auto rtl:md:hx-right-auto contrast-more:hx-border contrast-more:hx-border-gray-900 contrast-more:dark:hx-border-gray-50 hx-w-screen hx-min-h-[100px] hx-max-w-[min(calc(100vw-2rem),calc(100%+20rem))]"
      style="transition: max-height 0.2s ease 0s;"
    ></ul>
  </div>
</div>

  </div>
  <div class="hextra-scrollbar hx-overflow-y-auto hx-overflow-x-hidden hx-p-4 hx-grow md:hx-h-[calc(100vh-var(--navbar-height)-var(--menu-height))]">
    <ul class="hx-flex hx-flex-col hx-gap-1 md:hx-hidden">
      
      
          <li class="open"><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/articles/"
    
  >articles
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a><div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col open"><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      sidebar-active-item hx-bg-primary-100 hx-font-semibold hx-text-primary-800 contrast-more:hx-border contrast-more:hx-border-primary-500 dark:hx-bg-primary-400/10 dark:hx-text-primary-600 contrast-more:dark:hx-border-primary-500"
    href="/articles/exploring-autonomous-llm-agents-for-capture-the-flag-problem-solving-using-context-engineering-rag-and-open-source-models/"
    
  >Exploring Autonomous LLM Agents for Capture The Flag problem solving using Prompt Engineering, RAG and Open Source LLMs
    </a>
  
    <ul class='hx-flex hx-flex-col hx-gap-1 hx-relative before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] dark:before:hx-bg-neutral-800 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-pr-3 rtl:before:hx-right-0 ltr:hx-ml-3 rtl:hx-mr-3'><li>
              <a
                href="#a-quick-introduction-on-llm-agents"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >A quick introduction on LLM Agents</a>
            </li>
          <li>
              <a
                href="#making-a-simple-interactive-tui-agent"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Making a simple interactive TUI Agent</a>
            </li>
          <li>
              <a
                href="#reviewing-previous-research"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Reviewing previous research</a>
            </li>
          <li>
              <a
                href="#developing-a-more-robust-agentic-solution-to-solve-ctf-challenges"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Developing a more robust Agentic solution to solve CTF challenges</a>
            </li>
          <li>
              <a
                href="#testing-improvements-on-a-new-benchmark"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Testing improvements on a new benchmark</a>
            </li>
          <li>
              <a
                href="#observability-and-operations"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Observability and Operations</a>
            </li>
          <li>
              <a
                href="#testing-improvements-in-a-live-ctf"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Testing improvements in a live CTF</a>
            </li>
          <li>
              <a
                href="#conclusion-and-research-outcomes"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Conclusion and research outcomes</a>
            </li>
          <li>
              <a
                href="#appendix"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Appendix</a>
            </li>
          </ul>
  
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/articles/isp-default-wifi-passwords-are-costlier-to-keep-than-to-crack-value-optimised-cloud-gpu-password-cracking/"
    
  >ISP Default WiFi Passwords Are Costlier to Keep Than to Crack (Value optimised Cloud GPU password cracking)
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/articles/creating-a-havoc-module-to-run-commands-on-all-agents-at-once-and-map-out-an-environment-passively/"
    
  >Creating a Havoc Module to run commands on all agents at once and map out an environment passively
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/articles/replicating-cobalt-strikes-port-scanner-as-a-bof-for-open-source-c2-frameworks/"
    
  >Replicating Cobalt Strike&#39;s Port Scanner BOF for Open-Source C2 | Fast OPSEC-Aware Ping &amp; TCP Connect Scanning in C
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/articles/osep-exam-review/"
    
  >OffSec Experienced Penetration Tester (OSEP) Exam Review
    </a>
              
            </li></ul>
      </div></li>
          <li class=""><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/minis/"
    
  >minis
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a><div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/minis/reverse-engineering-onemillionchessboards.com-frontend-with-chrome-devtools-to-build-a-bot/"
    
  >Reverse Engineering onemillionchessboards.com Frontend with DevTools to Build a Bot
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/minis/building-a-flask-blog-with-ai-coding-tools-using-cline-mcp-servers-in-vscode/"
    
  >Building a Flask Blog in 3 prompts with AI Coding Tools: Using Cline &amp; MCP Servers in VSCode
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/minis/leveraging-ai-to-automate-seo-metadata-generation-for-web-content/"
    
  >Leveraging AI to Automate SEO Metadata Generation for Web Content
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/minis/ai-overthinking-more-than-me-with-insomnia-at-3-am/"
    
  >AI overthinking more than me with insomnia at 3 am
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/minis/creating-lightweight-windows-virtual-machines-for-your-personal-lab-environment/"
    
  >Creating Lightweight Windows Virtual Machines for your Personal Lab Environment
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/minis/create-infinite-email-aliases-using-cloudflare-email-routing/"
    
  >Create Infinite Email aliases using Cloudflare Email Routing
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/minis/improving-functionality-of-open-source-bofs/"
    
  >Improving functionality of Open Source BOFs
    </a>
              
            </li></ul>
      </div></li>
          <li class=""><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/"
    
  >bazaar
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a><div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col open"><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/"
    
  >Windows
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a>
              <div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col open"><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/active-directory/"
    
  >Active Directory
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a>
              <div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/active-directory/lateral-movement/"
    
  >Lateral Movement
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/active-directory/ad-enumeration/"
    
  >AD Enumeration
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/active-directory/mssql/"
    
  >MSSQL
    </a>
              
            </li></ul>
      </div>
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/privilege-escalation/"
    
  >Privilege Escalation
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/post-exploitation--looting/"
    
  >Post Exploitation &amp; Looting
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/defence-evasion/"
    
  >Defence Evasion
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/misc-snippets/"
    
  >Misc Snippets
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/forensics/"
    
  >Forensics
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/windows/outlook-exchange-server/"
    
  >Outlook Exchange Server
    </a>
              
            </li></ul>
      </div>
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/linux/"
    
  >Linux
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a>
              <div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/linux/other-commands/"
    
  >Other Commands
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/linux/reverse-shells/"
    
  >Reverse Shells
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/linux/system-hardening/"
    
  >System Hardening
    </a>
              
            </li></ul>
      </div>
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/phishing/"
    
  >Phishing
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/web-exploitation/"
    
  >Web Exploitation
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a>
              <div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/web-exploitation/php/"
    
  >PHP
    </a>
              
            </li></ul>
      </div>
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/c2-and-red-team-tools/"
    
  >C2 and Red Team Tools
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a>
              <div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/c2-and-red-team-tools/havoc/"
    
  >Havoc
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/c2-and-red-team-tools/malware-droppers/"
    
  >Malware Droppers
    </a>
              
            </li></ul>
      </div>
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/other-cheatsheets/"
    
  >&#43;&#43; cyber cheatsheets
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/ai/"
    
  >Ai
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a>
              <div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/ai/inference-providers/"
    
  >Inference Providers
    </a>
              
            </li></ul>
      </div>
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/"
    
  >Computer Science &amp; Programming
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a>
              <div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/ai-tools/"
    
  >Ai Tools
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/dependency-visualisation/"
    
  >Dependency Visualisation
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/docker/"
    
  >Docker
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/file-synchronisation/"
    
  >File Synchronisation
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/git/"
    
  >Git
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/image-modifications/"
    
  >Image Modifications
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/latex/"
    
  >Latex
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/orchestration-workflows/"
    
  >Orchestration (Workflows)
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/versioning/"
    
  >Versioning
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/web-dev-cheatsheet/"
    
  >Web Dev Cheatsheet
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/computer-science--programming/web-proxies/"
    
  >Web Proxies
    </a>
              
            </li></ul>
      </div>
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/wifi/"
    
  >Wifi
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/other/"
    
  >Other
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a>
              <div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/other/networking/"
    
  >Networking
    </a>
              
            </li><li class="hx-flex hx-flex-col "><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/bazaar/other/password-cracking/"
    
  >Password Cracking
    </a>
              
            </li></ul>
      </div>
            </li></ul>
      </div></li>
      <li class="[word-break:break-word] hx-mt-5 hx-mb-2 hx-px-2 hx-py-1.5 hx-text-sm hx-font-semibold hx-text-gray-900 first:hx-mt-0 dark:hx-text-gray-100">
        <span class="hx-cursor-default">Bottom text</span>
      </li>
    
      <li><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="http://blinking.dog"
    target="_blank" rel="noreferrer"
  >🦧</a></li>
    
    </ul>

    </div>
  
  
    <div class="md:hx-hidden  hx-sticky hx-bottom-0 hx-bg-white dark:hx-bg-dark hx-mx-4 hx-py-4 hx-shadow-[0_-12px_16px_#fff] hx-flex hx-items-center hx-gap-2 dark:hx-border-neutral-800 dark:hx-shadow-[0_-12px_16px_#111] contrast-more:hx-border-neutral-400 contrast-more:hx-shadow-none contrast-more:dark:hx-shadow-none hx-border-t" data-toggle-animation="show"><div class="hx-flex hx-grow hx-flex-col"><button
  title="Change theme"
  data-theme="light"
  class="theme-toggle hx-group hx-h-7 hx-rounded-md hx-px-2 hx-text-left hx-text-xs hx-font-medium hx-text-gray-600 hx-transition-colors dark:hx-text-gray-400 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50"
  type="button"
  aria-label="Change theme"
>
  <div class="hx-flex hx-items-center hx-gap-2 hx-capitalize"><svg height=12 class="group-data-[theme=light]:hx-hidden" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><span class="group-data-[theme=light]:hx-hidden">Light</span><svg height=12 class="group-data-[theme=dark]:hx-hidden" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z"/></svg><span class="group-data-[theme=dark]:hx-hidden">Dark</span></div>
</button>
</div></div></aside>
    
<nav class="hextra-toc hx-order-last hx-hidden hx-w-64 hx-shrink-0 xl:hx-block print:hx-hidden hx-px-4" aria-label="table of contents">
    <div class="hextra-scrollbar hx-sticky hx-top-16 hx-overflow-y-auto hx-pr-4 hx-pt-6 hx-text-sm [hyphens:auto] hx-max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] ltr:hx--mr-4 rtl:hx--ml-4"><p class="hx-mb-4 hx-font-semibold hx-tracking-tight">On this page</p><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#a-quick-introduction-on-llm-agents">A quick introduction on LLM Agents
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#what-are-llm-agents">What are LLM Agents
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#whats-so-special-about-gpt-5">What’s so special about GPT-5?
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#improving-agents-using-context-engineering-and-prompting-techniques">Improving Agents using Context Engineering and Prompting Techniques
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-8 rtl:hx-pr-8 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#chain-of-thought-cot">Chain-of-Thought (CoT)
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-8 rtl:hx-pr-8 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#planning">Planning
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-8 rtl:hx-pr-8 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#react">ReAct
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-8 rtl:hx-pr-8 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#prompt-chaining">Prompt Chaining
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-8 rtl:hx-pr-8 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#retrieval-augmented-generation-rag">Retrieval Augmented Generation (RAG)
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-8 rtl:hx-pr-8 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#structured-output">Structured Output
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#making-a-simple-interactive-tui-agent">Making a simple interactive TUI Agent
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#reviewing-previous-research">Reviewing previous research
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#developing-a-more-robust-agentic-solution-to-solve-ctf-challenges">Developing a more robust Agentic solution to solve CTF challenges
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#benchmark-comparison-post-rewrite">Benchmark comparison post-rewrite
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#retrieval-augmented-generation-rag-1">Retrieval Augmented Generation (RAG)
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-8 rtl:hx-pr-8 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#enhancing-capabilities-by-introducing-tools-rsactftool-for-crypto-challenges">Enhancing capabilities by introducing tools: RsaCTFTool for crypto challenges
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-8 rtl:hx-pr-8 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#reducing-step-count-by-giving-command-examples-recursive-binwalk">Reducing step count by giving command examples: recursive binwalk
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-8 rtl:hx-pr-8 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#adding-rag-to-our-agent-system">Adding RAG to our Agent system
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-8 rtl:hx-pr-8 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#limitations-of-rag">Limitations of RAG
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-12 rtl:hx-pr-12 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#rag-vs-finetuning">RAG vs Finetuning
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#testing-improvements-on-a-new-benchmark">Testing improvements on a new benchmark
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#why-do-we-even-need-a-new-benchmark">Why do we even need a new benchmark?
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#creating-a-new-benchmarks">Creating a new benchmarks
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#comparing-agents-on-the-new-benchmark">Comparing Agents on the new benchmark
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#observability-and-operations">Observability and Operations
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#testing-improvements-in-a-live-ctf">Testing improvements in a live CTF
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#conclusion-and-research-outcomes">Conclusion and research outcomes
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#research-outcome">Research Outcome
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#the-future-of-ctfs">The future of CTFs
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#future-research-and-tool-improvements">Future research and tool improvements
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#appendix">Appendix
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#using-vision-language-models-to-help-solve-ctf-challenges">Using Vision Language Models to help solve CTF challenges
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#topping-the-leaderboards">Topping the leaderboards
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#plain-llm-agents">Plain LLM Agents
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#additional-references">Additional References
        </a>
      </li></ul>
      <div class="hx-mt-8 hx-border-t hx-bg-white hx-pt-8 hx-shadow-[0_-12px_16px_white] dark:hx-bg-dark dark:hx-shadow-[0_-12px_16px_#111] hx-sticky hx-bottom-0 hx-flex hx-flex-col hx-items-start hx-gap-2 hx-pb-8 dark:hx-border-neutral-800 contrast-more:hx-border-t contrast-more:hx-border-neutral-400 contrast-more:hx-shadow-none contrast-more:dark:hx-border-neutral-400">
        <button aria-hidden="true" id="backToTop" onClick="scrollUp();" class="hx-transition-all hx-duration-75 hx-opacity-0 hx-text-xs hx-font-medium hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-100 contrast-more:hx-text-gray-800 contrast-more:dark:hx-text-gray-50">
          <span>Scroll to top</span>
          <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="hx-inline ltr:hx-ml-1 rtl:hx-mr-1 hx-h-3.5 hx-w-3.5 hx-border hx-rounded-full hx-border-gray-500 hover:hx-border-gray-900 dark:hx-border-gray-400 dark:hover:hx-border-gray-100 contrast-more:hx-border-gray-800 contrast-more:dark:hx-border-gray-50">
            <path stroke-linecap="round" stroke-linejoin="round" d="M4.5 15.75l7.5-7.5 7.5 7.5" />
          </svg>
        </button>
      </div>
    </div>
  </nav>


    <article class="hx-w-full hx-break-words hx-flex hx-min-h-[calc(100vh-var(--navbar-height))] hx-min-w-0 hx-justify-center hx-pb-8 hx-pr-[calc(env(safe-area-inset-right)-1.5rem)]">
        
      <main class="hx-w-full hx-min-w-0 hx-max-w-6xl hx-pt-4">
        
  <div class="hx-mt-1.5 hx-flex hx-items-center hx-gap-1 hx-overflow-hidden hx-text-sm hx-text-gray-500 dark:hx-text-gray-400 contrast-more:hx-text-current">
        <div class="hx-whitespace-nowrap hx-transition-colors hx-min-w-[24px] hx-overflow-hidden hx-text-ellipsis hover:hx-text-gray-900 dark:hover:hx-text-gray-100">
          <a href="/articles/">articles</a>
        </div><svg class="hx-w-3.5 hx-shrink-0 rtl:-hx-rotate-180" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M9 5l7 7-7 7"/></svg><div class="hx-whitespace-nowrap hx-transition-colors hx-font-medium hx-text-gray-700 contrast-more:hx-font-bold contrast-more:hx-text-current dark:hx-text-gray-100 contrast-more:dark:hx-text-current">Exploring Autonomous LLM Agents for Capture The Flag problem solving using Prompt Engineering, RAG and Open Source LLMs</div>
  </div>

        <h1 class="hx-mt-2 hx-text-4xl hx-font-bold hx-tracking-tight hx-text-slate-900 dark:hx-text-slate-100">Exploring Autonomous LLM Agents for Capture The Flag problem solving using Prompt Engineering, RAG and Open Source LLMs</h1>
            
        <div class="hx-mt-4 hx-mb-4 hx-text-gray-500 hx-text-sm hx-flex hx-items-center hx-flex-wrap hx-gap-y-2"><span class="hx-mr-1">August 28, 2025</span><span class="hx-mx-1">·</span><a
                  href="https://fyx.me/articles" target="_blank"
                  class="hx-group hx-inline-flex hx-items-center hx-text-current hx-gap-x-1.5 hx-mx-1"
                  title="fyx(me)"
                ><img src="https://fyx.me/favicon.ico" alt="fyx(me)" class="hx-inline-block hx-h-4 hx-w-4 hx-rounded-full" loading="lazy" />
                  <div class="group-hover:hx-underline">fyx(me)</div>
                </a></div>
        <div class="content">
          <p>
    <img src="../img/flagseeker-no-font.webp" alt="" loading="lazy" /></p>
<details class="last-of-type:hx-mb-0 hx-rounded-lg hx-bg-neutral-50 dark:hx-bg-neutral-800 hx-p-2 hx-mt-4 hx-group" >
  <summary class="hx-flex hx-items-center hx-cursor-pointer hx-select-none hx-list-none hx-p-1 hx-rounded hx-transition-colors hover:hx-bg-gray-100 dark:hover:hx-bg-neutral-800 before:hx-mr-1 before:hx-inline-block before:hx-transition-transform before:hx-content-[''] dark:before:hx-invert rtl:before:hx-rotate-180 group-open:before:hx-rotate-90">
    <strong class="hx-text-lg">TLDR</strong>
  </summary>
  <div class="hx-p-2 hx-overflow-hidden">
    <blockquote>
  <p>Tested LLMs against CTF tasks and developed my own AI Plain Agent to solve CTF challenges using context engineering and RAG to increase solve rate with open source models. Released a modular tool called <a href="https://github.com/fyxme/flagseeker" target="_blank" rel="noopener">Flagseeker</a> which is an AI Plain Agent library developed to test AI Agentic abilities at solving CTF Cybersecurity challenges. Used it against live CTF events and had success solving various challenges.
<br/><br/>
If you already know about AI, LLMs and Agents and simply want to skip the theory parts, I recommend the following sections:</p>
<ul>
<li><a href="#making-a-simple-interactive-tui-agent" >Making an interactive TUI Agent</a>: basically v0 of Flagseeker and what started it all.</li>
<li><a href="#developing-a-more-robust-agentic-solution-to-solve-ctf-challenges" >Developing a more robust Agentic solution to solve CTF challenges</a>: making an autonomous agent system using ideas from previous research; increasing stability, speed and observability</li>
<li><a href="#retrieval-augmented-generation-rag-1" >Retrieval Augmented Generation (RAG)</a>: showcasing RAG capabilities with CTF challenges and enhancing our agent&rsquo;s capabilities by using RAG to retrieve tools relevant to specific challenges.</li>
<li><a href="#using-vision-language-models-to-help-solve-ctf-challenges" >Using Vision Language Models to help solve CTF challenges</a>: Exploring Vision Language Models to help solve image related challenges or extract text/information from images.</li>
</ul>
</blockquote>
  </div>
</details>
<p>Capture The Flag (CTF) challenges are a great way to improve your offensive security skill set and test new tools in controlled environments.  Only issue is once you&rsquo;ve done the same stego challenge a million times, it can get boring and repetitive&hellip; What if we could leverage LLMs to help us solve these simple challenges and potentially highly attack paths, or even solve harder challenges?</p>
<p>A quick summary of CTF events: CTFs are basically hacking competitions where teams and/or individuals compete in a controlled environment where they are tasked with a number of challenges in different security categories and their goal is to solve the challenge and retrieve a &ldquo;flag&rdquo; (ie. a string that is usually easy to identify and usually follows a given format, eg.  <code>flag{this_challenge_was_easy}</code>) . These event are a great way to test your skills and learn new things which can sometimes be applied to real world scenarios but will teach you to always try harder.</p>
<p>Recently, there&rsquo;s been a few papers and articles coming out from different research teams and organisations highlighting the potential of using Large Language Models (LLMs) and LLM Agents in CTF events:</p>
<ul>
<li>Anthropic recently released their <a href="red.anthropic.com" >red.anthropic.com</a> blog which highlights <a href="https://red.anthropic.com/2025/cyber-competitions/" target="_blank" rel="noopener">Claude&rsquo;s capabilities in CTF competitions</a> showcasing that LLMs can solve simple-medium CTF challenges, however they still struggle on harder challenges (eg. 0 challenges solved for Plaid CTF and DEF CON CTF Qualifier). They presented their research at DEF CON 33 which you can see <a href="https://www.youtube.com/watch?v=sbkeEwhWIks" target="_blank" rel="noopener">here</a>.</li>
<li>A number of research studies have been published showcasing LLM&rsquo;s abilities in solving CTF challenges as well as improvements when crafting specific Prompt and using LLM Agents to improve capabilities and solve harder challenges. As part of this blog, I&rsquo;m going to focus on a specific paper which has achieved great results using Prompt Engineering; combining a number of prompting techniques to create more powerful Agents. You can read their research paper <a href="https://arxiv.org/abs/2412.02776" target="_blank" rel="noopener">here</a> and access their code <a href="https://github.com/PalisadeResearch/intercode" target="_blank" rel="noopener">here</a></li>
<li><a href="https://aicyberchallenge.com/" target="_blank" rel="noopener">AIxCC</a> a 2 year competition where teams were tasked to find and fix vulnerabilities in Open Source applications by leveraging Artificial Intelligence completed recently and every competing team had to release their code. This provided an insight into leveraging LLMs to solve cybersecurity issues at scale. Highly recommend spending the time into reading some of the articles of different teams. I suggest starting with <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/" target="_blank" rel="noopener">Trail of Bits</a> article on the topic.</li>
<li>Earlier this month, <a href="https://x.com/cl4sm" target="_blank" rel="noopener">wilgibbs</a> released a blog about using open AI&rsquo;s GPT-5 model to solve one of the challenges in the DEF CON CTF finals. DEF CON CTF is regarded as one of the hardest CTF competitions that runs every year and having an LLM solve one of the challenges highlighted the AI technological improvements that we&rsquo;ve seen recently. You can read his blog post <a href="https://wilgibbs.com/blog/defcon-finals-mcp/" target="_blank" rel="noopener">here</a>.</li>
</ul>
<p>That&rsquo;s a lot of research to explore but after reading so many articles I wanted to also get my hands dirty and see what I could come up with. When I started looking into it, I wanted to set myself a number of goals:</p>
<ul>
<li>I wanted to focus on Open Source LLM agents and see how far they can be pushed to solve complex problems like CTF challenges. Closed Source LLMs are great but as LLMs providers become more like LLM Agents (I&rsquo;ll explain what I mean with in the &ldquo;What&rsquo;s so special about GPT-5?&rdquo; section below), we start wondering how much improvement is coming from the LLM itself vs Agentic improvements. Furthermore, for privacy reasons, companies might want to run their own LLMs instead of sending all their internal information and code to 3rd parties like Open AI.</li>
<li>I wanted to attempt to use smaller but more specialised LLMs, for example using a 12B parameters LLM that focuses on only solving Cryptography challenges</li>
<li>Ensure the Agent is fully autonomous such that the agent receives no user interaction (apart from starting the agent).</li>
<li>Improve the capabilities of smaller agents by leveraging RAG and/or fine tuning</li>
</ul>
<h2>A quick introduction on LLM Agents<span class="hx-absolute -hx-mt-20" id="a-quick-introduction-on-llm-agents"></span>
    <a href="#a-quick-introduction-on-llm-agents" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><h3>What are LLM Agents<span class="hx-absolute -hx-mt-20" id="what-are-llm-agents"></span>
    <a href="#what-are-llm-agents" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><blockquote>
  <p>An agent is an LLM-powered system designed to take actions and solve complex tasks autonomously. Unlike traditional LLMs, AI agents go beyond simple text generation. They are equipped with additional capabilities, including:</p>
<ul>
<li><strong>Planning and reflection:</strong> AI agents can analyze a problem, break it down into steps, and adjust their approach based on new information.</li>
<li><strong>Tool access:</strong> They can interact with external tools and resources, such as databases, APIs, and software applications, to gather information and execute actions.</li>
<li><strong>Memory:</strong> AI agents can store and retrieve information, allowing them to learn from past experiences and make more informed decisions.
<em>ref: <a href="https://www.promptingguide.ai/agents/introduction" target="_blank" rel="noopener">https://www.promptingguide.ai/agents/introduction</a></em></li>
</ul>

</blockquote>
<blockquote>
  <p>Agents represent <strong>systems that intelligently accomplish tasks</strong>, ranging from executing simple workflows to pursuing complex, open-ended objectives.
<em>OpenAI</em></p>

</blockquote>
<p>One of the main selling points of Agents is that you can leverage them to perform more advanced tasks by giving them access to tools, guiding them to provide <a href="https://platform.openai.com/docs/guides/structured-outputs" target="_blank" rel="noopener">structured</a> answers (eg. respond with the following JSON template) and chain tasks/sub-tasks until they solve your problem. CTF challenges can be quite complex and usually require multiple actions/tools in order to solve. Hence, they&rsquo;re a great testcase for exploring LLM Agents and pushing its boundaries.</p>
<p>If you want to learn more about agents, I highly recommend looking at <a href="https://platform.openai.com/docs/guides/agents" target="_blank" rel="noopener">OpenAI&rsquo;s guide on building agents</a> .</p>
<h3>What&rsquo;s so special about GPT-5?<span class="hx-absolute -hx-mt-20" id="whats-so-special-about-gpt-5"></span>
    <a href="#whats-so-special-about-gpt-5" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>If you&rsquo;ve played around with GPT-5 (especially its &ldquo;Thinking&rdquo; version), you might have realised how good it is at breaking tasks into sub-tasks until it solves your query. It also has access to tools which can be executed during any sub task. In the past, &ldquo;thinking&rdquo; traces appeared to be continuous and limited in their capabilities but with the release of GPT-5 the &ldquo;Thinking&rdquo; traces appear to be <em>somewhat</em> limitless, continuing until they solve your task. If you&rsquo;ve played around with LLM agents before, you might have realised that this sounds very similar to some of the techniques used to augment LLM capabilities, namely:</p>
<ul>
<li><a href="https://www.promptingguide.ai/techniques/cot" target="_blank" rel="noopener">chain-of-thought</a> process / <a href="https://www.promptingguide.ai/techniques/react" target="_blank" rel="noopener">ReAct Prompting</a></li>
<li>embedded <a href="https://www.promptingguide.ai/techniques/prompt_chaining" target="_blank" rel="noopener">prompt-chaining</a></li>
</ul>
<p><em>I explain some of these techniques in a later section: &ldquo;Improving Agents using Context Engineering and Prompting Techniques&rdquo;</em></p>
<p>Take for example, the following chat showing GPT-5 attempting a networking CTF Challenge from <a href="https://247ctf.com" target="_blank" rel="noopener">247CTF.com</a>. You can see it mapping out intermediate steps, trying out different tools and techniques before giving a final answer. The answer is wrong (hence why I&rsquo;m showing it here) but the way it moves between sub-tasks is very interesting and very thoughtful, using python builtin libraries to parse the packet capture (pcap) file embed in the zip file:</p>
<p>
    <img src="../img/Pasted%20image%2020250903113921.webp" alt="" loading="lazy" /></p>
<p>
    <img src="../img/Pasted%20image%2020250903132519.webp" alt="" loading="lazy" /></p>
<p>
    <img src="../img/Pasted%20image%2020250903132300.webp" alt="" loading="lazy" /></p>
<p>After playing around and reading about GPT-5 a lot, I speculate that there are actually not many direct LLM improvements (ie. data/learning improvements) but instead they trained the model to be more <em>agentic</em> and improved the agent&rsquo;s flow by leveraging recent prompting techniques (ie. Chain-of-Thought, ReAct, Prompt-Chaining), which I&rsquo;ll explain in the next section.</p>
<p><strong>With that in mind, this means that you may potentially be able to replicate or at least improve other models by incorporating them into similar agent systems.</strong> This is one of the reasons that I&rsquo;m excited to try using Open Source LLMs (especially smaller ones) to see if they can be tuned to perform on par with GPT-5 and other large language models at specialised tasks like solving CTF challenges.</p>
<p>If you want to read more about GPT-5 specifically, I recommend the following articles:</p>
<ul>
<li><a href="https://openai.com/index/introducing-gpt-5/" target="_blank" rel="noopener">https://openai.com/index/introducing-gpt-5/</a></li>
<li><a href="https://botpress.com/blog/everything-you-should-know-about-gpt-5" target="_blank" rel="noopener">https://botpress.com/blog/everything-you-should-know-about-gpt-5</a></li>
<li><a href="https://github.com/elder-plinius/CL4R1T4S/blob/main/OPENAI/ChatGPT5-08-07-2025.mkd" target="_blank" rel="noopener">https://github.com/elder-plinius/CL4R1T4S/blob/main/OPENAI/ChatGPT5-08-07-2025.mkd</a></li>
<li><a href="https://fi-le.net/oss/" target="_blank" rel="noopener">https://fi-le.net/oss/</a></li>
</ul>
<h3>Improving Agents using Context Engineering and Prompting Techniques<span class="hx-absolute -hx-mt-20" id="improving-agents-using-context-engineering-and-prompting-techniques"></span>
    <a href="#improving-agents-using-context-engineering-and-prompting-techniques" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><div class="hx-overflow-x-auto hx-mt-6 hx-flex hx-flex-col hx-rounded-lg hx-border hx-py-4 hx-px-4 contrast-more:hx-border-current contrast-more:dark:hx-border-current hx-border-orange-100 hx-bg-orange-50 hx-text-orange-800 dark:hx-border-orange-400/30 dark:hx-bg-orange-400/20 dark:hx-text-orange-300">
  <p class="hx-flex hx-items-center hx-font-medium">Info</p>

  <div class="hx-w-full hx-min-w-0 hx-leading-7">
    <div class="hx-mt-6 hx-leading-7 first:hx-mt-0"><p>If you already know about context engineering and prompting techniques, I recommend you skip to the next section <em>Making a simple interactive TUI Agent</em>.</p>
</div>
  </div>
</div>
<p>A number of researchers have published techniques and prompting strategies that can be leveraged to enhance responses from AI agents. Using these enhancements allows LLMs to solve more complex challenges, more consistently and/or with fewer steps. They provide a great toolkit to builder who want to tackle more complex problems.</p>
<p><a href="https://www.promptingguide.ai/guides/context-engineering-guide" target="_blank" rel="noopener">Context Engineering</a> is a newer term which has started replacing prompt engineering as Agents have evolved to incorporate more than just better prompting. Its a more encompassing term which now includes things like Retrieval Augmented Generation (RAG) to add contextual information to chats, Structured Output to standardise the LLMs response into more predictable formats (ie. JSON) and keeping Memory of past events or actions to adapt LLM responses.</p>
<p>I&rsquo;ll introduce a number of context engineering techniques which are discussed in this article and used by the Agent released alongside it.</p>
<h4>Chain-of-Thought (CoT)<span class="hx-absolute -hx-mt-20" id="chain-of-thought-cot"></span>
    <a href="#chain-of-thought-cot" class="subheading-anchor" aria-label="Permalink for this section"></a></h4><p>Chain-of-Thought sounds complicated but its actually very simple. The idea is basically to split a task into smaller (more manageable steps). To do this with LLMs, you basically ask them about the first step to solve a problem, then the second step and the next step, and so on until the problem is solved.  Newer models who have &ldquo;Thinking&rdquo; abilities, can attempt to do Chain-of-Thought directly. However, its harder to manage then simply asking about one step at a time since the model is free to &ldquo;think&rdquo; and might get sidetracked quickly, hallucinate or end up in rabbit holes (error propagation).</p>
<p>As such, its easier to keep on querying the model for a single thought and then querying it again for the next thought while providing the previous thought. It allows us to manage the context we&rsquo;re giving the model. We can provide less context such that it doesn&rsquo;t overwhelm the model with information as research has shown that the more information (ie. context) you provide, the easier it is for the model to hallucinate, forget information and co.</p>
<p>Here&rsquo;s a quick example of what Chain-of-Thought might look like in code:</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">system_prompt</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">You are tasked with providing technical guidance, helping users install Arch Linux. 
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">Think step by step and only provide one step at a time. I will provide a list of steps we have taken so far, only give me the next step or command I need to do. 
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">If you believe we are done, only reply with &#34;INSTALLATION COMPLETED!&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">done_trigger</span> <span class="o">=</span> <span class="s2">&#34;INSTALLATION COMPLETED!&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">installation_succeeded</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">steps_performed</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Maximum number of steps as fallback</span>
</span></span><span class="line"><span class="cl"><span class="c1"># in case we don&#39;t succeed in installing Arch Linux</span>
</span></span><span class="line"><span class="cl"><span class="n">max_steps</span> <span class="o">=</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;&#34;</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="c1"># Add the step history to our query so the Model knows where we&#39;re at</span>
</span></span><span class="line"><span class="cl">	<span class="c1"># and can think about the next step after this</span>
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="n">steps_performed</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;Here are the steps I have performed:</span><span class="se">\n</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">		<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">steps_performed</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">			<span class="c1"># Note: We could decided to truncate the step description </span>
</span></span><span class="line"><span class="cl">			<span class="c1"># as it might contain a lot of information and we only want a short summary</span>
</span></span><span class="line"><span class="cl">			<span class="n">query</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&#34;step </span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="se">\n</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="n">query</span> <span class="o">+=</span> <span class="s2">&#34;What is my next step?&#34;</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">	    <span class="n">model</span><span class="o">=</span><span class="s2">&#34;gpt-4o-2024-08-06&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	    <span class="nb">input</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">	        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">	        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">query</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">	    <span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="p">)</span>
</span></span><span class="line"><span class="cl">		
</span></span><span class="line"><span class="cl">	<span class="n">next_step</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">output_text</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">trim</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="c1"># The LLM thinks we&#39;re done</span>
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="n">next_step</span> <span class="o">==</span> <span class="n">done_trigger</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="n">installation_succeeded</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">		<span class="k">break</span>
</span></span><span class="line"><span class="cl">		
</span></span><span class="line"><span class="cl">	<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Here&#39;s our next step: </span><span class="si">{</span><span class="n">next_step</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="c1"># ... You could add code here to tell the model if you&#39;re running into issues with this steps</span>
</span></span><span class="line"><span class="cl">	<span class="c1"># and provide some context such that the model tries to help you solve your issues </span>
</span></span><span class="line"><span class="cl">	<span class="c1"># before moving on to the next step</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="c1"># Adding step to steps performed </span>
</span></span><span class="line"><span class="cl">	<span class="n">steps_performed</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_step</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Installation succeeded: </span><span class="si">{</span><span class="n">installation_succeeded</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<h4>Planning<span class="hx-absolute -hx-mt-20" id="planning"></span>
    <a href="#planning" class="subheading-anchor" aria-label="Permalink for this section"></a></h4><p>Planning simply involves asking the model to generate a plan instead of provide a description or single step. This does not seem super useful on its own since LLMs are trained to do this by default. However, when you are combining different agents for different tasks, it becomes a lot more interesting as you can use stronger models for planning, request agents to write plans for next few steps so they don&rsquo;t get sidetracked and more.</p>
<p>Here&rsquo;s a super basic example, which doesn&rsquo;t add much value on its own:</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">system_prompt</span> <span class="o">=</span> <span class="s2">&#34;You are tasked with providing technical guidance. When a user has a request, give the user a plan of all steps needed to solve his issue.&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;I&#39;m trying to install Arch Linux on this new computer, how do I do it?&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">	<span class="n">model</span><span class="o">=</span><span class="s2">&#34;gpt-4o-2024-08-06&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="nb">input</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">		<span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">		<span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">query</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">output_text</span><span class="p">)</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<h4>ReAct<span class="hx-absolute -hx-mt-20" id="react"></span>
    <a href="#react" class="subheading-anchor" aria-label="Permalink for this section"></a></h4><p>ReAct is a general approach that couples an LLM’s reasoning with concrete actions. By prompting the model to produce both intermediate reasoning traces and action steps, the system can plan, revise, and execute tasks dynamically, while also consulting external sources (eg. using web search tools) to bring in new information and refine its reasoning.</p>
<p>The best way to explain ReAct prompting is to look at the example provided in the research article which introduce the idea (<a href="https://arxiv.org/abs/2210.03629" target="_blank" rel="noopener">Yao et al., 2022</a>). For this example, they asked the following question:  &ldquo;What other devices, apart from the Apple Remote, can control the program originally intended for the Apple Remote?&rdquo; and provided context to the model (ie. <code>Thought</code>, <code>Action</code> and <code>Observation</code>) which helped the model perform step by step analysis and enhance its response based on the information it retrieved from its actions (ie. <code>tools</code>):</p>
<p>
    <img src="../img/Pasted%20image%2020250917203141.webp" alt="" loading="lazy" /></p>
<p>If you want to read more on the topic I recommend reading the <a href="https://arxiv.org/abs/2210.03629" target="_blank" rel="noopener">article itself</a> or a quick rundown <a href="https://www.promptingguide.ai/techniques/react" target="_blank" rel="noopener">here</a>.</p>
<h4>Prompt Chaining<span class="hx-absolute -hx-mt-20" id="prompt-chaining"></span>
    <a href="#prompt-chaining" class="subheading-anchor" aria-label="Permalink for this section"></a></h4><p>Prompt chaining refers to basically using different prompts to perform different actions. Our first prompt could be to request a plan from a model and then we create a second request that asks the same or another model to create an action from that plan (ie. combine our planning technique with another model that provides actions).</p>
<p>Splitting the prompts this way also helps with keeping context small, testing different models for different steps and limiting models to a single action per query instead of letting them go rogue (ie. easier to manage).</p>
<h4>Retrieval Augmented Generation (RAG)<span class="hx-absolute -hx-mt-20" id="retrieval-augmented-generation-rag"></span>
    <a href="#retrieval-augmented-generation-rag" class="subheading-anchor" aria-label="Permalink for this section"></a></h4><p>Retrieval Augmented Generation (RAG) is a method used to provide additional context to a model by search for information relevant to the task from a database/set of documents.</p>
<blockquote>
  <p>RAG takes an input and retrieves a set of relevant/supporting documents given a source (e.g., Wikipedia). The documents are concatenated as context with the original input prompt and fed to the text generator which produces the final output. This makes RAG adaptive for situations where facts could evolve over time. This is very useful as LLMs&rsquo;s parametric knowledge is static. RAG allows language models to bypass retraining, enabling access to the latest information for generating reliable outputs via retrieval-based generation.
ref: <a href="https://www.promptingguide.ai/techniques/rag" target="_blank" rel="noopener">https://www.promptingguide.ai/techniques/rag</a></p>

</blockquote>
<p>For CTFs, there are a lot of tools and terminal commands that you need to know about and a lot of the time you&rsquo;ll have to research or look at examples to understand how to run the tools. If we&rsquo;re able to provide these tools, use-cases and examples, the model can make use of those tools and might be more likely to solve the challenge. <strong>Provided that we give the correct tools and information in our query, which is easier said then done&hellip;</strong></p>
<p>There are two main steps in RAG:</p>
<ol>
<li><strong>Retrieval:</strong> retrieve relevant information from a knowledge base</li>
<li><strong>Generation:</strong> insert the relevant information to the prompt for the LLM to generate information</li>
</ol>
<p>However, the retrieval part can be a little complicated and requires some preparation. You can&rsquo;t simply provide everything you have to a model unless your knowledge base is small and/or the model&rsquo;s context limit it high. To solve this, most RAG systems will store their database in text embeddings stored in a vector store database. Text embeddings are numerical vectors that represent pieces of text (words, sentences, docs) so that similar meanings have vectors that are close together. Vector stores are simply special databases optimised for vector similarity search (ie. find the vectors most similar to this other vector).</p>
<p>With this system, we can store our knowledge base in a special database as vectors and when we&rsquo;re looking for something we simply convert what we&rsquo;re looking for to a vector and search for similar vectors in the database.</p>
<p>Here&rsquo;s a quick rundown of how this would work step by step:</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<pre><code># Before requesting information from a model 
1. Create a knowledge base
2. Split that knowledge based into documents (ie. chunks of text) and create text embeddings for each document
3. Store those embeddings in a vector store database
   
# When querying for information
1. Request the topic/question/query from the user
2. Convert that query to text embedding(s) as before
3. Search your database for the most similar vectors
4. Send the user&#39;s query to an LLM alongside the documents with the most similar vectors to help the LLM respond to the user&#39;s query
5. Retrieve the LLM&#39;s response and provide it to the user</code></pre><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p>This sounds easy but in practice, there are many edge cases which might affect the effective of your RAG Agent such as:</p>
<ul>
<li>Noisy, outdated, or duplicated documents leading to bad answers</li>
<li>Chunking issues (eg. you have a knowledge base with bash commands but your chunks cut through those commands by mistake so you might have one part of a command in a chunk and one part in another)</li>
<li>Using different embedding models</li>
<li>Ambiguous queries (eg. &ldquo;what&rsquo;s the new policy?&rdquo; - New relative to when? What type of policy?)</li>
<li>Security issues like (indirect) prompt injection</li>
<li>and a lot more&hellip;..</li>
</ul>
<p>If you want to look at a basic RAG code example, I recommend looking at the <a href="https://github.com/mistralai/cookbook/blob/main/mistral/rag/basic_RAG.ipynb" target="_blank" rel="noopener">following Jupyter notebook by mistral.ai</a>.</p>
<h4>Structured Output<span class="hx-absolute -hx-mt-20" id="structured-output"></span>
    <a href="#structured-output" class="subheading-anchor" aria-label="Permalink for this section"></a></h4><blockquote>
  <p>JSON is one of the most widely used formats in the world for applications to exchange data.
Structured Outputs is a feature that ensures the model will always generate responses that adhere to your supplied <a href="https://json-schema.org/overview/what-is-jsonschema" target="_blank" rel="noopener">JSON Schema</a>, so you don&rsquo;t need to worry about the model omitting a required key, or hallucinating an invalid enum value.
<a href="https://platform.openai.com/docs/guides/structured-outputs" target="_blank" rel="noopener">~ OpenAI</a></p>

</blockquote>
<p>You basically give the model a format to follow, this will usually be a JSON schema. Some SDKs and inference providers support it directly so you don&rsquo;t need to write pure JSON but instead can do something like this.</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># This is the format I want the model to follow</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MovieResponseFormat</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">title</span><span class="p">:</span> <span class="nb">str</span>
</span></span><span class="line"><span class="cl">    <span class="n">rating</span><span class="p">:</span> <span class="nb">int</span>
</span></span><span class="line"><span class="cl">    <span class="n">actors</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">=</span><span class="s2">&#34;gpt-4o-2024-08-06&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="nb">input</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;You&#39;re a movie title expert. Provie Movie recommendations based on the user&#39;s preferences.&#34;</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">        <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;I like action and comedy movies&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">text_format</span><span class="o">=</span><span class="n">MovieResponseFormat</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># The parsed value will be a MovieTitle object</span>
</span></span><span class="line"><span class="cl"><span class="n">movie</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">output_parsed</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># And you can use it as such</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Suggested movie&#34;</span><span class="p">,</span> <span class="n">movie</span><span class="o">.</span><span class="n">title</span><span class="p">,</span> <span class="n">movie</span><span class="o">.</span><span class="n">actors</span><span class="p">)</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p>If you look at the API chat response, it should look something like this:</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&#34;title&#34;</span><span class="p">:</span> <span class="s2">&#34;My beautiful movie&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&#34;rating&#34;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&#34;actors&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;Jacob&#34;</span><span class="p">,</span> <span class="s2">&#34;Adam&#34;</span><span class="p">,</span> <span class="s2">&#34;Paul&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p><em>Something to note, older or smaller models might not always follow response format instructions and therefore might respond with invalid json or no json at all, potentially causing bugs or exceptions in your code.</em></p>
<h2>Making a simple interactive TUI Agent<span class="hx-absolute -hx-mt-20" id="making-a-simple-interactive-tui-agent"></span>
    <a href="#making-a-simple-interactive-tui-agent" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>Enough theory, lets get into the interesting stuff now and actually make an Agent and solve some CTF challenges.</p>
<p>My first iteration involved making a Terminal UI (TUI) Agent which supported tools that I could provide to the agent and chat with the agent directly and see the progress. I also wanted to have the ability to save each chat trace including tool calls and display it as a webpage so that I could see what tools were being called, the agent&rsquo;s thought process, my user input, etc&hellip; You can view the <a href="https://github.com/fyxme/flagseeker/tree/main/research/v0" target="_blank" rel="noopener">code here</a> (mostly vibe coded with <code>codex</code>).</p>
<p>To test the agent, I was using a CTF challenge from the awesome platform <a href="https://247ctf.com/" target="_blank" rel="noopener">247ctf.com</a>. The platform has a variety of challenges and is a great way to learn about new and interesting hacking topics. One of the challenges I was able to solved using the Agent was a web challenge called <em>Compare the pair</em>:</p>
<p>
    <img src="../img/Pasted%20image%2020250917204502.webp" alt="" loading="lazy" /></p>
<p>This challenge involves bypassing a weak authentication check in order to retrieve a flag (I&rsquo;m not going to spoil the solution in case someone wants to try it, otherwise you can just read the Agent&rsquo;s chat trace below):</p>
<p>
    <img src="../img/Pasted%20image%2020250917204702.webp" alt="" loading="lazy" /></p>
<p>Here is the prompt I used which resulted in the Agent solving the challenge. Notice that <strong>I explicitly asked</strong> to not execute any actions and make a plan instead but it decided otherwise and was able to solve the challenge:</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<pre><code>You are a ctf player, using the tools at your disposal solve the challenge. Request the challenge first and then make a plan of action. DO NOT EXECUTE any of the actions yet! When bruteforcing you can bruteforce up to the following number: 999999999. The challenge is: url: https://55affb983512588f.247ctf.com/ Can you identify a way to bypass our login logic? MD5 is supposed to be a one-way function right?. </code></pre><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p>
    <img src="../img/Pasted%20image%2020250915075848.webp" alt="" loading="lazy" /></p>
<p>
    <img src="../img/Pasted%20image%2020251007172652.webp" alt="" loading="lazy" /></p>
<p>My first attempt was quick and dirty and ran commands in my virtual machine. It didn&rsquo;t take long for models to start downloading and installing random tools&hellip; I learned my lesson quickly and move on to using a separate docker environment. You can find the docker contained MCP server I modified <a href="https://github.com/fyxme/mcp-file-server" target="_blank" rel="noopener">here</a>.</p>
<p>It was great to test out various tools and play around with writing better prompts. However, it required a lot of babysitting and re-prompting. After playing with it for a while, I wanted to move on to something more automated that leveraged more advanced techniques and hopefully had a better chance at solving challenges. More specifically, I wanted to use context engineering techniques and see if I could an automated agent able to solve advanced problems more consistently.</p>
<h2>Reviewing previous research<span class="hx-absolute -hx-mt-20" id="reviewing-previous-research"></span>
    <a href="#reviewing-previous-research" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>While researching the topic, I came across a multiple articles using benchmarks to test LLM and Agentic capabilities for solving CTF challenges. One of the newer articles on the topic comes from <a href="https://arxiv.org/abs/2412.02776" target="_blank" rel="noopener">PalisadeResearch</a> and showcased a comparison of different prompting techniques leveraged to solve a set of challenges from the <a href="https://picoctf.com" target="_blank" rel="noopener">picoCTF</a> competition. picoCTF is an entry-level competition so the challenges themselves are not difficult but they teach a number of techniques that are required to know and solve harder challenges. Hence, getting a baseline on these challenges is a great way to ensure LLMs and Agents might be capable of solving harder challenges.</p>
<p>PalisadeResearch has made their <a href="https://github.com/PalisadeResearch/intercode/tree/master" target="_blank" rel="noopener">code available</a> which makes it easy to test out and build upon.</p>
<p>As my goal is to use open-source models, I wanted to get a baseline comparaison of their current capabilities using PalisadeResearch&rsquo;s code before moving on. Only small modifications were made to allow using OpenRouter as an inference provider instead of OpenAI. I&rsquo;ve uploaded the diff of changes <a href="https://github.com/fyxme/flagseeker/blob/main/research/palisade-intercode-baseline-run/git-diff-changes.diff" target="_blank" rel="noopener">here</a> for transparency.</p>
<p><em>Note: I have not modified the code, prompts, environment or Agentic behaviour in order to keep a better baseline comparison. I understand that this code is made to compare different configurations but is not robust enough to be used in a production environment and does not handle agents misbehaving, not following response formats, etc. I&rsquo;ve remade the application from scratch to better handle such cases which I&rsquo;ll showcase in the next section.</em></p>
<p>I decided to use the following open-source models (logs can be found <a href="https://github.com/fyxme/flagseeker/tree/main/research/palisade-intercode-baseline-run" target="_blank" rel="noopener">here</a>):</p>
<table>
  <thead>
      <tr>
          <th>model</th>
          <th style="text-align: center"># of parameters</th>
          <th style="text-align: center">Thinking?</th>
          <th style="text-align: right"># of solves</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><a href="https://huggingface.co/deepseek-ai/DeepSeek-V3.1" target="_blank" rel="noopener">deepseek-ai/DeepSeek-V3.1</a></td>
          <td style="text-align: center">685B</td>
          <td style="text-align: center">True</td>
          <td style="text-align: right">80</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/ByteDance-Seed/Seed-OSS-36B-Instruct" target="_blank" rel="noopener">ByteDance-Seed/Seed-OSS-36B-Instruct</a></td>
          <td style="text-align: center">36B</td>
          <td style="text-align: center">True</td>
          <td style="text-align: right">79**</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/openai/gpt-oss-120b" target="_blank" rel="noopener">openai/gpt-oss-120b</a></td>
          <td style="text-align: center">120B</td>
          <td style="text-align: center">True</td>
          <td style="text-align: right">9*</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905" target="_blank" rel="noopener">moonshotai/Kimi-K2-Instruct-0905</a></td>
          <td style="text-align: center">1T</td>
          <td style="text-align: center">False</td>
          <td style="text-align: right">77</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct" target="_blank" rel="noopener">Qwen/Qwen3-Next-80B-A3B-Instruct</a></td>
          <td style="text-align: center">80B</td>
          <td style="text-align: center">False</td>
          <td style="text-align: right">80***</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking" target="_blank" rel="noopener">Qwen/Qwen3-Next-80B-A3B-Thinking</a></td>
          <td style="text-align: center">80B</td>
          <td style="text-align: center">True</td>
          <td style="text-align: right">26***</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct" target="_blank" rel="noopener">meta-llama/Llama-3.3-70B-Instruct</a></td>
          <td style="text-align: center">70B</td>
          <td style="text-align: center">False</td>
          <td style="text-align: right">4*</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407" target="_blank" rel="noopener">mistralai/Mistral-Nemo-Instruct-2407</a></td>
          <td style="text-align: center">12B</td>
          <td style="text-align: center">False</td>
          <td style="text-align: right">2*</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct" target="_blank" rel="noopener">meta-llama/Llama-3.1-8B-Instruct</a></td>
          <td style="text-align: center">8B</td>
          <td style="text-align: center">False</td>
          <td style="text-align: right">0*</td>
      </tr>
  </tbody>
</table>
<p><em>* : Some models error&rsquo;ed before completing the benchmark due to a number of issues (eg. not following response_format, running out of context space, inference provider issues, etc). Since my goal also involves making the Agent more robust, I am not going to try solving every error encountered yet and will use these tests as a baseline instead. I test a bunch of other models too but smaller models were very inconsistent with set response formats.</em></p>
<p><em>**: The first run of the ByteDance-Seed/Seed-OSS-36B-Instruct model failed due to provider issues (only 3 challenges were solved). However I wanted to get a better baseline as I decided to use this most for most of my testing later on. As such, I re-ran it a second time to get a more complete baseline.</em></p>
<p><em>***The two Qwen3-Next-80B-A3B models were released as I was about to release this blog. After testing them, they showed good results and seemed promising. The instruct (non-reasoning) model was also quite quick compared to some of the other models so I decided to test them out and use them in this research.</em></p>
<p>The fact that an open-source 80B parameters model matched a 685B model and was on par with strong closed source models is very promising. Furthermore, the ability of newer models such as <code>DeepSeek-V3.1</code>, <code>Seed-OSS-36B</code> and <code>Qwen3-Next-80B-A3B</code> to follow instructions and consistently provide accurate response formats has been quite impressive. Since I wanted to focus my research on smaller models, I decided to focus on one reasoning model (<code>ByteDance-Seed/Seed-OSS-36B-Instruct</code>) and one non-reasoning model (<code>Qwen3-Next-80B-A3B</code>).</p>
<p>This benchmark only compares solve rates, however since the newer models basically solve the same number of challenges, to be more thorough we should look at more than simply the number of solves. For example, solve speed and number of steps to solve could be taken into account to compare the different models. We&rsquo;ll look at optimising these in the <em>RAG section</em> of this article.</p>
<p>Furthermore, these models have more training, better quality data and benchmark data contamination might be an issue so it&rsquo;ll be important to test them against other challenges/benchmarks.</p>
<h2>Developing a more robust Agentic solution to solve CTF challenges<span class="hx-absolute -hx-mt-20" id="developing-a-more-robust-agentic-solution-to-solve-ctf-challenges"></span>
    <a href="#developing-a-more-robust-agentic-solution-to-solve-ctf-challenges" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>After attempting to refactor the Palisade/intercode&rsquo;s code twice (using GPT-5 <code>codex</code>and manually), I gave up and decided to rewrite everything from scratch. Too much of the code was useless or redundant (the original intercode research looked at more than just CTFs so more code was needed), prompts were stored everywhere and hard to manage. It was difficult to adapt new strategies and rework it, so instead I design an improved system and wrote it from scratch.</p>
<p><em>I will say that Palisade/intercode were only exploring different techniques for research purposes and had no intention of actually using the agents outside of benchmarks which is why they might put less time into designing a more robust and more versatile system that can be used for benchmarks as well as standalone tasks (ie. used during CTF events).</em></p>
<p>Palisade&rsquo;s research showed improved solve rates using prompting techniques and agent loops such as the ones we discussed earlier (eg. Chain-of-Thought, Plan, React, React-Plan). They had developed the following 5 strategies:</p>
<ul>
<li><strong>N-turns:</strong> this strategy is basically using Chain-of-Thought. The model is given the initial task and asked to perform 1 step each time for N number of turns. Each turn the agent is provided with the previous actions (ie. bash or python commands) performed and the action output (ie. <code>stdout/stderr</code>). The agent continues until it runs out of available turns or it solves the challenge. We&rsquo;ll call this agent the <code>ActionAgent</code>.</li>
<li><strong>Plan:</strong> this strategy is similar except that there is a secondary agent which provides a plan on how to solve the challenge. This plan is given to the <code>ActionAgent</code> in an attempt to help it solve the task. We&rsquo;ll call this secondary agent, the <code>PlanningAgent</code>.</li>
<li><strong>ReAct:</strong> this strategy involves two (2) steps. The first step is to ask an agent (ie. <code>ThinkingAgent</code>) to generate a thought about how to solve the next step, forcing the agent to think about reasoning steps before converting its reasoning to an action using the <code>ActionAgent</code>.</li>
<li><strong>ReAct+plan:</strong> this is basically the same as the ReAct strategy except also request a plan from the <code>PlanningAgent</code> and give that plan to the <code>ThinkingAgent</code>. This is the strategy that yielded the best results in their testing.</li>
<li><strong>Tree-of-Thoughts (ToT):</strong> this last strategy uses <a href="https://www.promptingguide.ai/techniques/tot" target="_blank" rel="noopener">Tree-of-Thoughts</a> which is another prompting strategy which I will explore in a future blogpost.</li>
</ul>
<p>From the strategies above you might have spotted a common theme, basically the <code>ActionAgent</code>, <code>ThinkingAgent</code> and <code>PlanningAgent</code> can be combined and interchanged to make up 4 of the 5 strategies. Combining them as such makes the code (and strategies) more modular as you can interchange them, and/or add new agents with new abilities. For example, a Vision Agent to extract information from images and videos or a DeepSearch agent to search for information and resources on a specific topic (or PoC/CVEs) when we&rsquo;re stuck on a challenge. This is why I decided to refactor them as such. It also makes it easier to manage the system and user prompts as they&rsquo;re basically always the same regardless of the strategy.</p>
<p>With the modifications added and the cleaned up prompts you can see each agent here:</p>
<ul>
<li><a href="https://github.com/fyxme/flagseeker/blob/main/src/agents/action_agent.py" target="_blank" rel="noopener">ActionAgent</a></li>
<li><a href="https://github.com/fyxme/flagseeker/blob/main/src/agents/planning_agent.py" target="_blank" rel="noopener">PlanningAgent</a></li>
<li><a href="https://github.com/fyxme/flagseeker/blob/main/src/agents/thinking_agent.py" target="_blank" rel="noopener">ThinkingAgent</a></li>
</ul>
<p>The <code>ThinkingAgent</code> seems quite redundant for reasoning enabled models as they already have their own thinking. It might be more helpful for non-reasoning agents as it provides them the ability to reason before giving an action command.  It would be interesting to test different setups in the future with and without the <code>ThinkingAgent</code> thoughts as I speculate that it might not provide much value except giving the agent an additional step/attempt to solve challenges. With the improved response format, the models are also asked to provide an explanation of their action which basically describes the thought behind their command and I believe could replace the &ldquo;thought&rdquo; from the thinking agent:</p>
<p>
    <img src="../img/Pasted%20image%2020250919173127.webp" alt="" loading="lazy" /></p>
<p><em>I have kept the <code>ThinkingAgent</code> for now as I test out different setups (and since I wanted to be able to replicate the previous study) and check if this step is needed or not. I also believe that with finetuning, a single agent setup might be able to replace the PlanningAgent and ActionAgent setup with a single agent that does everything and chooses when to make a plan vs tries to run a command.</em></p>
<p>In addition to separating each agent, I&rsquo;ve also added a response format for each agent which provides structured responses and allows better context management when building the query (ie. when providing the thoughts or plan to the action model). Here&rsquo;s a before and after adding a response format to the PlanningAgent, you can see the unstructured nature of the first response which would have been simply appended to our query and might cause confusion while the second version is more structured and allows us to test different version by providing more or less information to the ActionAgent (eg. providing suggested tools):</p>
<p>
    <img src="../img/Pasted%20image%2020250918172441.webp" alt="" loading="lazy" /></p>
<p>
    <img src="../img/Pasted%20image%2020250918172548.webp" alt="" loading="lazy" /></p>
<p>Running benchmarks is nice but all you get is number go up&hellip; What if we actually want to use our Agent during a CTF? For that reason, I added a Jupyter notebook with boilerplate code to download and setup a new Task (aka a challenge) and give it to the Agent to solve. Here&rsquo;s an example where I&rsquo;m using it to solve a networking challenge from <a href="https://247ctf.com/" target="_blank" rel="noopener">247ctf.com</a>:</p>
<p>
    <img src="../img/Pasted%20image%2020250919154631.webp" alt="" loading="lazy" /></p>
<p>
    <img src="../img/Pasted%20image%2020250919155151.webp" alt="" loading="lazy" /></p>
<p>
    <img src="../img/Pasted%20image%2020250919154108.webp" alt="" loading="lazy" /></p>
<p>It took its sweet time but got there in the end&hellip; There&rsquo;s still lots of improvements possible, especially around providing help with how to use certain tools but it was stubborn enough and managed to complete it! There&rsquo;s a few ideas we could leverage here like attempting to learn from our solve by looking at the shortest solve path based on the commands we ran and saving those commands for later use. We&rsquo;ll see how we can incorporate some of that in the RAG section below.</p>
<p>In addition to the changes above, here&rsquo;s a non-exhaustive list of additional features and improvements made:</p>
<ul>
<li>
<p>Code refactored for modularity, removing all unused code and combining as much as possible</p>
</li>
<li>
<p>Environment upgrades</p>
<ul>
<li>Added missing tools and created symlinks to help with models attempting to use tools in different manners (eg. <code>RsaCTFTool.py</code> instead of <code>RsaCTFTool</code>)</li>
<li>Each new run is performed in its own container environment meaning you can do multiple instances at once in different terminals</li>
<li>The challenges are copied during the task itself and not during container creation which makes it easier to test out new challenges and cleanup environments</li>
<li>Improved container deletion once benchmark/task has completed.</li>
</ul>
</li>
<li>
<p>Usability &amp; Reliability improvements</p>
<ul>
<li>Added a Jupyter notebook with a single task solver to use during CTFs</li>
<li>Added a shell script to run OpenRouter agents</li>
<li>Added a number of checks and conditional retries with exponential back-off to prevent issues with inference servers</li>
<li>Fixed a number of bugs, errors and added soft-fails where possible</li>
<li>Added multi-threading for benchmarks so you don&rsquo;t have to wait hours for it to be completed</li>
</ul>
</li>
<li>
<p>Observability and Operations</p>
<ul>
<li>Added the ability to setup Langfuse to help with LLM Observability (see <em>Observability and Operations</em> section for more information)</li>
</ul>
</li>
<li>
<p>Agents</p>
<ul>
<li>Cleaned up agent prompts and added context to improve task solve speed, solve rate and solve consistency</li>
<li>Removed prompt sections like &ldquo;<a href="https://github.com/PalisadeResearch/intercode/blob/master/experiments/utils/gpt_api.py#L131" target="_blank" rel="noopener">I&rsquo;ll tip you 100 dollars</a>&rdquo;. While this worked great some time ago, this is usually no longer required.</li>
<li>Centralised Prompts</li>
<li>Added additional context such as flag format, provided files, URLs and challenge category.</li>
<li>Added <code>ResponseFormats</code> to Planning and Thinking agents who didn&rsquo;t have a specific response format</li>
<li>Added RAG (See <em>Retrieval Augmented Generation (RAG)</em> for more details)</li>
<li>Added arguments to vary the planning strategy based on either static number of steps or every X step.</li>
</ul>
</li>
<li>
<p>Logging</p>
<ul>
<li>Cleaned up the log file naming convention to prevent overwriting runs</li>
<li>Added better logging overall and storing more information like start-time, end-time for tasks, runs, etc</li>
</ul>
</li>
</ul>
<p>Missing features from previous research:</p>
<ul>
<li>Currently does not support ToT strategy, however I will add this in the future.</li>
</ul>
<p>For a list of planned improvements, see the <em>Future research and tool improvements</em> Section.</p>
<h3>Benchmark comparison post-rewrite<span class="hx-absolute -hx-mt-20" id="benchmark-comparison-post-rewrite"></span>
    <a href="#benchmark-comparison-post-rewrite" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>To ensure I hadn&rsquo;t created a worse setup, I decided to run the benchmark again on models tested previously. The results are on-par with Palisade&rsquo;s research except with improvements on reliability (ie. gpt-oss-120b jumped from 9 to 75 challenges solved).</p>
<p>The updated table can be seen below. Its not cheap to run these and takes a while so I only re-ran a few of them which would give a good idea where we stand:</p>
<table>
  <thead>
      <tr>
          <th>model</th>
          <th style="text-align: center"># of parameters</th>
          <th style="text-align: center">Thinking?</th>
          <th style="text-align: right"># of solves (old)</th>
          <th style="text-align: right"># of solves (new)</th>
          <th style="text-align: right">delta</th>
          <th>logfile</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><a href="https://huggingface.co/deepseek-ai/DeepSeek-V3.1" target="_blank" rel="noopener">deepseek-ai/DeepSeek-V3.1</a></td>
          <td style="text-align: center">685B</td>
          <td style="text-align: center">True</td>
          <td style="text-align: right">80</td>
          <td style="text-align: right">79</td>
          <td style="text-align: right">-1*</td>
          <td><a href="https://github.com/fyxme/flagseeker/blob/main/logs/2025-09-26-14%3A56%3A14-613627_pico-ctf-benchmark_react-plan_deepseek-deepseek-chat-v3-1_steps-25.json" target="_blank" rel="noopener">log</a></td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/ByteDance-Seed/Seed-OSS-36B-Instruct" target="_blank" rel="noopener">ByteDance-Seed/Seed-OSS-36B-Instruct</a></td>
          <td style="text-align: center">36B</td>
          <td style="text-align: center">True</td>
          <td style="text-align: right">79</td>
          <td style="text-align: right">78</td>
          <td style="text-align: right">-1*</td>
          <td><a href="https://github.com/fyxme/flagseeker/blob/main/logs/2025-09-23-16%3A36%3A30-871952_pico-ctf-benchmark_react-plan_bytedance-seed-oss-36b-instruct_steps-30.json" target="_blank" rel="noopener">log</a></td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/openai/gpt-oss-120b" target="_blank" rel="noopener">openai/gpt-oss-120b</a></td>
          <td style="text-align: center">120B</td>
          <td style="text-align: center">True</td>
          <td style="text-align: right">9</td>
          <td style="text-align: right">75</td>
          <td style="text-align: right">+66</td>
          <td><a href="https://github.com/fyxme/flagseeker/blob/main/logs/2025-09-19-23%3A48%3A23-046498_pico-ctf-benchmark_react-plan_openai-gpt-oss-120b_steps-25.json" target="_blank" rel="noopener">log</a></td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905" target="_blank" rel="noopener">moonshotai/Kimi-K2-Instruct-0905</a></td>
          <td style="text-align: center">1T</td>
          <td style="text-align: center">False</td>
          <td style="text-align: right">77</td>
          <td style="text-align: right">N/A</td>
          <td style="text-align: right">N/A</td>
          <td>N/A</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct" target="_blank" rel="noopener">Qwen/Qwen3-Next-80B-A3B-Instruct</a></td>
          <td style="text-align: center">80B</td>
          <td style="text-align: center">False</td>
          <td style="text-align: right">80</td>
          <td style="text-align: right">69</td>
          <td style="text-align: right">-11*</td>
          <td><a href="https://github.com/fyxme/flagseeker/blob/main/logs/2025-09-23-14%3A08%3A39-007066_pico-ctf-benchmark_react-plan_qwen-qwen3-next-80b-a3b-instruct_steps-30.json" target="_blank" rel="noopener">log</a></td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking" target="_blank" rel="noopener">Qwen/Qwen3-Next-80B-A3B-Thinking</a></td>
          <td style="text-align: center">80B</td>
          <td style="text-align: center">True</td>
          <td style="text-align: right">26</td>
          <td style="text-align: right">N/A</td>
          <td style="text-align: right">N/A</td>
          <td>N/A</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct" target="_blank" rel="noopener">meta-llama/Llama-3.3-70B-Instruct</a></td>
          <td style="text-align: center">70B</td>
          <td style="text-align: center">False</td>
          <td style="text-align: right">4</td>
          <td style="text-align: right">N/A</td>
          <td style="text-align: right">N/A</td>
          <td>N/A</td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407" target="_blank" rel="noopener">mistralai/Mistral-Nemo-Instruct-2407</a></td>
          <td style="text-align: center">12B</td>
          <td style="text-align: center">False</td>
          <td style="text-align: right">2</td>
          <td style="text-align: right">33</td>
          <td style="text-align: right">+31</td>
          <td><a href="https://github.com/fyxme/flagseeker/blob/main/logs/2025-10-07-20%3A03%3A25-557852_pico-ctf-benchmark_react-plan_mistralai-mistral-nemo-instruct-2407_steps-25.json" target="_blank" rel="noopener">log</a></td>
      </tr>
      <tr>
          <td><a href="https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct" target="_blank" rel="noopener">meta-llama/Llama-3.1-8B-Instruct</a></td>
          <td style="text-align: center">8B</td>
          <td style="text-align: center">False</td>
          <td style="text-align: right">0</td>
          <td style="text-align: right">N/A</td>
          <td style="text-align: right">N/A</td>
          <td>N/A</td>
      </tr>
  </tbody>
</table>
<p><em>*The large negative deltas for <code>Qwen/Qwen3-Next-80B-A3B-Instruct</code>are due to inference provider errors and internet connection cuts. These benchmarks are expensive to run so I&rsquo;m not going to run these again and will assume that they are negligible for now. I also only did 1 pass through and 2 attempts for each task instead of the usual 3 attempts per task.</em></p>
<p>The -1 delta discrepancy for models DeepSeek and Seed-OSS models is due to less steps allowed (ie. 25 instead of 30) and less attempts (ie. 2 instead of 3) than the previous benchmark.  Hence, I&rsquo;ll consider these on-par. The biggest improvement can be seen with models that previously had very low score in the baseline due to a number of issues (ie. response formatting, poor error handling, bugs, etc). This shows that we&rsquo;ve managed to improve consistency and robustness quite a bit, allowing smaller models such as Mistral Nemo to perform significantly better while only being 12B tokens in size.</p>
<div class="hx-overflow-x-auto hx-mt-6 hx-flex hx-flex-col hx-rounded-lg hx-border hx-py-4 hx-px-4 contrast-more:hx-border-current contrast-more:dark:hx-border-current hx-border-blue-200 hx-bg-blue-100 hx-text-blue-900 dark:hx-border-blue-200/30 dark:hx-bg-blue-900/30 dark:hx-text-blue-200">
  <p class="hx-flex hx-items-center hx-font-medium"><svg height=16px class="hx-inline-block hx-align-middle hx-mr-2" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"/></svg>Note</p>

  <div class="hx-w-full hx-min-w-0 hx-leading-7">
    <div class="hx-mt-6 hx-leading-7 first:hx-mt-0"><p>Another issue I discovered later on is that some inference providers on openrouter are garbage and will continuously return empty responses (which explains the previous low results for some of the models (eg. gpt-oss-120b, llama 3.3 70B). If you keep on getting issues with certain models, it might be worth looking at your activity page (<a href="https://openrouter.ai/activity?page=1" target="_blank" rel="noopener">https://openrouter.ai/activity?page=1</a>) and ignoring those providers in your account settings (<a href="https://openrouter.ai/settings/preferences" target="_blank" rel="noopener">https://openrouter.ai/settings/preferences</a>)</p>
</div>
  </div>
</div>
<h3>Retrieval Augmented Generation (RAG)<span class="hx-absolute -hx-mt-20" id="retrieval-augmented-generation-rag-1"></span>
    <a href="#retrieval-augmented-generation-rag-1" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>There exists a tool called <a href="https://github.com/RsaCtfTool/RsaCtfTool" target="_blank" rel="noopener">RsaCtfTool</a>which basically tries a number of insecure RSA primitives to recover a private key and use that private key to decrypt encrypted text (ie. ciphertext). In their research, Palisade modified the prompt to mention that we have access to the tool, installed the tool in the environment and added it next to the challenges which might require it :</p>
<p>
    <img src="../img/Pasted%20image%2020250924124856.webp" alt="" loading="lazy" /></p>
<p>They also provide an example in one of their prompts:</p>
<p>
    <img src="../img/Pasted%20image%2020250924125044.webp" alt="" loading="lazy" /></p>
<p>This tells the model the tool exists, helps it learn about the tool and how to use it. While this is not being retrieved dynamically, if we were able to retrieve tools based on the current task, we could list a lot more tools that might help the agent solve the task. This is where RAG comes in. RAG enables us to retrieve tools and information at runtime based on current task and the theories we have to solve the challenge.</p>
<p>Lets look at examples of how that can improve our agents.</p>
<h4>Enhancing capabilities by introducing tools: <code>RsaCTFTool</code> for crypto challenges<span class="hx-absolute -hx-mt-20" id="enhancing-capabilities-by-introducing-tools-rsactftool-for-crypto-challenges"></span>
    <a href="#enhancing-capabilities-by-introducing-tools-rsactftool-for-crypto-challenges" class="subheading-anchor" aria-label="Permalink for this section"></a></h4><p>One of the challenges in the picoCTF benchmark can be solved entirely using <code>RsaCTFTool</code>. The problem is if the models are not aware the tool exists or don&rsquo;t know how to use the tool properly they will try to solve the tool manually <em>which may work</em> but is very inefficient.</p>
<p>The challenge is a crypto challenge that tries to teach you about RSA implementation weakness, specifically using non-prime number for N which can be factorised relatively easily:</p>
<p>
    <img src="../img/Pasted%20image%2020250924130826.webp" alt="" loading="lazy" /></p>
<p>
    <img src="../img/Pasted%20image%2020250924130850.webp" alt="" loading="lazy" /></p>
<p>The quickest way to solve this challenge is to use <code>RsaCtfTool</code> to search a online database of factors (ie. <a href="https://factordb.com/search.php" target="_blank" rel="noopener">factordb.com</a>) and factorise N. This allows us to recover the private key:</p>
<p>
    <img src="../img/Pasted%20image%2020250924132244.webp" alt="" loading="lazy" /></p>
<p><code>RsaCtfTool</code> also has a way to decrypt ciphertext directly which mean with one command you can basically solve the challenge:</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">$ RsaCtfTool -n <span class="m">1422450808944701344261903748621562998784243662042303391362692043823716783771691667</span> -e <span class="m">65537</span> --decrypt <span class="m">843044897663847841476319711639772861390329326681532977209935413827620909782846667</span> --attack factordb --private
</span></span><span class="line"><span class="cl"><span class="o">[</span><span class="s1">&#39;/tmp/tmpkbo3txdj&#39;</span><span class="o">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">[</span>*<span class="o">]</span> Testing key /tmp/tmpkbo3txdj.
</span></span><span class="line"><span class="cl"><span class="o">[</span>*<span class="o">]</span> Performing factordb attack on /tmp/tmpkbo3txdj.
</span></span><span class="line"><span class="cl"><span class="o">[</span>*<span class="o">]</span> Attack success with factordb method !
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Results <span class="k">for</span> /tmp/tmpkbo3txdj:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Private key :
</span></span><span class="line"><span class="cl">-----BEGIN RSA PRIVATE KEY-----
</span></span><span class="line"><span class="cl">MIGwAgEAAiIv/IZi84fX6oy8X46Nkz8/hpvqZIr+AVHktXPVdOmciSqTAgMBAAEC
</span></span><span class="line"><span class="cl">IiDlTT8CUaqryOTN4Qye16nwq1dq9EdZ7q2VP9DPJWALAaECEQZY9sOHJWE7+0FH
</span></span><span class="line"><span class="cl">2V+wZK0DAhIHj1QAU1FI0d/1sfIrHodVrzECEQP5H8zYBT/NycHc9WV+BiZ9AhE9
</span></span><span class="line"><span class="cl">KENmXqA1eaVS/TsdmNs9UQIRAPFen0CtiPHZkuODgHqHqRA<span class="o">=</span>
</span></span><span class="line"><span class="cl">-----END RSA PRIVATE KEY-----
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Decrypted data :
</span></span><span class="line"><span class="cl">HEX : 0x007069636f4354467b736d6131315f4e5f6e305f67306f645f30303236343537307d
</span></span><span class="line"><span class="cl">INT <span class="o">(</span>big endian<span class="o">)</span> : <span class="m">13016382529449106065927291425342535437996222135352905256639555294957886055592061</span>
</span></span><span class="line"><span class="cl">INT <span class="o">(</span>little endian<span class="o">)</span> : <span class="m">3710929847087427876431838308943291274263296323136963202115989746100135819907526656</span>
</span></span><span class="line"><span class="cl">utf-8 : picoCTF<span class="o">{</span>sma11_N_n0_g0od_00264570<span class="o">}</span>
</span></span><span class="line"><span class="cl">utf-16 : 瀀捩䍯䙔獻慭ㄱ也湟弰で摯た㈰㐶㜵細
</span></span><span class="line"><span class="cl">STR : b<span class="s1">&#39;\x00picoCTF{sma11_N_n0_g0od_00264570}&#39;</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p>If we look at how the model attempts to solve the task when it doesn&rsquo;t know about <code>RsaCtfTool</code>, we can see it understands what it needs to do but tries to do it manually and factorise locally which could take a while, if even possible on a laptop. You can see the PlanningAgent&rsquo;s response where its trying to use python to do it manually:</p>
<p>
    <img src="../img/Pasted%20image%2020250922174702.webp" alt="" loading="lazy" /></p>
<p>And the action models does as suggested using python:</p>
<p>
    <img src="../img/Pasted%20image%2020250922174508.webp" alt="" loading="lazy" /></p>
<p>
    <img src="../img/Pasted%20image%2020250922174602.webp" alt="" loading="lazy" /></p>
<p>We&rsquo;ll now teach the Agent about the tool itself by adding the tool, its utility and some examples in the system prompt as such:</p>
<p>
    <img src="../img/Pasted%20image%2020250922174413.webp" alt="" loading="lazy" /></p>
<p>After providing tools and example commands, the agent has learned about the tool and how to use it and is able to solve the challenge within the least amount of steps (we can&rsquo;t solve any faster then this). Here&rsquo;s the plan returned after the tool information was added to the system prompt which now contains references to <code>RsaCtfTool</code>:</p>
<p>
    <img src="../img/Pasted%20image%2020250922174152.webp" alt="" loading="lazy" /></p>
<p>And the list of actions is now very direct, the ActionAgent also realised that it could do step 2 and 3 of the plan at the same time using 1 command and went for it:</p>
<p>
    <img src="../img/Pasted%20image%2020250922173953.webp" alt="" loading="lazy" /></p>
<p>Hence we can teach agents to use new tools available to them.</p>
<h4>Reducing step count by giving command examples: recursive <code>binwalk</code><span class="hx-absolute -hx-mt-20" id="reducing-step-count-by-giving-command-examples-recursive-binwalk"></span>
    <a href="#reducing-step-count-by-giving-command-examples-recursive-binwalk" class="subheading-anchor" aria-label="Permalink for this section"></a></h4><p>Introducing new tools is great but we can also leverage this new ability to teach the model about how to use effective tools efficiently. Here you can see the model attempting a different challenge where it has to run a set of commands recursively until it gets to the flag:</p>
<p>
    <img src="../img/Pasted%20image%2020250922193848.webp" alt="" loading="lazy" /></p>
<p>The model is not aware that <code>binwalk</code> the first tool it uses has a way to run recursively which we can try to teach it:</p>
<p>
    <img src="../img/Pasted%20image%2020250922213321.webp" alt="" loading="lazy" /></p>
<p>After updating our system prompt we can see that the agent is now much more efficient, although its still not that great at navigating directories recursively:</p>
<p>
    <img src="../img/Pasted%20image%2020250922215038.webp" alt="" loading="lazy" /></p>
<p>By adding an example to our tool, we can teach it to be more efficient after extracting files:</p>
<p>
    <img src="../img/Pasted%20image%2020250922215641.webp" alt="" loading="lazy" /></p>
<p>With this new example, it decided to use the first example but then took ideas from the second example to find all files instead of recursively looking inside of each directory:</p>
<p>
    <img src="../img/Pasted%20image%2020250922221604.webp" alt="" loading="lazy" /></p>
<blockquote>
  <p><strong>Why are there two <code>cat</code> commands?</strong>
This is the output from the first <code>cat</code> command:  <code>p�i�c�o�C�T�F�{�4�f�1�1�0�4�8�e�8�3�f�f�c�7�d�3�4�2�a�1�5�b�d�2�3�0�9�b�4�7�d�e�}</code></p>
<p>Explanation from the LLM itself: <em>The observation from <code>cat flag.txt</code> shows the flag characters separated by null bytes (visible as blank boxes). To get the clean flag, we need to remove these null bytes using <code>tr -d '\0'</code></em></p>

</blockquote>
<h4>Adding RAG to our Agent system<span class="hx-absolute -hx-mt-20" id="adding-rag-to-our-agent-system"></span>
    <a href="#adding-rag-to-our-agent-system" class="subheading-anchor" aria-label="Permalink for this section"></a></h4><p>We&rsquo;ve just shown that its possible to improve capabilities by adding tools and examples to system prompts. Since my current list of tools is small I could technically just extend the system or user prompt with the tool list and examples. However, as the list of tools expands this won&rsquo;t be manageable.</p>
<p>As such, we need to be able to only provide the tools needed for the task at hand. This is where RAG comes in!</p>
<p>The hard part with RAG is knowing what data to add to your context and when to add it. For this solution, I&rsquo;ve decided to use multiple steps to figure out which commands and tools might be useful for the task. These tools and commands are stored in a database which are essentially json files. Here&rsquo;s an example for the <code>binwalk</code> tool which has some lesser known arguments like <code>-M</code> to extract recursively:</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&#34;title&#34;</span><span class="p">:</span> <span class="s2">&#34;binwalk&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&#34;explanation&#34;</span><span class="p">:</span> <span class="s2">&#34;Binwalk can identify and extract files and data that have been embedded inside of other files. Its primary focus is firmware analysis, it supports a wide variety of file and data types. Through entropy analysis, it can even help to identify unknown compression or encryption.&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&#34;examples&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="nt">&#34;query&#34;</span><span class="p">:</span> <span class="s2">&#34;Recursively scan extracted (-e) files and data like matryoshka dolls (-M)&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="nt">&#34;command&#34;</span><span class="p">:</span><span class="s2">&#34;binwalk -eM &lt;file.ext&gt;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="p">},</span>
</span></span><span class="line"><span class="cl">        <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="nt">&#34;query&#34;</span><span class="p">:</span> <span class="s2">&#34;Recursively scan extracted (-e) files and data like matryoshka dolls (-M) plus print all extracted files&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="nt">&#34;command&#34;</span><span class="p">:</span> <span class="s2">&#34;binwalk -e -M dolls.jpg &amp;&amp; find . -type f&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&#34;categories&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;reversing&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;forensic&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&#34;tags&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;reversing&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;forensic&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p>First, the planning agent receives a list of tools and descriptions based on the task&rsquo;s categories. Using these tools, it generates a plan and might include the tools in their tool suggestions. There are no examples, just a list of tools that match the challenge&rsquo;s category:</p>
<p>
    <img src="../img/Pasted%20image%2020251007145311.webp" alt="" loading="lazy" /></p>
<p>In its plan, the agent returns a list of suggested tools which might include some of the tools we retrieved from our database:</p>
<p>
    <img src="../img/Pasted%20image%2020251007145406.webp" alt="" loading="lazy" /></p>
<p>Now we want to convert the planning agent&rsquo;s output to search for related tools and get relevant examples in order to provide this information to the thinking/action agents. We do that by using a hybrid RAG setup. We find the most relevant tools to add by calculating a score using a number of methods:</p>
<ul>
<li><strong>BM25</strong>: basically a ranking algorithm that determines relevance based on keyword matching and word frequency in documents (ie. keyword matching)</li>
<li><strong>Semantic Search</strong>: Semantic search is all about understanding meaning and context instead of just word matching. This type of search focuses on understanding the intent behind the words in a query. Basically, we use an LLM to try and extract meaning from a query so that a query like &ldquo;my laptop dies overnight while sleeping&rdquo; does not end up with the agent trying to call the cops on you but instead find something like &ldquo;Troubleshooting standby power drain and unexpected battery loss during sleep mode.&rdquo;.</li>
<li><strong>Keyword Bonus</strong>: We have the luxury of having specific keywords that are more important than others. I&rsquo;m talking about the tools/commands specifically (eg. <code>binwalk</code>). This means we can use it to boost entries that are about this tool specifically. This prevents the tool being buried if the query ran matches other commands more than this tool itself.</li>
</ul>
<p>We generate a score for both <strong>BM25</strong> and <strong>Semantic Search</strong> which we combine (using <a href="https://medium.com/@devalshah1619/mathematical-intuition-behind-reciprocal-rank-fusion-rrf-explained-in-2-mins-002df0cc5e2a" target="_blank" rel="noopener">Reciprocal Rank Fusion</a>) and then add the <strong>Keyword Bonus</strong>, mathematically this looks something like this:</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-txt" data-lang="txt"><span class="line"><span class="cl">score = RRF(BM25(query),SS(query)) + KB(suggested_tools, card_tools)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">where
</span></span><span class="line"><span class="cl">	query -&gt; task_summary provided by the planning agent
</span></span><span class="line"><span class="cl">	suggested_tools -&gt; a list of suggested_tools provided by the planning agent
</span></span><span class="line"><span class="cl">	card_tools -&gt; a list of cards and associated tools for each card
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	RRF -&gt; Reciprocal Rank Fusion
</span></span><span class="line"><span class="cl">	BM25 -&gt; lexical search using Best Matching (ie. BM25)
</span></span><span class="line"><span class="cl">	SS -&gt; Semantic Search
</span></span><span class="line"><span class="cl">	KB -&gt; Keyword Bonus</span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p>Using this score, we rank the documents (ie. tool cards) and use a <a href="https://www.pinecone.io/learn/series/rag/rerankers/" target="_blank" rel="noopener">reranker</a> which is a type of model that given a query and a set of documents will output a similarity score. We use this similarity score to reorder the tool cards by relevance to our query and finally we remove all cards below a minimum score as they are probably not relevant (used a min score of <code>0</code> while testing). This aims to provide the most relevant tools for the task at hand and hopefully helps us solve harder challenges (ie.<code>RsaCTFTool</code> example) or solve challenges faster/more efficiently (ie. <code>binwalk</code> example).</p>
<p>To show this works, we can attempt challenges 12 and 14 again (ie. the <code>binwalk</code> and <code>rsactftool</code> challenges) from before and see the improvement with and without RAG.</p>
<p>Without RAG, its trying python shenanigans hoping it can factorise it on this limited docker container inside of my limited VM on this old laptop which it&rsquo;ll struggle with and timeouts before anything interesting happens. We can see the model does have limited knowledge of <code>rsactftool</code> and attempts to use it but fails miserably because it doesn&rsquo;t know how to use it properly:</p>
<p>
    <img src="../img/Pasted%20image%2020251007155529.webp" alt="" loading="lazy" /></p>
<p>Similarly for the &ldquo;binwalk&rdquo; challenge, it uses the slow method of extraction, repeatedly calling <code>binwalk</code>, <code>unzip</code>, and <code>dd</code>:</p>
<p>
    <img src="../img/Pasted%20image%2020251007161839.webp" alt="" loading="lazy" /></p>
<p>With RAG, it solves both challenges in the smallest amount of possible steps using the tools exactly as we&rsquo;ve provided them with in our RAG solution:</p>
<p>
    <img src="../img/Pasted%20image%2020251007153929.webp" alt="" loading="lazy" /></p>
<p>You can find both log traces here:</p>
<ul>
<li><a href="https://github.com/fyxme/flagseeker/blob/main/logs/2025-10-07-15%3A37%3A34-628196_pico-ctf-benchmark_react-plan_mistralai-magistral-small-2506_steps-25.json" target="_blank" rel="noopener">With RAG</a></li>
<li><a href="https://github.com/fyxme/flagseeker/blob/main/logs/2025-10-07-15%3A51%3A34-441914_pico-ctf-benchmark_react-plan_mistralai-magistral-small-2506_steps-10.json" target="_blank" rel="noopener">Without RAG</a></li>
</ul>
<p>This shows we can successfully leverage RAG to augment our agents and solve challenges that it might not have solved on its own.</p>
<h4>Limitations of RAG<span class="hx-absolute -hx-mt-20" id="limitations-of-rag"></span>
    <a href="#limitations-of-rag" class="subheading-anchor" aria-label="Permalink for this section"></a></h4><p>RAG is great when it provides the context required for a certain task but finding the right context (in our case the right tool(s)) and ensuring that we don&rsquo;t poison the context with garbage data that is not useful for the task at hand is much more difficult.</p>
<p>There are also a number of limitations that have <em>possible</em> solutions which I will explore in the future:</p>
<ul>
<li>The context window is not unlimited: At the moment, its easy because we have a low amount of tools but when more tools are added, we might need more tools and tool examples and the context grow quickly</li>
<li>Our current setup relies on the Planning Agent&rsquo;s query which might not be accurate and might not match the correct tool(s). For example, challenge descriptions can be cryptic so when the planning agent attempts to solve them at first, it might not have enough information about the task at hand and end up suggesting completely incorrect tools. An idea could be to try and retrieve the tool cards later on and not just for the planning agent.</li>
<li>It&rsquo;s hard to keep the wiki up to date: At the moment, the RAG wiki only has 4 tool cards, namely <code>binwalk</code>, <code>mergecap</code>, <code>rsactftool</code>, <code>ssldump</code>. However, there&rsquo;s a lot more tools that would be great to add in there but its hard to manage manually. What would be interesting is to use past/future solves and extract the set of commands required to solve the challenge and add them to our wiki automatically.</li>
<li>When to add RAG context: The RAG context is only added when the planning agent is called (which might not always be the case). I need to find a better solution on when to add context vs when not to.</li>
<li>Ambiguous tools: Some tools might be universal and not just relevant to crypto challenges for example and therefore would not be shown to the planning agent in our current setup. We might need to rethink how we list the tools relevant for the task when querying the planning agent in order to pull tools from categories other than the challenge&rsquo;s category. For example, we could try a similar thing as we do with the other agents and use the category as a bonus keyword when we&rsquo;re querying the cards for the planning agent.</li>
</ul>
<p>Lastly, we could look into finetuning to embed the information directly into an LLM.</p>
<h5>RAG vs Finetuning<span class="hx-absolute -hx-mt-20" id="rag-vs-finetuning"></span>
    <a href="#rag-vs-finetuning" class="subheading-anchor" aria-label="Permalink for this section"></a></h5><blockquote>
  <p>RAG is when you want to bring to the LLM specific information.
Fine tuning is when you want that knowledge set to be part of the system.
~ Xtianus21 (<a href="https://www.reddit.com/r/OpenAI/comments/1bjtz7y/comment/kvtuvv8/" target="_blank" rel="noopener">reddit</a>)</p>

</blockquote>
<p>RAG can help with giving knowledge of tools and concepts to LLMs by providing it within prompts and queries. The problem is it won&rsquo;t improve the model&rsquo;s task prioritisation and execution flow. For example, here the model knows about a few steps used to solve the task but instead of running one command at a time and checking it executed as expected its trying to perform all steps at once which is very error prone:</p>
<p>
    <img src="../img/Pasted%20image%2020250923125715.webp" alt="" loading="lazy" /></p>
<p>During testing, certain models had issues with <code>tshark</code> command and its various flags, filters, etc so it had to run similar commands quite a few times. It also failed to understand that it would be easier to run <code>mergecap</code> first and only once instead of running it on every command:</p>
<p>
    <img src="../img/Pasted%20image%2020250923125833.webp" alt="" loading="lazy" /></p>
<p>I will explore finetuning in a future article to see if it can help with solving these issues.</p>
<h2>Testing improvements on a new benchmark<span class="hx-absolute -hx-mt-20" id="testing-improvements-on-a-new-benchmark"></span>
    <a href="#testing-improvements-on-a-new-benchmark" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><h3>Why do we even need a new benchmark?<span class="hx-absolute -hx-mt-20" id="why-do-we-even-need-a-new-benchmark"></span>
    <a href="#why-do-we-even-need-a-new-benchmark" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><blockquote>
  <p>Large Language Model (LLM) benchmarks <strong>provide consistent, reproducible ways to assess and rank how well different LLMs handle specific tasks</strong>. They allow for an &ldquo;apples-to-apples&rdquo; comparison—like grading all students in a class on the same tests.
Limitations of LLM benchmarks include potential <strong>data contamination</strong>, where models are trained on the same data they’re later tested on, <strong>narrow focus</strong>, and loss of relevance over time as model capabilities surpass benchmarks.</p>

</blockquote>
<p>Benchmarks are nice but as LLMs get better and are trained with more data, a lot of benchmark data is also fed into LLMs which allows them to solve that specific benchmark but their abilities might not transfer to other benchmarks. It is said that some models are also directly trained on benchmark data in order to achieve better results for said benchmarks. This is called benchmaxing.</p>
<p>picoCTF is very well know and there is a plethora of write-ups available online. This means that the updated models Palisade have used (ie. OpenAI models) are likely to have direct solves for each of the challenges in their training data.</p>
<p>Furthermore, one of other the issues I have with Palisade&rsquo;s research is that for Crypto RSA challenges, they explicitly put the <a href="https://github.com/RsaCtfTool/RsaCtfTool" target="_blank" rel="noopener">RsaCTFTool</a> inside the challenge folder as can be seen on <a href="https://github.com/PalisadeResearch/intercode/tree/master/data/ctf/task_assets/12" target="_blank" rel="noopener">challenge 12</a> and <a href="https://github.com/PalisadeResearch/intercode/tree/6cbea9673b649a224a6ce4f9495f9a8add405d92/data/ctf/task_assets/79" target="_blank" rel="noopener">challenge 79</a>:</p>
<p>
    <img src="../img/Pasted%20image%2020250914142913.webp" alt="" loading="lazy" /></p>
<p>This is basically a huge hint for the challenge itself. The model will most likely run <code>ls -al</code> to list the files in the directory and will see that there is the challenge as well as the <code>RsaCTFTool</code> in there and therefore attempt to use the tool to solve the challenge. The <a href="https://github.com/princeton-nlp/intercode/tree/master/data/ctf/task_assets/12" target="_blank" rel="noopener">original research</a> did not provide the tool with the challenge itself. I feel like that is a big hint to give to the LLM as CTF challenges usually don&rsquo;t include tools with challenges but instead require the user to identify fitting tools for the challenge.</p>
<p>They also mention that the tool is available within one of their <a href="https://github.com/PalisadeResearch/intercode/blob/6cbea9673b649a224a6ce4f9495f9a8add405d92/experiments/utils/gpt_api.py#L140" target="_blank" rel="noopener">system prompts</a> although that is considered context engineering which in my opinion is fine:</p>
<p>
    <img src="../img/Pasted%20image%2020250914142744.webp" alt="" loading="lazy" /></p>
<p>Nevertheless, since there is only one tool listed it seems very &ldquo;optimised&rdquo; for the benchmark itself. Additional tools or a RAG integration would have been more impressive.</p>
<p>Regardless, I&rsquo;m not here to trash on their research, I just want to highlight some of them reasons why I believe we need more benchmarks.</p>
<h3>Creating a new benchmarks<span class="hx-absolute -hx-mt-20" id="creating-a-new-benchmarks"></span>
    <a href="#creating-a-new-benchmarks" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>Creating a new CTF benchmark is quite simple considering the amount of open source challenges and CTF archives on Github, <a href="https://ctftime.org/" target="_blank" rel="noopener">ctftime.org</a>, and the web.</p>
<p>As a test run, I decided to create simple benchmark using a total of 27 CTF challenges in varying difficulty. A lot of these challenges are quite a bit harder then the picoCTF challenges, however I know for a fact that a number of these can be solved with LLMs since I was able to solve a few using GPT-5 Thinking directly within OpenAI&rsquo;s chat interface (ie. no access to Kali environment).</p>
<p>The benchmark, which I&rsquo;ve named <em>The Unfinished CTF Benchmark</em>, is comprised of the following 27 challenges of varying difficulty, split in five different categories:</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Category</th>
          <th style="text-align: right"># of challenges</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">Miscellaneous</td>
          <td style="text-align: right">4</td>
      </tr>
      <tr>
          <td style="text-align: left">Cryptography</td>
          <td style="text-align: right">5</td>
      </tr>
      <tr>
          <td style="text-align: left">Networking</td>
          <td style="text-align: right">7</td>
      </tr>
      <tr>
          <td style="text-align: left">Reversing</td>
          <td style="text-align: right">10</td>
      </tr>
      <tr>
          <td style="text-align: left">Web</td>
          <td style="text-align: right">1</td>
      </tr>
  </tbody>
</table>
<p><em>Note: I&rsquo;ve decided not to release the benchmark as some of the challenges may still be active and I&rsquo;m still adding new challenges to it. I may or may not release a curated benchmark in the future&hellip; Only time will tell!</em></p>
<h3>Comparing Agents on the new benchmark<span class="hx-absolute -hx-mt-20" id="comparing-agents-on-the-new-benchmark"></span>
    <a href="#comparing-agents-on-the-new-benchmark" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>// TBD - comparison in progress</p>
<h2>Observability and Operations<span class="hx-absolute -hx-mt-20" id="observability-and-operations"></span>
    <a href="#observability-and-operations" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
  <p>LLM observability is the practice of gaining comprehensive, real-time visibility into the behavior, performance, and output characteristics of large language models (LLMs) and their associated applications in production. It goes beyond simple monitoring by providing the ability to understand the internal states of an LLM system through its outputs, enabling teams to debug issues, optimize performance, and ensure reliability, safety, and efficiency. This is achieved by collecting and correlating telemetry data such as logs, metrics, and traces from the application, APIs, and workflows.</p>

</blockquote>
<p>Observability tools allow you to see chat traces without having to print them in logs or terminal outputs and provide a platform to improve Agents through dataset benchmarking/evaluation, prompt management, and more. For my use case, I only wanted to be able to log LLM chats, search them easily and identify any shortcomings or improvements that could be made to the CTF Agent I created. As such I decided on using <a href="https://langfuse.com" target="_blank" rel="noopener">Langfuse</a>, an open source observability tool and one of the many available out there. The thing that sold me was the clean UI, ability to self-host and the simplicity with which you can integrate it into your applications to start logging chat traces.</p>
<p>In your Python application, replace the <code>openai</code> import with the <code>langfuse</code> equivalent</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># import openai</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langfuse.openai</span> <span class="kn">import</span> <span class="n">openai</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p>Export the required environment variables and simply run your python agent:</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">LANGFUSE_SECRET_KEY</span><span class="o">=</span>sk-lf-....-2300a4e4dea2
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">LANGFUSE_PUBLIC_KEY</span><span class="o">=</span>pk-lf-....-dd2171f8d0a7
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">LANGFUSE_HOST</span><span class="o">=</span><span class="s2">&#34;http://localhost:3000&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">python3 agent.py</span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p>That&rsquo;s it&hellip; That&rsquo;s all you need to get basic traces logged in Langfuse! I mostly used the Observability feature which provided LLM chat/session tracing so I can identify any issues or improvements. I will explore other features in the future. You can see some examples below:</p>
<p>
    <img src="../img/Pasted%20image%2020250906081151.webp" alt="" loading="lazy" /></p>
<p>It&rsquo;s a great way to see if something is wrong, for example here I&rsquo;m failing to provide a turn history:</p>
<p>
    <img src="../img/Pasted%20image%2020250906081255.webp" alt="" loading="lazy" /></p>
<h2>Testing improvements in a live CTF<span class="hx-absolute -hx-mt-20" id="testing-improvements-in-a-live-ctf"></span>
    <a href="#testing-improvements-in-a-live-ctf" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>Before I test the Agent in an actual live CTF environment, I needed it to have a hacker alias, and decided to let our LLM overloards choose. Here&rsquo;s what GPT-5 came up with:</p>
<p>
    <img src="../img/Pasted%20image%2020250907071159.webp" alt="" loading="lazy" /></p>
<p>I also asked it for a Country and Team Name as some CTFs require that information:</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<pre><code>Username: rop_n_roll
Country: Estonia
Team Name: Baltic Bitflip</code></pre><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p>So if you see a player named <code>rop_n_roll</code> from Estonia part of the Baltic Bitflip Team competing in your CTF event, you might be playing against a bot.</p>
<p>Unfortunately, I only had time to test a single challenge due to IRL commitments, however <code>rop_n_roll</code> battled through and was able to solve that it:</p>
<p>
    <img src="../img/Pasted%20image%2020250907081050.webp" alt="" loading="lazy" /></p>
<p>Great success!</p>
<h2>Conclusion and research outcomes<span class="hx-absolute -hx-mt-20" id="conclusion-and-research-outcomes"></span>
    <a href="#conclusion-and-research-outcomes" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><h3>Research Outcome<span class="hx-absolute -hx-mt-20" id="research-outcome"></span>
    <a href="#research-outcome" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>Learned a lot through this, understanding how agents and models work, how to improve their capabilities what they are good at and what they might need help with&hellip; The Agent I made is very early into development, there&rsquo;s still a lot of improvements possible which I will definitely explore in the future. Although future articles will be more to the point&hellip; Nevertheless, I was able to augment capabilities using RAG which are opening up ideas for future enhancements and hopefully help small open source LLMs bridge the gap and compete with large closed source models.</p>
<p>The agentic solution has already proven itself against live events! I will definitely do more testing in future events and try to see what can be improved further.</p>
<p>Furthermore, I&rsquo;m excited to try and incorporate self-improvement into RAG by automatically saving and optimising solve paths into command examples and what not as well as trying out finetuning. Obviously more data will be needed for this but with the new setup, I believe it will be easier to create new benchmarks from past and future CTFs and save challenges to train on. Also, I believe adding vision capabilities and deep research could be interesting and might be required to solve certain challenges. Food for thought.</p>
<h3>The future of CTFs<span class="hx-absolute -hx-mt-20" id="the-future-of-ctfs"></span>
    <a href="#the-future-of-ctfs" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>Are CTFs doomed? Short answer, probably not&hellip; CTFs have always been a good way to gain knowledge in new topics and a still an amazing way to learn and hone your skills in training environments.</p>
<p>If you play CTFs to learn about cyber security, this will not change and will still be a great way to learn. There are and still will be CTFs aimed at newcomers and people wanting to explore new skills.</p>
<p>If you&rsquo;re playing CTFs competitively, you&rsquo;re going to have to adapt quite a bit. LLMs are here to stay and are now able to do a lot of the grunt work. You&rsquo;ll need to learn how to leverage them to gain an advantage against other teams. Historically difficult CTFs will likely adapt and become more and more challenging as you&rsquo;re now expected to leverage LLMs to help solve challenges. Exploit path will likely be longer or more convoluted.</p>
<p>While everyone adapts to this change, I&rsquo;m sure a lot of CTFs are going to experience unexpectedly large number of challenge solves as people leverage LLMs more and more. It&rsquo;ll make for great drama on twitter with people confusing it for flag sharing and what not:</p>
<p>
    <figure>
    <img src="../img/Pasted%20image%2020250914145855.webp" title="ref: https://x.com/terjanq/status/1965037146504647038" alt="" loading="lazy" />
    <figcaption>ref: https://x.com/terjanq/status/1965037146504647038</figcaption>
  </figure></p>
<p><em>Note: I played in this CTF and know for a fact that GPT-5 Thinking was one-shotting a lot of these&hellip;</em></p>
<h3>Future research and tool improvements<span class="hx-absolute -hx-mt-20" id="future-research-and-tool-improvements"></span>
    <a href="#future-research-and-tool-improvements" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>Performing this research has given me a number of ideas on what to improve in future iterations. I&rsquo;ve added a starter list below which I hope to explore in follow up research:</p>
<ul>
<li>Finetuning models
<ul>
<li>Data generation
<ul>
<li>Synthetic dataset using OpenAI GPT-5 (or equivalent model) and a testing environment that validates the outputs and tools used</li>
<li>Using solves but removing intermediate steps which failed to identify optimised solves</li>
</ul>
</li>
<li>Finetuning for agentic use
<ul>
<li>RL
<ul>
<li><a href="https://github.com/OpenPipe/ART" target="_blank" rel="noopener">https://github.com/OpenPipe/ART</a></li>
<li><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4" target="_blank" rel="noopener">https://www.youtube.com/watch?v=gEDl9C8s_-4</a></li>
</ul>
</li>
<li>Finetuning a single agent instead of 3 separate agents - <a href="https://arxiv.org/abs/2509.06283" target="_blank" rel="noopener">https://arxiv.org/abs/2509.06283</a></li>
</ul>
</li>
<li>Tool use
<ul>
<li>Finetuning for tool use, python or bash commands</li>
<li>Fine tuning on kali linux commands</li>
<li>Fine tuning on better code search tools like <a href="https://ast-grep.github.io/" target="_blank" rel="noopener">ast-grep</a> and other tools like <a href="https://github.com/closed-systems/strangerstrings" target="_blank" rel="noopener">strangerstrings</a></li>
</ul>
</li>
<li>Trial fine-tuning using Lora, Qlora, etc&hellip;</li>
<li>Finetuning a reasoning model vs direct response model</li>
</ul>
</li>
<li>Agents / Context engineering
<ul>
<li>Adding a Deep Research Agent to search for tools, CVEs, topic knowledge and what not which may help provide more context and lead the agent to solving the challenge</li>
<li>Add an image parsing tool/agent to help describe, extract data or solve challenges which require looking at an image (ie. moondream 2B vision model, GLM-4.5V, etc)</li>
<li>Text recognition using <a href="https://github.com/open-mmlab/mmocr?tab=readme-ov-file" target="_blank" rel="noopener">https://github.com/open-mmlab/mmocr?tab=readme-ov-file</a> , <a href="https://github.com/PaddlePaddle/PaddleOCR" target="_blank" rel="noopener">https://github.com/PaddlePaddle/PaddleOCR</a> or tesseract</li>
<li>Add new tools like IDA/Ghidra MCP for reversing and pwn challenges and burpsuite or equivalent for Web challenges</li>
<li>Using specialised coding agents to analyse code for example during web or crypto challenges (ie. qwen coder, etc)</li>
<li>Test out and explore direct tool use instead of single step querying as is currently done</li>
<li>Explore specialised agents per task type</li>
<li>RAG
<ul>
<li>adding <a href="https://www.promptingguide.ai/applications/synthetic_rag" target="_blank" rel="noopener">synthetic RAG</a>, providing RAG based on the step (planning, thought, action)</li>
<li>self-learning mode - automatic RAG addition based on tools/commands that work well</li>
<li>test out other RAG solutions like weaviate or postgres vector</li>
<li>hybrid RAG retrieval
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1474034625001053" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S1474034625001053</a></li>
<li>Using Weaviate: <a href="https://ragaboutit.com/how-to-build-a-hybrid-rag-system-with-weaviates-new-multi-vector-search-the-complete-implementation-guide/" target="_blank" rel="noopener">https://ragaboutit.com/how-to-build-a-hybrid-rag-system-with-weaviates-new-multi-vector-search-the-complete-implementation-guide/</a></li>
</ul>
</li>
</ul>
</li>
<li>Prompt engineering
<ul>
<li>Test out prompt optimisation manually and using frameworks like dspy</li>
<li>Test different system templates - not all models respond to same message templates, adjust for each</li>
</ul>
</li>
</ul>
</li>
<li>Benchmarks / Training data
<ul>
<li>Adding an Improved Jupyter notebook to allow periodic saving of Task and Benchmarks for future comparisons</li>
<li>Add more challenges to train and benchmark against</li>
<li>keep all traces and use them for learning / improving models
<ul>
<li>remove non-working steps (ie. command not found, etc)</li>
<li>use traces to improve RAG or teach new models</li>
</ul>
</li>
</ul>
</li>
<li>Other
<ul>
<li>Using a less bloated environment (ie. Kali is too bloated)</li>
<li>Adding a web UI to view output and with the ability to talk to the agent(s) and provide additional context and ideas</li>
<li>Testing with locally ran and parameters optimised by models</li>
<li>LLM Cache (eg. <a href="https://github.com/LMCache/LMCache" target="_blank" rel="noopener">https://github.com/LMCache/LMCache</a>) - Not really useful for personal use agents but interested in trying it out</li>
</ul>
</li>
</ul>
<h2>Appendix<span class="hx-absolute -hx-mt-20" id="appendix"></span>
    <a href="#appendix" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><h3>Using Vision Language Models to help solve CTF challenges<span class="hx-absolute -hx-mt-20" id="using-vision-language-models-to-help-solve-ctf-challenges"></span>
    <a href="#using-vision-language-models-to-help-solve-ctf-challenges" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>I&rsquo;ve been thinking about using image models to help solve certain challenges like the picoCTF challenge below (although Vision Language Models might not be necessary here, you could probably do better with OpenCV). I first tried with the <a href="https://moondream.ai/c/playground" target="_blank" rel="noopener">Moondream.ai vision model</a> which is a 2B parameters model but very capable from previous testing, its not bad but needs some work:</p>
<p>
    <img src="../img/Pasted%20image%2020250914130534.webp" alt="" loading="lazy" /></p>
<p>I managed to get better results using GLM-4.5V model which correctly extracted the text from the image:</p>
<p>
    <img src="../img/Pasted%20image%2020250914130942.webp" alt="" loading="lazy" /></p>
<p>I also tested it on another challenge which uses <a href="https://en.wikipedia.org/wiki/Naval_flag_signalling#Sample_flag_meanings" target="_blank" rel="noopener">NATO flag signaling</a> although both models didn&rsquo;t seem to understand it. More testing to be done&hellip;</p>
<p>
    <img src="../img/Pasted%20image%2020250914131100.webp" alt="" loading="lazy" /></p>
<p>
    <img src="../img/Pasted%20image%2020250914131116.webp" alt="" loading="lazy" /></p>
<h3>Topping the leaderboards<span class="hx-absolute -hx-mt-20" id="topping-the-leaderboards"></span>
    <a href="#topping-the-leaderboards" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>Winner winner chicken dinner:</p>
<p>
    <img src="../img/Pasted%20image%2020250926132323.webp" alt="" loading="lazy" /></p>
<p>The only provider decided to stop providing the model (<em>feelsbadman</em>):</p>
<p>
    <img src="../img/Pasted%20image%2020250926132256.webp" alt="" loading="lazy" /></p>
<h3>Plain LLM Agents<span class="hx-absolute -hx-mt-20" id="plain-llm-agents"></span>
    <a href="#plain-llm-agents" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p><strong>Plain LLM agents</strong> are simple agents that use a large language model (LLM) directly to choose next actions or generate task steps without extra layers like complex planners, learned policies, or specialized orchestration frameworks.</p>
<p>Key characteristics:</p>
<ul>
<li><strong>Single-step decisioning:</strong> the LLM is prompted to decide the next action each turn (e.g., call a tool, ask a question, produce text).</li>
<li><strong>Minimal state management:</strong> little or no explicit memory, belief model, or long-term planning beyond what’s kept in the prompt/history.</li>
<li><strong>No learned controller:</strong> decisions rely on prompt engineering and the LLM’s reasoning, not on a separate trained policy network.</li>
<li><strong>Tool-driven behavior:</strong> often constrained to a fixed set of tools or API calls the LLM can invoke via structured outputs.</li>
<li><strong>Reactive and iterative:</strong> acts, observes results, and prompts the LLM again—adapting only through updated context.</li>
</ul>
<p>When to use:</p>
<ul>
<li>Prototyping agents quickly.</li>
<li>Tasks where short-horizon, conversational reasoning suffices.</li>
<li>Systems prioritizing simplicity and interoperability.</li>
</ul>
<p>Limitations:</p>
<ul>
<li>Poor scalability for long, complex plans.</li>
<li>Fragile to prompt drift and verbose histories.</li>
<li>Limited ability to optimize across multiple steps or maintain consistent long-term strategies.</li>
</ul>
<h3>Additional References<span class="hx-absolute -hx-mt-20" id="additional-references"></span>
    <a href="#additional-references" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>Prompt engineering:</p>
<ul>
<li><a href="https://www.promptingguide.ai/" target="_blank" rel="noopener">https://www.promptingguide.ai/</a></li>
<li><a href="https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/" target="_blank" rel="noopener">https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/</a></li>
<li><a href="https://github.com/elder-plinius/CL4R1T4S/blob/main/OPENAI/ChatGPT5-08-07-2025.mkd" target="_blank" rel="noopener">https://github.com/elder-plinius/CL4R1T4S/blob/main/OPENAI/ChatGPT5-08-07-2025.mkd</a></li>
</ul>
<p>CTF Agents research papers and blog posts:</p>
<ul>
<li><a href="https://arxiv.org/abs/2412.02776" target="_blank" rel="noopener">https://arxiv.org/abs/2412.02776</a></li>
<li><a href="https://arxiv.org/pdf/2403.05530" target="_blank" rel="noopener">https://arxiv.org/pdf/2403.05530</a></li>
<li><a href="https://arxiv.org/pdf/2403.13793" target="_blank" rel="noopener">https://arxiv.org/pdf/2403.13793</a></li>
<li><a href="https://enigma-agent.com/" target="_blank" rel="noopener">https://enigma-agent.com/</a></li>
<li><a href="https://wilgibbs.com/blog/defcon-finals-mcp/" target="_blank" rel="noopener">https://wilgibbs.com/blog/defcon-finals-mcp/</a></li>
<li><a href="https://github.com/aliasrobotics/cai" target="_blank" rel="noopener">https://github.com/aliasrobotics/cai</a></li>
<li><a href="https://github.com/enigma-agent/" target="_blank" rel="noopener">https://github.com/enigma-agent/</a></li>
<li><a href="https://github.com/princeton-nlp/intercode/" target="_blank" rel="noopener">https://github.com/princeton-nlp/intercode/</a></li>
</ul>
<p>Agent design patterns:</p>
<ul>
<li><a href="https://www.philschmid.de/agentic-pattern" target="_blank" rel="noopener">https://www.philschmid.de/agentic-pattern</a></li>
</ul>
<p>RAG:
- <a href="https://www.reddit.com/r/OpenAI/comments/1bjtz7y/when_do_we_use_llm_fine_tuning_vs_llm_rag/" target="_blank" rel="noopener">https://www.reddit.com/r/OpenAI/comments/1bjtz7y/when_do_we_use_llm_fine_tuning_vs_llm_rag/</a>
- <a href="https://docs.unsloth.ai/get-started/beginner-start-here/faq-&#43;-is-fine-tuning-right-for-me#is-rag-always-better-than-fine-tuning" target="_blank" rel="noopener">https://docs.unsloth.ai/get-started/beginner-start-here/faq-+-is-fine-tuning-right-for-me#is-rag-always-better-than-fine-tuning</a>
- <a href="https://x.com/rohanpaul_ai/status/1961990185698337156" target="_blank" rel="noopener">https://x.com/rohanpaul_ai/status/1961990185698337156</a>
- <a href="https://arxiv.org/abs/2508.21038" target="_blank" rel="noopener">https://arxiv.org/abs/2508.21038</a>
- <a href="https://learn.microsoft.com/en-us/azure/architecture/ai-ml/guide/rag/rag-solution-design-and-evaluation-guide" target="_blank" rel="noopener">https://learn.microsoft.com/en-us/azure/architecture/ai-ml/guide/rag/rag-solution-design-and-evaluation-guide</a></p>
<p>Open Source LLMs used:</p>
<ul>
<li>deepseek v3</li>
<li>llama 3.3 70b</li>
<li>llama 7b/8b</li>
<li>mistral nemo 12b</li>
<li>gpt oss 120b</li>
<li>bytedance seed 36b</li>
</ul>

        </div>
        <div class="hx-mt-16"></div>
        
        <div class="hx-mb-8 hx-flex hx-items-center hx-border-t hx-pt-8 dark:hx-border-neutral-800 contrast-more:hx-border-neutral-400 dark:contrast-more:hx-border-neutral-400 print:hx-hidden"><a
        href="/articles/isp-default-wifi-passwords-are-costlier-to-keep-than-to-crack-value-optimised-cloud-gpu-password-cracking/"
        title="ISP Default WiFi Passwords Are Costlier to Keep Than to Crack (Value optimised Cloud GPU password cracking)"
        class="hx-flex hx-max-w-[50%] hx-items-center hx-gap-1 hx-py-4 hx-text-base hx-font-medium hx-text-gray-600 hx-transition-colors [word-break:break-word] hover:hx-text-primary-600 dark:hx-text-gray-300 md:hx-text-lg ltr:hx-pr-4 rtl:hx-pl-4"
      ><svg class="hx-inline hx-h-5 hx-shrink-0 ltr:hx-rotate-180" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M9 5l7 7-7 7"/></svg>ISP Default WiFi Passwords Are Costlier to Keep Than to Crack (Value optimised Cloud GPU password cracking)</a></div>
        
      </main>
    </article>
  </div>

      <footer class="hextra-footer hx-bg-gray-100 hx-pb-[env(safe-area-inset-bottom)] dark:hx-bg-neutral-900 print:hx-bg-transparent"><div class="hx-mx-auto hx-flex hx-gap-2 hx-py-2 hx-px-4 hx-max-w-screen-xl"><button
  title="Change theme"
  data-theme="light"
  class="theme-toggle hx-group hx-h-7 hx-rounded-md hx-px-2 hx-text-left hx-text-xs hx-font-medium hx-text-gray-600 hx-transition-colors dark:hx-text-gray-400 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50"
  type="button"
  aria-label="Change theme"
>
  <div class="hx-flex hx-items-center hx-gap-2 hx-capitalize"><svg height=12 class="group-data-[theme=light]:hx-hidden" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><span class="group-data-[theme=light]:hx-hidden">Light</span><svg height=12 class="group-data-[theme=dark]:hx-hidden" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z"/></svg><span class="group-data-[theme=dark]:hx-hidden">Dark</span></div>
</button>
</div><hr class="dark:hx-border-neutral-800" /></footer>


    
    <script defer src="/js/main.min.a6eb101c76cd824b14b5bb9fa54e34e4b6414edb5e56347f59c358ba151e0432.js" integrity="sha256-pusQHHbNgksUtbufpU405LZBTtteVjR/WcNYuhUeBDI="></script>


<script defer src="/lib/flexsearch/flexsearch.bundle.min.0425860527cc9968f9f049421c7a56b39327d475e2e3a8f550416be3a9134327.js" integrity="sha256-BCWGBSfMmWj58ElCHHpWs5Mn1HXi46j1UEFr46kTQyc="></script>
    <script defer src="/en.search.min.4a72af14c5044971882cecddc91b1d5027c5a1ce9145e85eae7ee5145e971777.js" integrity="sha256-SnKvFMUESXGILOzdyRsdUCfFoc6RRehern7lFF6XF3c="></script>


  </body>
</html>
